{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import xgboost\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "import keras\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/Users/mykola/MLHEP/Wiremind/\"\n",
    "raw_features = pd.read_csv(os.path.join(DATA_PATH, \"ds_train.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current_price</th>\n",
       "      <th>days_before_departure</th>\n",
       "      <th>departure_date</th>\n",
       "      <th>direction</th>\n",
       "      <th>train_number</th>\n",
       "      <th>demand</th>\n",
       "      <th>od_destination_time_year</th>\n",
       "      <th>od_destination_time_month</th>\n",
       "      <th>od_destination_time_week</th>\n",
       "      <th>od_destination_time_day</th>\n",
       "      <th>...</th>\n",
       "      <th>od_destination_time_minute</th>\n",
       "      <th>od_origin_time_hour</th>\n",
       "      <th>od_origin_time_minute</th>\n",
       "      <th>od_time_travel</th>\n",
       "      <th>of_holiday</th>\n",
       "      <th>unof_holiday</th>\n",
       "      <th>od_destination_time_hourmin</th>\n",
       "      <th>od_origin_time_hourmin</th>\n",
       "      <th>direction_bool</th>\n",
       "      <th>date_numerical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>outbound</td>\n",
       "      <td>941</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>461</td>\n",
       "      <td>317</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>outbound</td>\n",
       "      <td>941</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>461</td>\n",
       "      <td>317</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>outbound</td>\n",
       "      <td>941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>461</td>\n",
       "      <td>317</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>outbound</td>\n",
       "      <td>941</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>461</td>\n",
       "      <td>317</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>outbound</td>\n",
       "      <td>941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>461</td>\n",
       "      <td>317</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292645</th>\n",
       "      <td>44</td>\n",
       "      <td>25</td>\n",
       "      <td>2018-12-28</td>\n",
       "      <td>inbound</td>\n",
       "      <td>980</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>53</td>\n",
       "      <td>21</td>\n",
       "      <td>50</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1433</td>\n",
       "      <td>1310</td>\n",
       "      <td>0</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292646</th>\n",
       "      <td>44</td>\n",
       "      <td>26</td>\n",
       "      <td>2018-12-28</td>\n",
       "      <td>inbound</td>\n",
       "      <td>980</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>53</td>\n",
       "      <td>21</td>\n",
       "      <td>50</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1433</td>\n",
       "      <td>1310</td>\n",
       "      <td>0</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292647</th>\n",
       "      <td>44</td>\n",
       "      <td>27</td>\n",
       "      <td>2018-12-28</td>\n",
       "      <td>inbound</td>\n",
       "      <td>980</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>53</td>\n",
       "      <td>21</td>\n",
       "      <td>50</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1433</td>\n",
       "      <td>1310</td>\n",
       "      <td>0</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292648</th>\n",
       "      <td>44</td>\n",
       "      <td>28</td>\n",
       "      <td>2018-12-28</td>\n",
       "      <td>inbound</td>\n",
       "      <td>980</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>53</td>\n",
       "      <td>21</td>\n",
       "      <td>50</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1433</td>\n",
       "      <td>1310</td>\n",
       "      <td>0</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292649</th>\n",
       "      <td>44</td>\n",
       "      <td>29</td>\n",
       "      <td>2018-12-28</td>\n",
       "      <td>inbound</td>\n",
       "      <td>980</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>53</td>\n",
       "      <td>21</td>\n",
       "      <td>50</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1433</td>\n",
       "      <td>1310</td>\n",
       "      <td>0</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>292650 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        current_price  days_before_departure departure_date direction  \\\n",
       "0                 100                      0     2018-01-02  outbound   \n",
       "1                 100                      1     2018-01-02  outbound   \n",
       "2                 100                      2     2018-01-02  outbound   \n",
       "3                 100                      3     2018-01-02  outbound   \n",
       "4                 100                      4     2018-01-02  outbound   \n",
       "...               ...                    ...            ...       ...   \n",
       "292645             44                     25     2018-12-28   inbound   \n",
       "292646             44                     26     2018-12-28   inbound   \n",
       "292647             44                     27     2018-12-28   inbound   \n",
       "292648             44                     28     2018-12-28   inbound   \n",
       "292649             44                     29     2018-12-28   inbound   \n",
       "\n",
       "        train_number  demand  od_destination_time_year  \\\n",
       "0                941     1.0                      2018   \n",
       "1                941     1.0                      2018   \n",
       "2                941     0.0                      2018   \n",
       "3                941     1.0                      2018   \n",
       "4                941     0.0                      2018   \n",
       "...              ...     ...                       ...   \n",
       "292645           980     0.0                      2018   \n",
       "292646           980     0.0                      2018   \n",
       "292647           980     0.0                      2018   \n",
       "292648           980     0.0                      2018   \n",
       "292649           980     0.0                      2018   \n",
       "\n",
       "        od_destination_time_month  od_destination_time_week  \\\n",
       "0                               1                         1   \n",
       "1                               1                         1   \n",
       "2                               1                         1   \n",
       "3                               1                         1   \n",
       "4                               1                         1   \n",
       "...                           ...                       ...   \n",
       "292645                         12                        52   \n",
       "292646                         12                        52   \n",
       "292647                         12                        52   \n",
       "292648                         12                        52   \n",
       "292649                         12                        52   \n",
       "\n",
       "        od_destination_time_day  ...  od_destination_time_minute  \\\n",
       "0                             2  ...                          41   \n",
       "1                             2  ...                          41   \n",
       "2                             2  ...                          41   \n",
       "3                             2  ...                          41   \n",
       "4                             2  ...                          41   \n",
       "...                         ...  ...                         ...   \n",
       "292645                       28  ...                          53   \n",
       "292646                       28  ...                          53   \n",
       "292647                       28  ...                          53   \n",
       "292648                       28  ...                          53   \n",
       "292649                       28  ...                          53   \n",
       "\n",
       "        od_origin_time_hour  od_origin_time_minute  od_time_travel  \\\n",
       "0                         5                     17           144.0   \n",
       "1                         5                     17           144.0   \n",
       "2                         5                     17           144.0   \n",
       "3                         5                     17           144.0   \n",
       "4                         5                     17           144.0   \n",
       "...                     ...                    ...             ...   \n",
       "292645                   21                     50           123.0   \n",
       "292646                   21                     50           123.0   \n",
       "292647                   21                     50           123.0   \n",
       "292648                   21                     50           123.0   \n",
       "292649                   21                     50           123.0   \n",
       "\n",
       "        of_holiday  unof_holiday  od_destination_time_hourmin  \\\n",
       "0                0             0                          461   \n",
       "1                0             0                          461   \n",
       "2                0             0                          461   \n",
       "3                0             0                          461   \n",
       "4                0             0                          461   \n",
       "...            ...           ...                          ...   \n",
       "292645           0             0                         1433   \n",
       "292646           0             0                         1433   \n",
       "292647           0             0                         1433   \n",
       "292648           0             0                         1433   \n",
       "292649           0             0                         1433   \n",
       "\n",
       "        od_origin_time_hourmin  direction_bool  date_numerical  \n",
       "0                          317               1               2  \n",
       "1                          317               1               2  \n",
       "2                          317               1               2  \n",
       "3                          317               1               2  \n",
       "4                          317               1               2  \n",
       "...                        ...             ...             ...  \n",
       "292645                    1310               0             362  \n",
       "292646                    1310               0             362  \n",
       "292647                    1310               0             362  \n",
       "292648                    1310               0             362  \n",
       "292649                    1310               0             362  \n",
       "\n",
       "[292650 rows x 22 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features = utils.features_preparation(raw_features)\n",
    "all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "/usr/local/lib/python3.8/site-packages/pandas/core/frame.py:2963: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current_price</th>\n",
       "      <th>days_before_departure</th>\n",
       "      <th>od_destination_time_month</th>\n",
       "      <th>od_destination_time_week</th>\n",
       "      <th>od_destination_time_day</th>\n",
       "      <th>od_destination_time_weekday</th>\n",
       "      <th>od_time_travel</th>\n",
       "      <th>od_destination_time_hourmin</th>\n",
       "      <th>od_origin_time_hourmin</th>\n",
       "      <th>direction_bool</th>\n",
       "      <th>demand</th>\n",
       "      <th>of_holiday</th>\n",
       "      <th>unof_holiday</th>\n",
       "      <th>date_numerical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.788732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.231013</td>\n",
       "      <td>0.224219</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.788732</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.231013</td>\n",
       "      <td>0.224219</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.788732</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.231013</td>\n",
       "      <td>0.224219</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.788732</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.231013</td>\n",
       "      <td>0.224219</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.788732</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.231013</td>\n",
       "      <td>0.224219</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292645</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292646</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292647</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292648</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292649</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>292650 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        current_price  days_before_departure  od_destination_time_month  \\\n",
       "0            0.788732               0.000000                        0.0   \n",
       "1            0.788732               0.034483                        0.0   \n",
       "2            0.788732               0.068966                        0.0   \n",
       "3            0.788732               0.103448                        0.0   \n",
       "4            0.788732               0.137931                        0.0   \n",
       "...               ...                    ...                        ...   \n",
       "292645       0.000000               0.862069                        1.0   \n",
       "292646       0.000000               0.896552                        1.0   \n",
       "292647       0.000000               0.931034                        1.0   \n",
       "292648       0.000000               0.965517                        1.0   \n",
       "292649       0.000000               1.000000                        1.0   \n",
       "\n",
       "        od_destination_time_week  od_destination_time_day  \\\n",
       "0                            0.0                 0.033333   \n",
       "1                            0.0                 0.033333   \n",
       "2                            0.0                 0.033333   \n",
       "3                            0.0                 0.033333   \n",
       "4                            0.0                 0.033333   \n",
       "...                          ...                      ...   \n",
       "292645                       1.0                 0.900000   \n",
       "292646                       1.0                 0.900000   \n",
       "292647                       1.0                 0.900000   \n",
       "292648                       1.0                 0.900000   \n",
       "292649                       1.0                 0.900000   \n",
       "\n",
       "        od_destination_time_weekday  od_time_travel  \\\n",
       "0                          0.166667        0.901961   \n",
       "1                          0.166667        0.901961   \n",
       "2                          0.166667        0.901961   \n",
       "3                          0.166667        0.901961   \n",
       "4                          0.166667        0.901961   \n",
       "...                             ...             ...   \n",
       "292645                     0.666667        0.490196   \n",
       "292646                     0.666667        0.490196   \n",
       "292647                     0.666667        0.490196   \n",
       "292648                     0.666667        0.490196   \n",
       "292649                     0.666667        0.490196   \n",
       "\n",
       "        od_destination_time_hourmin  od_origin_time_hourmin  direction_bool  \\\n",
       "0                          0.231013                0.224219               1   \n",
       "1                          0.231013                0.224219               1   \n",
       "2                          0.231013                0.224219               1   \n",
       "3                          0.231013                0.224219               1   \n",
       "4                          0.231013                0.224219               1   \n",
       "...                             ...                     ...             ...   \n",
       "292645                     1.000000                1.000000               0   \n",
       "292646                     1.000000                1.000000               0   \n",
       "292647                     1.000000                1.000000               0   \n",
       "292648                     1.000000                1.000000               0   \n",
       "292649                     1.000000                1.000000               0   \n",
       "\n",
       "        demand  of_holiday  unof_holiday  date_numerical  \n",
       "0          1.0           0             0               2  \n",
       "1          1.0           0             0               2  \n",
       "2          0.0           0             0               2  \n",
       "3          1.0           0             0               2  \n",
       "4          0.0           0             0               2  \n",
       "...        ...         ...           ...             ...  \n",
       "292645     0.0           0             0             362  \n",
       "292646     0.0           0             0             362  \n",
       "292647     0.0           0             0             362  \n",
       "292648     0.0           0             0             362  \n",
       "292649     0.0           0             0             362  \n",
       "\n",
       "[292650 rows x 14 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_features = utils.features_scale(all_features)\n",
    "scaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'K' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-ac932280e860>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mdense23\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tanh'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mbn3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdense23\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0msecondary_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0msecondary_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'K' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model\n",
    "import tensorlayer as tl\n",
    "main_input = Input(shape=(12,))\n",
    "dense20 = Dense(512,activation='tanh')(main_input)\n",
    "dpt3 = (layers.Dropout(rate=0.15))(dense20)\n",
    "dense21 = Dense(256,activation='tanh')(dpt3)\n",
    "bn1 = layers.BatchNormalization()(dense21)\n",
    "dense22 = Dense(128,activation='tanh')(bn1)\n",
    "bn2 = layers.BatchNormalization()(dense22)\n",
    "dense23 = Dense(64,activation='tanh')(bn2)\n",
    "bn3 = layers.BatchNormalization()(dense23)\n",
    "secondary_out = Dense(1,activation=K.exp)(bn3)\n",
    "secondary_out.trainable = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def negative_binomial_layer(x):\n",
    "    \"\"\"\n",
    "    Lambda function for generating negative binomial parameters\n",
    "    n and p from a Dense(2) output.\n",
    "    Assumes tensorflow 2 backend.\n",
    "    \n",
    "    Usage\n",
    "    -----\n",
    "    outputs = Dense(2)(final_layer)\n",
    "    distribution_outputs = Lambda(negative_binomial_layer)(outputs)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : tf.Tensor\n",
    "        output tensor of Dense layer\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    out_tensor : tf.Tensor\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the number of dimensions of the input\n",
    "    num_dims = len(x.get_shape())\n",
    "    \n",
    "    # Separate the parameters\n",
    "    n, p = tf.unstack(x, num=2, axis=-1)\n",
    "    \n",
    "    # Add one dimension to make the right shape\n",
    "    n = tf.expand_dims(n, -1)\n",
    "    p = tf.expand_dims(p, -1)\n",
    "        \n",
    "    # Apply a softplus to make positive\n",
    "    n = tf.keras.activations.softplus(n)\n",
    "    \n",
    "    # Apply a sigmoid activation to bound between 0 and 1\n",
    "    p = tf.keras.activations.sigmoid(p)\n",
    "\n",
    "    # Join back together again\n",
    "    out_tensor = tf.concat((n, p), axis=num_dims-1)\n",
    "\n",
    "    return out_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need a class (or closure) here,\n",
    "# because it's not possible to\n",
    "# pass extra arguments to Keras loss functions\n",
    "# See https://github.com/fchollet/keras/issues/2121\n",
    "\n",
    "# dispersion (theta) parameter is a scalar by default.\n",
    "# scale_factor scales the nbinom mean before the \n",
    "# calculation of the loss to balance the\n",
    "# learning rates of theta and network weights\n",
    "\n",
    "class NB(object):\n",
    "    def __init__(self, theta=None, theta_init=[0.0],\n",
    "                 scale_factor=1.0, scope='nbinom_loss/',\n",
    "                 debug=False, **theta_kwargs):\n",
    "        \n",
    "        # for numerical stability\n",
    "        self.eps = 1e-10\n",
    "        self.scale_factor = scale_factor\n",
    "        self.debug = debug\n",
    "        self.scope = scope\n",
    "        \n",
    "        with tf.name_scope(self.scope):\n",
    "            # a variable may be given by user or it can be created here\n",
    "            if theta is None:\n",
    "                theta = tf.Variable(theta_init, dtype=tf.float32,\n",
    "                                    name='theta', **theta_kwargs)\n",
    "\n",
    "            # keep a reference to the variable itself\n",
    "            self.theta_variable = theta\n",
    "\n",
    "            # to keep dispersion always non-negative\n",
    "            self.theta = tf.nn.softplus(theta)\n",
    "           \n",
    "    def loss(self, y_true, y_pred, reduce=True):\n",
    "        scale_factor = self.scale_factor\n",
    "        eps = self.eps\n",
    "        \n",
    "        with tf.name_scope(self.scope):\n",
    "            y_true = tf.cast(y_true, tf.float32)\n",
    "            y_pred = tf.cast(y_pred, tf.float32) * scale_factor\n",
    "            \n",
    "            theta = 1.0/(self.theta+eps)\n",
    "\n",
    "            t1 = -tf.math.lgamma(y_true+theta+eps) \n",
    "            t2 = tf.math.lgamma(theta+eps)\n",
    "            t3 = tf.math.lgamma(y_true+1.0) \n",
    "            t4 = -(theta * (tf.math.log(theta+eps)))\n",
    "            t5 = -(y_true * (tf.math.log(y_pred+eps)))\n",
    "            t6 = (theta+y_true) * tf.math.log(theta+y_pred+eps)      \n",
    "\n",
    "            if self.debug:\n",
    "                tf.summary.histogram('t1', t1)\n",
    "                tf.summary.histogram('t2', t2)\n",
    "                tf.summary.histogram('t3', t3)\n",
    "                tf.summary.histogram('t4', t4)\n",
    "                tf.summary.histogram('t5', t5)\n",
    "                tf.summary.histogram('t6', t6)\n",
    "\n",
    "            final = t1 + t2 + t3 + t4 + t5 + t6\n",
    "            \n",
    "            if reduce:\n",
    "                final = tf.reduce_mean(final)\n",
    "            \n",
    "        return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def negative_binomial_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Negative binomial loss function.\n",
    "    Assumes tensorflow backend.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : tf.Tensor\n",
    "        Ground truth values of predicted variable.\n",
    "    y_pred : tf.Tensor\n",
    "        n and p values of predicted distribution.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    nll : tf.Tensor\n",
    "        Negative log likelihood.\n",
    "    \"\"\"\n",
    "\n",
    "    # Separate the parameters\n",
    "    n, p = tf.unstack(y_pred, num=2, axis=-1)\n",
    "    \n",
    "    # Add one dimension to make the right shape\n",
    "    n = tf.expand_dims(n, -1)\n",
    "    p = tf.expand_dims(p, -1)\n",
    "    \n",
    "    # Calculate the negative log likelihood\n",
    "    nll = (\n",
    "        tf.math.lgamma(n) \n",
    "        + tf.math.lgamma(y_true + 1)\n",
    "        - tf.math.lgamma(n + y_true)\n",
    "        - n * tf.math.log(p)\n",
    "        - y_true * tf.math.log(1 - p)\n",
    "    )                  \n",
    "\n",
    "    return nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model\n",
    "import tensorlayer as tl\n",
    "main_input = Input(shape=(12,))\n",
    "dense23 = Dense(512,activation='relu')(main_input)\n",
    "#bn3 = layers.BatchNormalization()(dense23)\n",
    "dense22 = Dense(256,activation='relu')(dense23)\n",
    "#bn2 = layers.BatchNormalization()(dense22)\n",
    "dense21 = Dense(256,activation='relu')(dense22)\n",
    "#bn1 = layers.BatchNormalization()(dense22)\n",
    "secondary_out = Dense(2)(bn1)\n",
    "\n",
    "#distribution_outputs = Lambda(negative_binomial_layer)(secondary_out)\n",
    "secondary_out.trainable = False\n",
    "\n",
    "model = Model(inputs=main_input, outputs=distribution_outputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.layers.core.Lambda object at 0x15126da00>\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(234120, 14)\n",
      "(58530, 14)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "69580     0.0\n",
       "49753     0.0\n",
       "2702      1.0\n",
       "98526     0.0\n",
       "109822    2.0\n",
       "         ... \n",
       "128419    0.0\n",
       "270933    0.0\n",
       "292252    0.0\n",
       "247226    0.0\n",
       "205700    0.0\n",
       "Name: demand, Length: 58530, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_part, validation = train_test_split(scaled_features, test_size=0.2, shuffle=True, random_state=342343234)\n",
    "print(train_part.shape)\n",
    "print(validation.shape)\n",
    "validation.demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/1100\n",
      "1551/1561 [============================>.] - ETA: 0s - loss: 1.1259 - MAE: 1.4311 - MSE: 13.4151\n",
      "Epoch 00001: saving model to NNmodels/weights.01-1.09437.h5\n",
      "1561/1561 [==============================] - 6s 4ms/step - loss: 1.1258 - MAE: 1.4304 - MSE: 13.4004 - val_loss: 1.0944 - val_MAE: 1.3816 - val_MSE: 12.5525\n",
      "Epoch 2/1100\n",
      "1555/1561 [============================>.] - ETA: 0s - loss: 1.0898 - MAE: 1.3786 - MSE: 12.7405\n",
      "Epoch 00002: saving model to NNmodels/weights.02-1.07993.h5\n",
      "1561/1561 [==============================] - 6s 4ms/step - loss: 1.0898 - MAE: 1.3784 - MSE: 12.7326 - val_loss: 1.0799 - val_MAE: 1.3436 - val_MSE: 11.9694\n",
      "Epoch 3/1100\n",
      " 814/1561 [==============>...............] - ETA: 2s - loss: 1.0814 - MAE: 1.3632 - MSE: 12.3231"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-a3f080d384be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0msave_all_xy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NNmodels/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'weights.{epoch:02d}-{val_loss:.5f}.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_weights_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperiod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_part\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_part\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdemand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msave_all_xy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdemand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "nb = NB()\n",
    "nbinom_loss, param_theta = nb.loss, nb.theta\n",
    "\n",
    "opt = Adam()\n",
    "#model.compile(loss = negative_binomial_loss, metrics = [\"MAE\",\"MSE\"], optimizer = opt)\n",
    "#model.compile(loss = negative_binomial_loss, metrics = [\"MAE\",\"MSE\"], optimizer = opt)\n",
    "model.compile(loss = negative_binomial_loss, metrics = [\"MAE\",\"MSE\"], optimizer = opt)\n",
    "\n",
    "#history = model.fit(train_X, train_Y, epochs = num_epochs,validation_data = [val_X, val_Y])\n",
    "save_all_xy = keras.callbacks.ModelCheckpoint(\"NNmodels/\"+'weights.{epoch:02d}-{val_loss:.5f}.h5', monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "history = model.fit(train_part.loc[:,utils.input_features].values,train_part.demand, verbose=1, callbacks=[save_all_xy], validation_data=(validation.loc[:,utils.input_features].values, validation.demand), shuffle=True, batch_size=150, epochs=1100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[main_input],outputs=[secondary_out])\n",
    "from keras import backend as K\n",
    "def poisson(y_true, y_pred): \n",
    "    return K.mean(K.maximum(.0, y_pred) - y_true * K.log(K.maximum(.0, y_pred) + K.epsilon()), axis=-1)\n",
    "#    return K.mean(y_pred - y_true * K.log(y_pred + K.epsilon()), axis=-1)\n",
    "def poisson_loss(y_true, y_pred):\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    return tf.reduce_mean(y_pred - y_true*tf.math.log(y_pred+1e-10) + \\\n",
    "                          tf.math.lgamma(y_true+1.0))\n",
    "m = tf.keras.losses.poisson\n",
    "\n",
    "save_all_xy = keras.callbacks.ModelCheckpoint(\"NNmodels/\"+'weights.{epoch:02d}-{val_loss:.5f}.h5', monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "model.compile(loss=[poisson_loss], metrics=[\"MAE\",\"MSE\"] ,optimizer=Adam(lr=0.001),loss_weights=[1])\n",
    "history = model.fit(train_part.loc[:,utils.input_features].values,train_part.demand, verbose=1, callbacks=[save_all_xy], validation_data=(validation.loc[:,utils.input_features].values, validation.demand), shuffle=True, batch_size=150, epochs=1100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Training loss', 'Validation loss'], loc='upper right')\n",
    "plt.savefig(\"loss.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "def r_square(y_true, y_pred):\n",
    "    from keras import backend as K\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return (1 - SS_res/(SS_tot + K.epsilon()))\n",
    "\n",
    "def poisson_loss(y_true, y_pred):\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    return tf.reduce_mean(y_pred - y_true*tf.math.log(y_pred+1e-10) + \\\n",
    "                          tf.math.lgamma(y_true+1.0))\n",
    "\n",
    "model = load_model(\"/Users/mykola/MLHEP/Wiremind/NNModels/weights.85-1.15921.h5\", custom_objects={'<lambda>': lambda x : tl.act.lrelu(x, 0.2),\"r_square\":r_square,\"exp\":K.exp,\"poisson_loss\":poisson_loss})\n",
    "prediction_validation = np.array(model.predict(validation.loc[:, utils.input_features].values),dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = np.floor(prediction_validation).astype(np.int)\n",
    "np.unique(k)\n",
    "#validation.demand.unique\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = prediction_validation\n",
    "first.flatten().shape\n",
    "second = prediction_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation.shape\n",
    "prediction_validation.shape\n",
    "#validation.loc[:,\"nn_demand\"] = np.rint(prediction_validation.flatten())\n",
    "#validation[25:50]\n",
    "#prediction_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.25*np.rint(prediction_validation)[:50]\n",
    "print(abs(np.rint(k.flatten()) - np.array(validation.demand)).sum())\n",
    "#np.rint(prediction_validation)[:50]\n",
    "#np.mean(validation.current_price*abs(np.rint(first.flatten()) - np.array(validation.demand)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(abs(np.rint(k.flatten()) - np.array(validation.demand)))\n",
    "#np.mean((np.rint(k.flatten()) - np.array(validation.demand))**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "x = np.random.randint(1, 100, 5000)\n",
    "x\n",
    "#plt.hist(x, bins=20)\n",
    "#plt.ylabel('No of times')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
