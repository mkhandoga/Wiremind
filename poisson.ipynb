{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import xgboost\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "import keras\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "DATA_PATH = \"/Users/mykola/MLHEP/Wiremind/\"\n",
    "raw_features = pd.read_csv(os.path.join(DATA_PATH, \"ds_train.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current_price</th>\n",
       "      <th>days_before_departure</th>\n",
       "      <th>departure_date</th>\n",
       "      <th>direction</th>\n",
       "      <th>train_number</th>\n",
       "      <th>demand</th>\n",
       "      <th>od_destination_time_year</th>\n",
       "      <th>od_destination_time_month</th>\n",
       "      <th>od_destination_time_week</th>\n",
       "      <th>od_destination_time_day</th>\n",
       "      <th>...</th>\n",
       "      <th>od_destination_time_minute</th>\n",
       "      <th>od_origin_time_hour</th>\n",
       "      <th>od_origin_time_minute</th>\n",
       "      <th>od_time_travel</th>\n",
       "      <th>of_holiday</th>\n",
       "      <th>unof_holiday</th>\n",
       "      <th>od_destination_time_hourmin</th>\n",
       "      <th>od_origin_time_hourmin</th>\n",
       "      <th>direction_bool</th>\n",
       "      <th>date_numerical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>outbound</td>\n",
       "      <td>941</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>461</td>\n",
       "      <td>317</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>outbound</td>\n",
       "      <td>941</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>461</td>\n",
       "      <td>317</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>outbound</td>\n",
       "      <td>941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>461</td>\n",
       "      <td>317</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>outbound</td>\n",
       "      <td>941</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>461</td>\n",
       "      <td>317</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>outbound</td>\n",
       "      <td>941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>461</td>\n",
       "      <td>317</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292645</th>\n",
       "      <td>44</td>\n",
       "      <td>25</td>\n",
       "      <td>2018-12-28</td>\n",
       "      <td>inbound</td>\n",
       "      <td>980</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>53</td>\n",
       "      <td>21</td>\n",
       "      <td>50</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1433</td>\n",
       "      <td>1310</td>\n",
       "      <td>0</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292646</th>\n",
       "      <td>44</td>\n",
       "      <td>26</td>\n",
       "      <td>2018-12-28</td>\n",
       "      <td>inbound</td>\n",
       "      <td>980</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>53</td>\n",
       "      <td>21</td>\n",
       "      <td>50</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1433</td>\n",
       "      <td>1310</td>\n",
       "      <td>0</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292647</th>\n",
       "      <td>44</td>\n",
       "      <td>27</td>\n",
       "      <td>2018-12-28</td>\n",
       "      <td>inbound</td>\n",
       "      <td>980</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>53</td>\n",
       "      <td>21</td>\n",
       "      <td>50</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1433</td>\n",
       "      <td>1310</td>\n",
       "      <td>0</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292648</th>\n",
       "      <td>44</td>\n",
       "      <td>28</td>\n",
       "      <td>2018-12-28</td>\n",
       "      <td>inbound</td>\n",
       "      <td>980</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>53</td>\n",
       "      <td>21</td>\n",
       "      <td>50</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1433</td>\n",
       "      <td>1310</td>\n",
       "      <td>0</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292649</th>\n",
       "      <td>44</td>\n",
       "      <td>29</td>\n",
       "      <td>2018-12-28</td>\n",
       "      <td>inbound</td>\n",
       "      <td>980</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>53</td>\n",
       "      <td>21</td>\n",
       "      <td>50</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1433</td>\n",
       "      <td>1310</td>\n",
       "      <td>0</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>292650 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        current_price  days_before_departure departure_date direction  \\\n",
       "0                 100                      0     2018-01-02  outbound   \n",
       "1                 100                      1     2018-01-02  outbound   \n",
       "2                 100                      2     2018-01-02  outbound   \n",
       "3                 100                      3     2018-01-02  outbound   \n",
       "4                 100                      4     2018-01-02  outbound   \n",
       "...               ...                    ...            ...       ...   \n",
       "292645             44                     25     2018-12-28   inbound   \n",
       "292646             44                     26     2018-12-28   inbound   \n",
       "292647             44                     27     2018-12-28   inbound   \n",
       "292648             44                     28     2018-12-28   inbound   \n",
       "292649             44                     29     2018-12-28   inbound   \n",
       "\n",
       "        train_number  demand  od_destination_time_year  \\\n",
       "0                941     1.0                      2018   \n",
       "1                941     1.0                      2018   \n",
       "2                941     0.0                      2018   \n",
       "3                941     1.0                      2018   \n",
       "4                941     0.0                      2018   \n",
       "...              ...     ...                       ...   \n",
       "292645           980     0.0                      2018   \n",
       "292646           980     0.0                      2018   \n",
       "292647           980     0.0                      2018   \n",
       "292648           980     0.0                      2018   \n",
       "292649           980     0.0                      2018   \n",
       "\n",
       "        od_destination_time_month  od_destination_time_week  \\\n",
       "0                               1                         1   \n",
       "1                               1                         1   \n",
       "2                               1                         1   \n",
       "3                               1                         1   \n",
       "4                               1                         1   \n",
       "...                           ...                       ...   \n",
       "292645                         12                        52   \n",
       "292646                         12                        52   \n",
       "292647                         12                        52   \n",
       "292648                         12                        52   \n",
       "292649                         12                        52   \n",
       "\n",
       "        od_destination_time_day  ...  od_destination_time_minute  \\\n",
       "0                             2  ...                          41   \n",
       "1                             2  ...                          41   \n",
       "2                             2  ...                          41   \n",
       "3                             2  ...                          41   \n",
       "4                             2  ...                          41   \n",
       "...                         ...  ...                         ...   \n",
       "292645                       28  ...                          53   \n",
       "292646                       28  ...                          53   \n",
       "292647                       28  ...                          53   \n",
       "292648                       28  ...                          53   \n",
       "292649                       28  ...                          53   \n",
       "\n",
       "        od_origin_time_hour  od_origin_time_minute  od_time_travel  \\\n",
       "0                         5                     17           144.0   \n",
       "1                         5                     17           144.0   \n",
       "2                         5                     17           144.0   \n",
       "3                         5                     17           144.0   \n",
       "4                         5                     17           144.0   \n",
       "...                     ...                    ...             ...   \n",
       "292645                   21                     50           123.0   \n",
       "292646                   21                     50           123.0   \n",
       "292647                   21                     50           123.0   \n",
       "292648                   21                     50           123.0   \n",
       "292649                   21                     50           123.0   \n",
       "\n",
       "        of_holiday  unof_holiday  od_destination_time_hourmin  \\\n",
       "0                0             0                          461   \n",
       "1                0             0                          461   \n",
       "2                0             0                          461   \n",
       "3                0             0                          461   \n",
       "4                0             0                          461   \n",
       "...            ...           ...                          ...   \n",
       "292645           0             0                         1433   \n",
       "292646           0             0                         1433   \n",
       "292647           0             0                         1433   \n",
       "292648           0             0                         1433   \n",
       "292649           0             0                         1433   \n",
       "\n",
       "        od_origin_time_hourmin  direction_bool  date_numerical  \n",
       "0                          317               1               2  \n",
       "1                          317               1               2  \n",
       "2                          317               1               2  \n",
       "3                          317               1               2  \n",
       "4                          317               1               2  \n",
       "...                        ...             ...             ...  \n",
       "292645                    1310               0             362  \n",
       "292646                    1310               0             362  \n",
       "292647                    1310               0             362  \n",
       "292648                    1310               0             362  \n",
       "292649                    1310               0             362  \n",
       "\n",
       "[292650 rows x 22 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features = utils.features_preparation(raw_features)\n",
    "all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "/usr/local/lib/python3.8/site-packages/pandas/core/frame.py:2963: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current_price</th>\n",
       "      <th>days_before_departure</th>\n",
       "      <th>od_destination_time_month</th>\n",
       "      <th>od_destination_time_week</th>\n",
       "      <th>od_destination_time_day</th>\n",
       "      <th>od_destination_time_weekday</th>\n",
       "      <th>od_time_travel</th>\n",
       "      <th>od_destination_time_hourmin</th>\n",
       "      <th>od_origin_time_hourmin</th>\n",
       "      <th>direction_bool</th>\n",
       "      <th>demand</th>\n",
       "      <th>of_holiday</th>\n",
       "      <th>unof_holiday</th>\n",
       "      <th>date_numerical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.788732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.231013</td>\n",
       "      <td>0.224219</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.788732</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.231013</td>\n",
       "      <td>0.224219</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.788732</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.231013</td>\n",
       "      <td>0.224219</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.788732</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.231013</td>\n",
       "      <td>0.224219</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.788732</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.231013</td>\n",
       "      <td>0.224219</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292645</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292646</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292647</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292648</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292649</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>292650 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        current_price  days_before_departure  od_destination_time_month  \\\n",
       "0            0.788732               0.000000                        0.0   \n",
       "1            0.788732               0.034483                        0.0   \n",
       "2            0.788732               0.068966                        0.0   \n",
       "3            0.788732               0.103448                        0.0   \n",
       "4            0.788732               0.137931                        0.0   \n",
       "...               ...                    ...                        ...   \n",
       "292645       0.000000               0.862069                        1.0   \n",
       "292646       0.000000               0.896552                        1.0   \n",
       "292647       0.000000               0.931034                        1.0   \n",
       "292648       0.000000               0.965517                        1.0   \n",
       "292649       0.000000               1.000000                        1.0   \n",
       "\n",
       "        od_destination_time_week  od_destination_time_day  \\\n",
       "0                            0.0                 0.033333   \n",
       "1                            0.0                 0.033333   \n",
       "2                            0.0                 0.033333   \n",
       "3                            0.0                 0.033333   \n",
       "4                            0.0                 0.033333   \n",
       "...                          ...                      ...   \n",
       "292645                       1.0                 0.900000   \n",
       "292646                       1.0                 0.900000   \n",
       "292647                       1.0                 0.900000   \n",
       "292648                       1.0                 0.900000   \n",
       "292649                       1.0                 0.900000   \n",
       "\n",
       "        od_destination_time_weekday  od_time_travel  \\\n",
       "0                          0.166667        0.901961   \n",
       "1                          0.166667        0.901961   \n",
       "2                          0.166667        0.901961   \n",
       "3                          0.166667        0.901961   \n",
       "4                          0.166667        0.901961   \n",
       "...                             ...             ...   \n",
       "292645                     0.666667        0.490196   \n",
       "292646                     0.666667        0.490196   \n",
       "292647                     0.666667        0.490196   \n",
       "292648                     0.666667        0.490196   \n",
       "292649                     0.666667        0.490196   \n",
       "\n",
       "        od_destination_time_hourmin  od_origin_time_hourmin  direction_bool  \\\n",
       "0                          0.231013                0.224219               1   \n",
       "1                          0.231013                0.224219               1   \n",
       "2                          0.231013                0.224219               1   \n",
       "3                          0.231013                0.224219               1   \n",
       "4                          0.231013                0.224219               1   \n",
       "...                             ...                     ...             ...   \n",
       "292645                     1.000000                1.000000               0   \n",
       "292646                     1.000000                1.000000               0   \n",
       "292647                     1.000000                1.000000               0   \n",
       "292648                     1.000000                1.000000               0   \n",
       "292649                     1.000000                1.000000               0   \n",
       "\n",
       "        demand  of_holiday  unof_holiday  date_numerical  \n",
       "0          1.0           0             0               2  \n",
       "1          1.0           0             0               2  \n",
       "2          0.0           0             0               2  \n",
       "3          1.0           0             0               2  \n",
       "4          0.0           0             0               2  \n",
       "...        ...         ...           ...             ...  \n",
       "292645     0.0           0             0             362  \n",
       "292646     0.0           0             0             362  \n",
       "292647     0.0           0             0             362  \n",
       "292648     0.0           0             0             362  \n",
       "292649     0.0           0             0             362  \n",
       "\n",
       "[292650 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_features = utils.features_scale(all_features)\n",
    "scaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorlayer as tl\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, activation=lambda x : tl.act.lrelu(x, 0.2), kernel_initializer='random_normal', input_dim=12))\n",
    "model.add(layers.Dropout(rate=0.3))\n",
    "model.add(Dense(512, activation=lambda x : tl.act.lrelu(x, 0.2), kernel_initializer='random_normal'))\n",
    "model.add(layers.Dropout(rate=0.2))\n",
    "#model.add(Dense(512, activation='relu', kernel_initializer='random_normal'))\n",
    "model.add(Dense(256, activation=lambda x : tl.act.lrelu(x, 0.2), kernel_initializer='random_normal'))\n",
    "model.add(Dense(128, activation=lambda x : tl.act.lrelu(x, 0.2), kernel_initializer='random_normal'))\n",
    "#model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(rate=0.1))\n",
    "model.add(Dense(64, activation=lambda x : tl.act.lrelu(x, 0.2), kernel_initializer='random_normal'))\n",
    "#model.add(layers.BatchNormalization())\n",
    "#model.add(Dense(64, activation='relu', kernel_initializer='random_normal'))\n",
    "#model.add(layers.BatchNormalization())\n",
    "model.add(Dense(1, activation=lambda x : tl.act.lrelu(x, 0.2), kernel_initializer='random_normal'))\n",
    "#model.compile(optimizer =Adam(lr=0.001),loss=[r_square_loss], metrics =['MSE','MAE'])\n",
    "model.compile(optimizer =Adam(lr=0.001),loss=['MSE'], metrics =[utils.r_square,'MAE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model\n",
    "import tensorlayer as tl\n",
    "main_input = Input(shape=(12,))\n",
    "dense20 = Dense(512,activation='tanh')(main_input)\n",
    "dpt3 = (layers.Dropout(rate=0.15))(dense20)\n",
    "dense21 = Dense(256,activation='tanh')(dpt3)\n",
    "bn1 = layers.BatchNormalization()(dense21)\n",
    "dense22 = Dense(128,activation='tanh')(bn1)\n",
    "bn2 = layers.BatchNormalization()(dense22)\n",
    "dense23 = Dense(64,activation='tanh')(bn2)\n",
    "bn3 = layers.BatchNormalization()(dense23)\n",
    "secondary_out = Dense(1,activation=K.exp)(bn3)\n",
    "secondary_out.trainable = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(234120, 14)\n",
      "(58530, 14)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "69580     0.0\n",
       "49753     0.0\n",
       "2702      1.0\n",
       "98526     0.0\n",
       "109822    2.0\n",
       "         ... \n",
       "128419    0.0\n",
       "270933    0.0\n",
       "292252    0.0\n",
       "247226    0.0\n",
       "205700    0.0\n",
       "Name: demand, Length: 58530, dtype: float64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_part, validation = train_test_split(scaled_features, test_size=0.2, shuffle=True, random_state=342343234)\n",
    "print(train_part.shape)\n",
    "print(validation.shape)\n",
    "validation.demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.4954 - MAE: 1.2376 - MSE: 7.5490\n",
      "Epoch 00001: saving model to NNmodels/weights.01-1.34267.h5\n",
      "1561/1561 [==============================] - 31s 20ms/step - loss: 1.4953 - MAE: 1.2375 - MSE: 7.5469 - val_loss: 1.3427 - val_MAE: 1.1477 - val_MSE: 6.6696\n",
      "Epoch 2/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.3193 - MAE: 1.0779 - MSE: 5.1847\n",
      "Epoch 00002: saving model to NNmodels/weights.02-1.28381.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.3192 - MAE: 1.0779 - MSE: 5.1836 - val_loss: 1.2838 - val_MAE: 1.0786 - val_MSE: 5.4982\n",
      "Epoch 3/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.2965 - MAE: 1.0506 - MSE: 4.8349\n",
      "Epoch 00003: saving model to NNmodels/weights.03-1.26883.h5\n",
      "1561/1561 [==============================] - 33s 21ms/step - loss: 1.2965 - MAE: 1.0506 - MSE: 4.8338 - val_loss: 1.2688 - val_MAE: 1.0519 - val_MSE: 4.9230\n",
      "Epoch 4/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.2788 - MAE: 1.0328 - MSE: 4.5817\n",
      "Epoch 00004: saving model to NNmodels/weights.04-1.26249.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.2788 - MAE: 1.0328 - MSE: 4.5817 - val_loss: 1.2625 - val_MAE: 0.9949 - val_MSE: 4.4964\n",
      "Epoch 5/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.2757 - MAE: 1.0284 - MSE: 4.5942\n",
      "Epoch 00005: saving model to NNmodels/weights.05-1.26619.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.2757 - MAE: 1.0284 - MSE: 4.5942 - val_loss: 1.2662 - val_MAE: 1.0508 - val_MSE: 4.9955\n",
      "Epoch 6/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.2618 - MAE: 1.0134 - MSE: 4.3551\n",
      "Epoch 00006: saving model to NNmodels/weights.06-1.23540.h5\n",
      "1561/1561 [==============================] - 39s 25ms/step - loss: 1.2618 - MAE: 1.0134 - MSE: 4.3551 - val_loss: 1.2354 - val_MAE: 1.0075 - val_MSE: 4.1520\n",
      "Epoch 7/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.2528 - MAE: 1.0044 - MSE: 4.2435\n",
      "Epoch 00007: saving model to NNmodels/weights.07-1.24598.h5\n",
      "1561/1561 [==============================] - 42s 27ms/step - loss: 1.2528 - MAE: 1.0044 - MSE: 4.2425 - val_loss: 1.2460 - val_MAE: 1.0237 - val_MSE: 4.8529\n",
      "Epoch 8/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.2465 - MAE: 0.9985 - MSE: 4.2181\n",
      "Epoch 00008: saving model to NNmodels/weights.08-1.22519.h5\n",
      "1561/1561 [==============================] - 48s 31ms/step - loss: 1.2466 - MAE: 0.9985 - MSE: 4.2176 - val_loss: 1.2252 - val_MAE: 0.9769 - val_MSE: 3.9918\n",
      "Epoch 9/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.2416 - MAE: 0.9932 - MSE: 4.1446\n",
      "Epoch 00009: saving model to NNmodels/weights.09-1.22491.h5\n",
      "1561/1561 [==============================] - 53s 34ms/step - loss: 1.2416 - MAE: 0.9932 - MSE: 4.1440 - val_loss: 1.2249 - val_MAE: 0.9940 - val_MSE: 4.0796\n",
      "Epoch 10/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.2360 - MAE: 0.9872 - MSE: 4.0848\n",
      "Epoch 00010: saving model to NNmodels/weights.10-1.22093.h5\n",
      "1561/1561 [==============================] - 51s 32ms/step - loss: 1.2360 - MAE: 0.9872 - MSE: 4.0848 - val_loss: 1.2209 - val_MAE: 1.0064 - val_MSE: 4.4356\n",
      "Epoch 11/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.2302 - MAE: 0.9809 - MSE: 4.0166\n",
      "Epoch 00011: saving model to NNmodels/weights.11-1.21885.h5\n",
      "1561/1561 [==============================] - 50s 32ms/step - loss: 1.2302 - MAE: 0.9809 - MSE: 4.0166 - val_loss: 1.2188 - val_MAE: 1.0032 - val_MSE: 4.3711\n",
      "Epoch 12/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.2282 - MAE: 0.9791 - MSE: 3.9967\n",
      "Epoch 00012: saving model to NNmodels/weights.12-1.20559.h5\n",
      "1561/1561 [==============================] - 49s 32ms/step - loss: 1.2282 - MAE: 0.9791 - MSE: 3.9962 - val_loss: 1.2056 - val_MAE: 0.9532 - val_MSE: 3.7505\n",
      "Epoch 13/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.2237 - MAE: 0.9741 - MSE: 3.9431\n",
      "Epoch 00013: saving model to NNmodels/weights.13-1.21517.h5\n",
      "1561/1561 [==============================] - 46s 30ms/step - loss: 1.2237 - MAE: 0.9740 - MSE: 3.9424 - val_loss: 1.2152 - val_MAE: 0.9851 - val_MSE: 3.8988\n",
      "Epoch 14/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.2212 - MAE: 0.9709 - MSE: 3.9148\n",
      "Epoch 00014: saving model to NNmodels/weights.14-1.20316.h5\n",
      "1561/1561 [==============================] - 41s 27ms/step - loss: 1.2212 - MAE: 0.9709 - MSE: 3.9142 - val_loss: 1.2032 - val_MAE: 0.9794 - val_MSE: 3.7397\n",
      "Epoch 15/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.2186 - MAE: 0.9696 - MSE: 3.9025\n",
      "Epoch 00015: saving model to NNmodels/weights.15-1.20110.h5\n",
      "1561/1561 [==============================] - 41s 26ms/step - loss: 1.2186 - MAE: 0.9696 - MSE: 3.9025 - val_loss: 1.2011 - val_MAE: 0.9720 - val_MSE: 3.7148\n",
      "Epoch 16/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.2170 - MAE: 0.9668 - MSE: 3.8827\n",
      "Epoch 00016: saving model to NNmodels/weights.16-1.19893.h5\n",
      "1561/1561 [==============================] - 45s 29ms/step - loss: 1.2170 - MAE: 0.9668 - MSE: 3.8819 - val_loss: 1.1989 - val_MAE: 0.9513 - val_MSE: 3.5929\n",
      "Epoch 17/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.2136 - MAE: 0.9634 - MSE: 3.8390\n",
      "Epoch 00017: saving model to NNmodels/weights.17-1.19546.h5\n",
      "1561/1561 [==============================] - 39s 25ms/step - loss: 1.2136 - MAE: 0.9634 - MSE: 3.8390 - val_loss: 1.1955 - val_MAE: 0.9564 - val_MSE: 3.6807\n",
      "Epoch 18/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.2110 - MAE: 0.9613 - MSE: 3.8143\n",
      "Epoch 00018: saving model to NNmodels/weights.18-1.19367.h5\n",
      "1561/1561 [==============================] - 39s 25ms/step - loss: 1.2110 - MAE: 0.9612 - MSE: 3.8135 - val_loss: 1.1937 - val_MAE: 0.9423 - val_MSE: 3.5132\n",
      "Epoch 19/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.2100 - MAE: 0.9597 - MSE: 3.8068\n",
      "Epoch 00019: saving model to NNmodels/weights.19-1.19290.h5\n",
      "1561/1561 [==============================] - 42s 27ms/step - loss: 1.2100 - MAE: 0.9597 - MSE: 3.8068 - val_loss: 1.1929 - val_MAE: 0.9451 - val_MSE: 5.7941\n",
      "Epoch 20/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.2081 - MAE: 0.9572 - MSE: 3.7900\n",
      "Epoch 00020: saving model to NNmodels/weights.20-1.21081.h5\n",
      "1561/1561 [==============================] - 43s 27ms/step - loss: 1.2081 - MAE: 0.9572 - MSE: 3.7900 - val_loss: 1.2108 - val_MAE: 0.9930 - val_MSE: 4.7656\n",
      "Epoch 21/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.2047 - MAE: 0.9543 - MSE: 3.7434\n",
      "Epoch 00021: saving model to NNmodels/weights.21-1.19166.h5\n",
      "1561/1561 [==============================] - 44s 28ms/step - loss: 1.2047 - MAE: 0.9542 - MSE: 3.7428 - val_loss: 1.1917 - val_MAE: 0.9368 - val_MSE: 3.6921\n",
      "Epoch 22/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.2028 - MAE: 0.9515 - MSE: 3.7312\n",
      "Epoch 00022: saving model to NNmodels/weights.22-1.19634.h5\n",
      "1561/1561 [==============================] - 48s 31ms/step - loss: 1.2029 - MAE: 0.9515 - MSE: 3.7302 - val_loss: 1.1963 - val_MAE: 0.9613 - val_MSE: 4.6852\n",
      "Epoch 23/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.2010 - MAE: 0.9511 - MSE: 3.7088\n",
      "Epoch 00023: saving model to NNmodels/weights.23-1.18586.h5\n",
      "1561/1561 [==============================] - 44s 28ms/step - loss: 1.2010 - MAE: 0.9510 - MSE: 3.7080 - val_loss: 1.1859 - val_MAE: 0.9471 - val_MSE: 3.5850\n",
      "Epoch 24/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1996 - MAE: 0.9490 - MSE: 3.6821\n",
      "Epoch 00024: saving model to NNmodels/weights.24-1.18523.h5\n",
      "1561/1561 [==============================] - 49s 31ms/step - loss: 1.1996 - MAE: 0.9489 - MSE: 3.6815 - val_loss: 1.1852 - val_MAE: 0.9374 - val_MSE: 3.5054\n",
      "Epoch 25/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.1991 - MAE: 0.9490 - MSE: 3.6899\n",
      "Epoch 00025: saving model to NNmodels/weights.25-1.18330.h5\n",
      "1561/1561 [==============================] - 45s 29ms/step - loss: 1.1991 - MAE: 0.9489 - MSE: 3.6888 - val_loss: 1.1833 - val_MAE: 0.9279 - val_MSE: 3.4611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1964 - MAE: 0.9460 - MSE: 3.6408\n",
      "Epoch 00026: saving model to NNmodels/weights.26-1.18203.h5\n",
      "1561/1561 [==============================] - 46s 30ms/step - loss: 1.1964 - MAE: 0.9460 - MSE: 3.6398 - val_loss: 1.1820 - val_MAE: 0.9348 - val_MSE: 3.6374\n",
      "Epoch 27/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.1983 - MAE: 0.9482 - MSE: 3.6782\n",
      "Epoch 00027: saving model to NNmodels/weights.27-1.17804.h5\n",
      "1561/1561 [==============================] - 48s 31ms/step - loss: 1.1983 - MAE: 0.9482 - MSE: 3.6782 - val_loss: 1.1780 - val_MAE: 0.9271 - val_MSE: 3.4270\n",
      "Epoch 28/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1927 - MAE: 0.9429 - MSE: 3.6251\n",
      "Epoch 00028: saving model to NNmodels/weights.28-1.18112.h5\n",
      "1561/1561 [==============================] - 46s 29ms/step - loss: 1.1927 - MAE: 0.9429 - MSE: 3.6241 - val_loss: 1.1811 - val_MAE: 0.9320 - val_MSE: 3.5991\n",
      "Epoch 29/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1903 - MAE: 0.9397 - MSE: 3.5788\n",
      "Epoch 00029: saving model to NNmodels/weights.29-1.17920.h5\n",
      "1561/1561 [==============================] - 44s 28ms/step - loss: 1.1903 - MAE: 0.9396 - MSE: 3.5781 - val_loss: 1.1792 - val_MAE: 0.9329 - val_MSE: 3.5227\n",
      "Epoch 30/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1889 - MAE: 0.9391 - MSE: 3.5741\n",
      "Epoch 00030: saving model to NNmodels/weights.30-1.17521.h5\n",
      "1561/1561 [==============================] - 45s 29ms/step - loss: 1.1889 - MAE: 0.9390 - MSE: 3.5732 - val_loss: 1.1752 - val_MAE: 0.9301 - val_MSE: 3.3599\n",
      "Epoch 31/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1888 - MAE: 0.9380 - MSE: 3.5723\n",
      "Epoch 00031: saving model to NNmodels/weights.31-1.18089.h5\n",
      "1561/1561 [==============================] - 45s 29ms/step - loss: 1.1887 - MAE: 0.9379 - MSE: 3.5715 - val_loss: 1.1809 - val_MAE: 0.9184 - val_MSE: 3.5220\n",
      "Epoch 32/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1868 - MAE: 0.9365 - MSE: 3.5485\n",
      "Epoch 00032: saving model to NNmodels/weights.32-1.17423.h5\n",
      "1561/1561 [==============================] - 43s 27ms/step - loss: 1.1868 - MAE: 0.9364 - MSE: 3.5476 - val_loss: 1.1742 - val_MAE: 0.9278 - val_MSE: 3.3060\n",
      "Epoch 33/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.1851 - MAE: 0.9347 - MSE: 3.5362\n",
      "Epoch 00033: saving model to NNmodels/weights.33-1.17424.h5\n",
      "1561/1561 [==============================] - 47s 30ms/step - loss: 1.1851 - MAE: 0.9347 - MSE: 3.5362 - val_loss: 1.1742 - val_MAE: 0.9232 - val_MSE: 3.3951\n",
      "Epoch 34/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1843 - MAE: 0.9348 - MSE: 3.5418\n",
      "Epoch 00034: saving model to NNmodels/weights.34-1.17592.h5\n",
      "1561/1561 [==============================] - 46s 29ms/step - loss: 1.1843 - MAE: 0.9347 - MSE: 3.5409 - val_loss: 1.1759 - val_MAE: 0.9337 - val_MSE: 3.5132\n",
      "Epoch 35/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1830 - MAE: 0.9325 - MSE: 3.5088\n",
      "Epoch 00035: saving model to NNmodels/weights.35-1.17494.h5\n",
      "1561/1561 [==============================] - 45s 29ms/step - loss: 1.1830 - MAE: 0.9325 - MSE: 3.5081 - val_loss: 1.1749 - val_MAE: 0.9132 - val_MSE: 3.4246\n",
      "Epoch 36/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.1807 - MAE: 0.9298 - MSE: 3.4852\n",
      "Epoch 00036: saving model to NNmodels/weights.36-1.17684.h5\n",
      "1561/1561 [==============================] - 44s 28ms/step - loss: 1.1807 - MAE: 0.9298 - MSE: 3.4852 - val_loss: 1.1768 - val_MAE: 0.9318 - val_MSE: 3.7929\n",
      "Epoch 37/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.1797 - MAE: 0.9302 - MSE: 3.4666\n",
      "Epoch 00037: saving model to NNmodels/weights.37-1.17122.h5\n",
      "1561/1561 [==============================] - 48s 31ms/step - loss: 1.1797 - MAE: 0.9302 - MSE: 3.4666 - val_loss: 1.1712 - val_MAE: 0.9185 - val_MSE: 3.3002\n",
      "Epoch 38/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.1815 - MAE: 0.9320 - MSE: 3.5150\n",
      "Epoch 00038: saving model to NNmodels/weights.38-1.37541.h5\n",
      "1561/1561 [==============================] - 51s 33ms/step - loss: 1.1816 - MAE: 0.9320 - MSE: 3.5140 - val_loss: 1.3754 - val_MAE: 1.1328 - val_MSE: 2337.8855\n",
      "Epoch 39/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1782 - MAE: 0.9275 - MSE: 3.4726\n",
      "Epoch 00039: saving model to NNmodels/weights.39-1.16970.h5\n",
      "1561/1561 [==============================] - 49s 31ms/step - loss: 1.1782 - MAE: 0.9275 - MSE: 3.4718 - val_loss: 1.1697 - val_MAE: 0.9206 - val_MSE: 3.4199\n",
      "Epoch 40/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.1776 - MAE: 0.9275 - MSE: 3.4604\n",
      "Epoch 00040: saving model to NNmodels/weights.40-1.17446.h5\n",
      "1561/1561 [==============================] - 49s 31ms/step - loss: 1.1776 - MAE: 0.9275 - MSE: 3.4604 - val_loss: 1.1745 - val_MAE: 0.9209 - val_MSE: 4.2218\n",
      "Epoch 41/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1756 - MAE: 0.9253 - MSE: 3.4345\n",
      "Epoch 00041: saving model to NNmodels/weights.41-1.16892.h5\n",
      "1561/1561 [==============================] - 47s 30ms/step - loss: 1.1756 - MAE: 0.9252 - MSE: 3.4339 - val_loss: 1.1689 - val_MAE: 0.9194 - val_MSE: 3.2403\n",
      "Epoch 42/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.1755 - MAE: 0.9259 - MSE: 3.4425\n",
      "Epoch 00042: saving model to NNmodels/weights.42-24.00210.h5\n",
      "1561/1561 [==============================] - 55s 35ms/step - loss: 1.1755 - MAE: 0.9259 - MSE: 3.4425 - val_loss: 24.0021 - val_MAE: 23.7475 - val_MSE: 30383502.0000\n",
      "Epoch 43/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1736 - MAE: 0.9235 - MSE: 3.4178\n",
      "Epoch 00043: saving model to NNmodels/weights.43-1.17703.h5\n",
      "1561/1561 [==============================] - 53s 34ms/step - loss: 1.1736 - MAE: 0.9235 - MSE: 3.4170 - val_loss: 1.1770 - val_MAE: 0.9257 - val_MSE: 12.6809\n",
      "Epoch 44/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1717 - MAE: 0.9221 - MSE: 3.4004\n",
      "Epoch 00044: saving model to NNmodels/weights.44-76.85283.h5\n",
      "1561/1561 [==============================] - 53s 34ms/step - loss: 1.1717 - MAE: 0.9221 - MSE: 3.3997 - val_loss: 76.8528 - val_MAE: 76.5990 - val_MSE: 335008704.0000\n",
      "Epoch 45/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1722 - MAE: 0.9220 - MSE: 3.4093\n",
      "Epoch 00045: saving model to NNmodels/weights.45-1.18546.h5\n",
      "1561/1561 [==============================] - 66s 42ms/step - loss: 1.1722 - MAE: 0.9220 - MSE: 3.4086 - val_loss: 1.1855 - val_MAE: 0.9207 - val_MSE: 12.8048\n",
      "Epoch 46/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.1710 - MAE: 0.9200 - MSE: 3.3671\n",
      "Epoch 00046: saving model to NNmodels/weights.46-1.75919.h5\n",
      "1561/1561 [==============================] - 54s 34ms/step - loss: 1.1710 - MAE: 0.9200 - MSE: 3.3663 - val_loss: 1.7592 - val_MAE: 1.5013 - val_MSE: 18135.0938\n",
      "Epoch 47/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1697 - MAE: 0.9197 - MSE: 3.3749\n",
      "Epoch 00047: saving model to NNmodels/weights.47-1.17081.h5\n",
      "1561/1561 [==============================] - 48s 31ms/step - loss: 1.1697 - MAE: 0.9197 - MSE: 3.3742 - val_loss: 1.1708 - val_MAE: 0.9115 - val_MSE: 3.5572\n",
      "Epoch 48/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.1719 - MAE: 0.9220 - MSE: 3.4216\n",
      "Epoch 00048: saving model to NNmodels/weights.48-1.17106.h5\n",
      "1561/1561 [==============================] - 41s 26ms/step - loss: 1.1720 - MAE: 0.9220 - MSE: 3.4204 - val_loss: 1.1711 - val_MAE: 0.9187 - val_MSE: 3.5711\n",
      "Epoch 49/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.1669 - MAE: 0.9170 - MSE: 3.3552\n",
      "Epoch 00049: saving model to NNmodels/weights.49-1.16344.h5\n",
      "1561/1561 [==============================] - 41s 26ms/step - loss: 1.1669 - MAE: 0.9169 - MSE: 3.3542 - val_loss: 1.1634 - val_MAE: 0.9173 - val_MSE: 3.3713\n",
      "Epoch 50/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1684 - MAE: 0.9184 - MSE: 3.3694\n",
      "Epoch 00050: saving model to NNmodels/weights.50-1.17750.h5\n",
      "1561/1561 [==============================] - 45s 29ms/step - loss: 1.1684 - MAE: 0.9184 - MSE: 3.3688 - val_loss: 1.1775 - val_MAE: 0.9141 - val_MSE: 6.4153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1660 - MAE: 0.9153 - MSE: 3.3199\n",
      "Epoch 00051: saving model to NNmodels/weights.51-1.17022.h5\n",
      "1561/1561 [==============================] - 44s 28ms/step - loss: 1.1660 - MAE: 0.9152 - MSE: 3.3193 - val_loss: 1.1702 - val_MAE: 0.9144 - val_MSE: 3.7847\n",
      "Epoch 52/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.1674 - MAE: 0.9166 - MSE: 3.3596\n",
      "Epoch 00052: saving model to NNmodels/weights.52-1.17453.h5\n",
      "1561/1561 [==============================] - 44s 28ms/step - loss: 1.1674 - MAE: 0.9166 - MSE: 3.3586 - val_loss: 1.1745 - val_MAE: 0.9158 - val_MSE: 4.9765\n",
      "Epoch 53/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.1641 - MAE: 0.9144 - MSE: 3.3268\n",
      "Epoch 00053: saving model to NNmodels/weights.53-1.17729.h5\n",
      "1561/1561 [==============================] - 44s 28ms/step - loss: 1.1641 - MAE: 0.9144 - MSE: 3.3268 - val_loss: 1.1773 - val_MAE: 0.9196 - val_MSE: 5.7984\n",
      "Epoch 54/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.1631 - MAE: 0.9126 - MSE: 3.3214\n",
      "Epoch 00054: saving model to NNmodels/weights.54-1.17030.h5\n",
      "1561/1561 [==============================] - 48s 31ms/step - loss: 1.1631 - MAE: 0.9126 - MSE: 3.3214 - val_loss: 1.1703 - val_MAE: 0.9066 - val_MSE: 3.3806\n",
      "Epoch 55/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.1633 - MAE: 0.9124 - MSE: 3.3211\n",
      "Epoch 00055: saving model to NNmodels/weights.55-1.16896.h5\n",
      "1561/1561 [==============================] - 47s 30ms/step - loss: 1.1633 - MAE: 0.9124 - MSE: 3.3211 - val_loss: 1.1690 - val_MAE: 0.9160 - val_MSE: 3.8891\n",
      "Epoch 56/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.1612 - MAE: 0.9104 - MSE: 3.2783\n",
      "Epoch 00056: saving model to NNmodels/weights.56-1.16821.h5\n",
      "1561/1561 [==============================] - 44s 28ms/step - loss: 1.1612 - MAE: 0.9103 - MSE: 3.2771 - val_loss: 1.1682 - val_MAE: 0.9092 - val_MSE: 3.3565\n",
      "Epoch 57/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1617 - MAE: 0.9119 - MSE: 3.3008\n",
      "Epoch 00057: saving model to NNmodels/weights.57-1.17338.h5\n",
      "1561/1561 [==============================] - 45s 29ms/step - loss: 1.1617 - MAE: 0.9118 - MSE: 3.3001 - val_loss: 1.1734 - val_MAE: 0.9155 - val_MSE: 4.8149\n",
      "Epoch 58/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.1592 - MAE: 0.9099 - MSE: 3.2789\n",
      "Epoch 00058: saving model to NNmodels/weights.58-1.16922.h5\n",
      "1561/1561 [==============================] - 44s 28ms/step - loss: 1.1592 - MAE: 0.9099 - MSE: 3.2780 - val_loss: 1.1692 - val_MAE: 0.9091 - val_MSE: 3.5013\n",
      "Epoch 59/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1601 - MAE: 0.9110 - MSE: 3.3014\n",
      "Epoch 00059: saving model to NNmodels/weights.59-1.17014.h5\n",
      "1561/1561 [==============================] - 44s 28ms/step - loss: 1.1601 - MAE: 0.9110 - MSE: 3.3009 - val_loss: 1.1701 - val_MAE: 0.9125 - val_MSE: 4.3440\n",
      "Epoch 60/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.1594 - MAE: 0.9092 - MSE: 3.2823\n",
      "Epoch 00060: saving model to NNmodels/weights.60-1.17807.h5\n",
      "1561/1561 [==============================] - 44s 28ms/step - loss: 1.1594 - MAE: 0.9092 - MSE: 3.2816 - val_loss: 1.1781 - val_MAE: 0.9127 - val_MSE: 5.2586\n",
      "Epoch 61/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.1581 - MAE: 0.9073 - MSE: 3.2397\n",
      "Epoch 00061: saving model to NNmodels/weights.61-1.16515.h5\n",
      "1561/1561 [==============================] - 45s 29ms/step - loss: 1.1581 - MAE: 0.9073 - MSE: 3.2397 - val_loss: 1.1652 - val_MAE: 0.9119 - val_MSE: 3.4391\n",
      "Epoch 62/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1567 - MAE: 0.9065 - MSE: 3.2421\n",
      "Epoch 00062: saving model to NNmodels/weights.62-1.16806.h5\n",
      "1561/1561 [==============================] - 44s 28ms/step - loss: 1.1567 - MAE: 0.9065 - MSE: 3.2415 - val_loss: 1.1681 - val_MAE: 0.9089 - val_MSE: 3.9279\n",
      "Epoch 63/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1557 - MAE: 0.9054 - MSE: 3.2481\n",
      "Epoch 00063: saving model to NNmodels/weights.63-1.16336.h5\n",
      "1561/1561 [==============================] - 43s 27ms/step - loss: 1.1557 - MAE: 0.9054 - MSE: 3.2475 - val_loss: 1.1634 - val_MAE: 0.9102 - val_MSE: 3.2223\n",
      "Epoch 64/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1548 - MAE: 0.9046 - MSE: 3.2272\n",
      "Epoch 00064: saving model to NNmodels/weights.64-1.17025.h5\n",
      "1561/1561 [==============================] - 44s 28ms/step - loss: 1.1548 - MAE: 0.9045 - MSE: 3.2266 - val_loss: 1.1703 - val_MAE: 0.9123 - val_MSE: 4.9255\n",
      "Epoch 65/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1560 - MAE: 0.9058 - MSE: 3.2489\n",
      "Epoch 00065: saving model to NNmodels/weights.65-1.16701.h5\n",
      "1561/1561 [==============================] - 44s 28ms/step - loss: 1.1560 - MAE: 0.9058 - MSE: 3.2482 - val_loss: 1.1670 - val_MAE: 0.8969 - val_MSE: 3.4153\n",
      "Epoch 66/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1536 - MAE: 0.9033 - MSE: 3.2191\n",
      "Epoch 00066: saving model to NNmodels/weights.66-1.16348.h5\n",
      "1561/1561 [==============================] - 44s 28ms/step - loss: 1.1536 - MAE: 0.9032 - MSE: 3.2185 - val_loss: 1.1635 - val_MAE: 0.9028 - val_MSE: 3.4233\n",
      "Epoch 67/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1523 - MAE: 0.9017 - MSE: 3.2070\n",
      "Epoch 00067: saving model to NNmodels/weights.67-1.16674.h5\n",
      "1561/1561 [==============================] - 44s 28ms/step - loss: 1.1523 - MAE: 0.9017 - MSE: 3.2064 - val_loss: 1.1667 - val_MAE: 0.9064 - val_MSE: 3.3574\n",
      "Epoch 68/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.1521 - MAE: 0.9017 - MSE: 3.2032\n",
      "Epoch 00068: saving model to NNmodels/weights.68-1.17694.h5\n",
      "1561/1561 [==============================] - 44s 28ms/step - loss: 1.1522 - MAE: 0.9016 - MSE: 3.2021 - val_loss: 1.1769 - val_MAE: 0.9102 - val_MSE: 6.4723\n",
      "Epoch 69/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1512 - MAE: 0.9005 - MSE: 3.1895\n",
      "Epoch 00069: saving model to NNmodels/weights.69-1.16911.h5\n",
      "1561/1561 [==============================] - 45s 29ms/step - loss: 1.1511 - MAE: 0.9004 - MSE: 3.1887 - val_loss: 1.1691 - val_MAE: 0.9063 - val_MSE: 4.1092\n",
      "Epoch 70/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1520 - MAE: 0.9019 - MSE: 3.2067\n",
      "Epoch 00070: saving model to NNmodels/weights.70-1.17066.h5\n",
      "1561/1561 [==============================] - 43s 28ms/step - loss: 1.1520 - MAE: 0.9019 - MSE: 3.2062 - val_loss: 1.1707 - val_MAE: 0.9106 - val_MSE: 4.1512\n",
      "Epoch 71/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.1500 - MAE: 0.8997 - MSE: 3.1929\n",
      "Epoch 00071: saving model to NNmodels/weights.71-1.16356.h5\n",
      "1561/1561 [==============================] - 43s 28ms/step - loss: 1.1500 - MAE: 0.8997 - MSE: 3.1920 - val_loss: 1.1636 - val_MAE: 0.9003 - val_MSE: 3.3442\n",
      "Epoch 72/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.1503 - MAE: 0.9006 - MSE: 3.1900\n",
      "Epoch 00072: saving model to NNmodels/weights.72-1.17038.h5\n",
      "1561/1561 [==============================] - 43s 28ms/step - loss: 1.1503 - MAE: 0.9006 - MSE: 3.1889 - val_loss: 1.1704 - val_MAE: 0.9001 - val_MSE: 3.7983\n",
      "Epoch 73/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1504 - MAE: 0.9008 - MSE: 3.2033\n",
      "Epoch 00073: saving model to NNmodels/weights.73-1.16860.h5\n",
      "1561/1561 [==============================] - 44s 28ms/step - loss: 1.1504 - MAE: 0.9008 - MSE: 3.2027 - val_loss: 1.1686 - val_MAE: 0.8957 - val_MSE: 3.4056\n",
      "Epoch 74/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.1481 - MAE: 0.8980 - MSE: 3.1606\n",
      "Epoch 00074: saving model to NNmodels/weights.74-1.16643.h5\n",
      "1561/1561 [==============================] - 43s 28ms/step - loss: 1.1481 - MAE: 0.8980 - MSE: 3.1606 - val_loss: 1.1664 - val_MAE: 0.9005 - val_MSE: 4.0275\n",
      "Epoch 75/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1478 - MAE: 0.8983 - MSE: 3.1667\n",
      "Epoch 00075: saving model to NNmodels/weights.75-1.16398.h5\n",
      "1561/1561 [==============================] - 46s 29ms/step - loss: 1.1478 - MAE: 0.8982 - MSE: 3.1661 - val_loss: 1.1640 - val_MAE: 0.9032 - val_MSE: 3.6096\n",
      "Epoch 76/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.1466 - MAE: 0.8966 - MSE: 3.1528\n",
      "Epoch 00076: saving model to NNmodels/weights.76-1.16438.h5\n",
      "1561/1561 [==============================] - 42s 27ms/step - loss: 1.1466 - MAE: 0.8966 - MSE: 3.1528 - val_loss: 1.1644 - val_MAE: 0.8935 - val_MSE: 3.4932\n",
      "Epoch 77/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.1493 - MAE: 0.8993 - MSE: 3.1679\n",
      "Epoch 00077: saving model to NNmodels/weights.77-1.16105.h5\n",
      "1561/1561 [==============================] - 41s 26ms/step - loss: 1.1493 - MAE: 0.8992 - MSE: 3.1669 - val_loss: 1.1610 - val_MAE: 0.8968 - val_MSE: 3.1630\n",
      "Epoch 78/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.1441 - MAE: 0.8937 - MSE: 3.1084\n",
      "Epoch 00078: saving model to NNmodels/weights.78-1.16573.h5\n",
      "1561/1561 [==============================] - 44s 28ms/step - loss: 1.1441 - MAE: 0.8937 - MSE: 3.1082 - val_loss: 1.1657 - val_MAE: 0.8981 - val_MSE: 3.5347\n",
      "Epoch 79/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1461 - MAE: 0.8954 - MSE: 3.1332\n",
      "Epoch 00079: saving model to NNmodels/weights.79-1.16480.h5\n",
      "1561/1561 [==============================] - 43s 28ms/step - loss: 1.1461 - MAE: 0.8953 - MSE: 3.1328 - val_loss: 1.1648 - val_MAE: 0.9025 - val_MSE: 3.9528\n",
      "Epoch 80/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1453 - MAE: 0.8948 - MSE: 3.1357\n",
      "Epoch 00080: saving model to NNmodels/weights.80-1.16838.h5\n",
      "1561/1561 [==============================] - 44s 28ms/step - loss: 1.1453 - MAE: 0.8948 - MSE: 3.1353 - val_loss: 1.1684 - val_MAE: 0.8986 - val_MSE: 3.9516\n",
      "Epoch 81/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1423 - MAE: 0.8923 - MSE: 3.0979\n",
      "Epoch 00081: saving model to NNmodels/weights.81-1.16751.h5\n",
      "1561/1561 [==============================] - 44s 28ms/step - loss: 1.1423 - MAE: 0.8923 - MSE: 3.0972 - val_loss: 1.1675 - val_MAE: 0.9140 - val_MSE: 4.2911\n",
      "Epoch 82/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.1440 - MAE: 0.8943 - MSE: 3.1395\n",
      "Epoch 00082: saving model to NNmodels/weights.82-1.16646.h5\n",
      "1561/1561 [==============================] - 50s 32ms/step - loss: 1.1440 - MAE: 0.8943 - MSE: 3.1395 - val_loss: 1.1665 - val_MAE: 0.9009 - val_MSE: 3.4002\n",
      "Epoch 83/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1404 - MAE: 0.8898 - MSE: 3.0637\n",
      "Epoch 00083: saving model to NNmodels/weights.83-1.16955.h5\n",
      "1561/1561 [==============================] - 48s 31ms/step - loss: 1.1404 - MAE: 0.8897 - MSE: 3.0630 - val_loss: 1.1696 - val_MAE: 0.9007 - val_MSE: 3.7075\n",
      "Epoch 84/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1407 - MAE: 0.8897 - MSE: 3.0701\n",
      "Epoch 00084: saving model to NNmodels/weights.84-1.16292.h5\n",
      "1561/1561 [==============================] - 49s 31ms/step - loss: 1.1407 - MAE: 0.8896 - MSE: 3.0694 - val_loss: 1.1629 - val_MAE: 0.9010 - val_MSE: 3.3115\n",
      "Epoch 85/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.1409 - MAE: 0.8906 - MSE: 3.0915- ETA: 0s - loss: 1.1408 - MAE: 0.8907 - \n",
      "Epoch 00085: saving model to NNmodels/weights.85-1.15921.h5\n",
      "1561/1561 [==============================] - 49s 32ms/step - loss: 1.1409 - MAE: 0.8906 - MSE: 3.0915 - val_loss: 1.1592 - val_MAE: 0.8971 - val_MSE: 3.1288\n",
      "Epoch 86/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1397 - MAE: 0.8893 - MSE: 3.0905\n",
      "Epoch 00086: saving model to NNmodels/weights.86-1.16376.h5\n",
      "1561/1561 [==============================] - 49s 31ms/step - loss: 1.1397 - MAE: 0.8893 - MSE: 3.0899 - val_loss: 1.1638 - val_MAE: 0.8917 - val_MSE: 3.2038\n",
      "Epoch 87/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.1388 - MAE: 0.8884 - MSE: 3.0564\n",
      "Epoch 00087: saving model to NNmodels/weights.87-1.16446.h5\n",
      "1561/1561 [==============================] - 48s 31ms/step - loss: 1.1388 - MAE: 0.8884 - MSE: 3.0564 - val_loss: 1.1645 - val_MAE: 0.8967 - val_MSE: 3.3797\n",
      "Epoch 88/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1390 - MAE: 0.8880 - MSE: 3.0502\n",
      "Epoch 00088: saving model to NNmodels/weights.88-1.16122.h5\n",
      "1561/1561 [==============================] - 49s 32ms/step - loss: 1.1390 - MAE: 0.8879 - MSE: 3.0495 - val_loss: 1.1612 - val_MAE: 0.8979 - val_MSE: 3.3301\n",
      "Epoch 89/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1376 - MAE: 0.8873 - MSE: 3.0560\n",
      "Epoch 00089: saving model to NNmodels/weights.89-1.16351.h5\n",
      "1561/1561 [==============================] - 48s 31ms/step - loss: 1.1376 - MAE: 0.8872 - MSE: 3.0554 - val_loss: 1.1635 - val_MAE: 0.8882 - val_MSE: 3.1386\n",
      "Epoch 90/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.1378 - MAE: 0.8868 - MSE: 3.0669\n",
      "Epoch 00090: saving model to NNmodels/weights.90-1.16579.h5\n",
      "1561/1561 [==============================] - 48s 31ms/step - loss: 1.1378 - MAE: 0.8868 - MSE: 3.0669 - val_loss: 1.1658 - val_MAE: 0.9059 - val_MSE: 4.9401\n",
      "Epoch 91/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1367 - MAE: 0.8872 - MSE: 3.0271\n",
      "Epoch 00091: saving model to NNmodels/weights.91-1.17091.h5\n",
      "1561/1561 [==============================] - 48s 31ms/step - loss: 1.1367 - MAE: 0.8871 - MSE: 3.0264 - val_loss: 1.1709 - val_MAE: 0.8984 - val_MSE: 3.8281\n",
      "Epoch 92/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1356 - MAE: 0.8853 - MSE: 3.0223\n",
      "Epoch 00092: saving model to NNmodels/weights.92-1.16814.h5\n",
      "1561/1561 [==============================] - 49s 31ms/step - loss: 1.1356 - MAE: 0.8852 - MSE: 3.0217 - val_loss: 1.1681 - val_MAE: 0.9039 - val_MSE: 5.6431\n",
      "Epoch 93/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.1337 - MAE: 0.8837 - MSE: 2.9858\n",
      "Epoch 00093: saving model to NNmodels/weights.93-1.17664.h5\n",
      "1561/1561 [==============================] - 49s 31ms/step - loss: 1.1337 - MAE: 0.8837 - MSE: 2.9858 - val_loss: 1.1766 - val_MAE: 0.9130 - val_MSE: 12.3494\n",
      "Epoch 94/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.1359 - MAE: 0.8848 - MSE: 2.9893\n",
      "Epoch 00094: saving model to NNmodels/weights.94-1.16934.h5\n",
      "1561/1561 [==============================] - 49s 31ms/step - loss: 1.1359 - MAE: 0.8848 - MSE: 2.9893 - val_loss: 1.1693 - val_MAE: 0.8944 - val_MSE: 4.6747\n",
      "Epoch 95/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.1344 - MAE: 0.8831 - MSE: 3.0154\n",
      "Epoch 00095: saving model to NNmodels/weights.95-1.16639.h5\n",
      "1561/1561 [==============================] - 48s 31ms/step - loss: 1.1344 - MAE: 0.8831 - MSE: 3.0154 - val_loss: 1.1664 - val_MAE: 0.9048 - val_MSE: 4.6506\n",
      "Epoch 96/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.1359 - MAE: 0.8851 - MSE: 2.9866\n",
      "Epoch 00096: saving model to NNmodels/weights.96-1.16836.h5\n",
      "1561/1561 [==============================] - 48s 31ms/step - loss: 1.1359 - MAE: 0.8851 - MSE: 2.9866 - val_loss: 1.1684 - val_MAE: 0.9004 - val_MSE: 4.5241\n",
      "Epoch 97/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.1335 - MAE: 0.8830 - MSE: 3.0084\n",
      "Epoch 00097: saving model to NNmodels/weights.97-1.16406.h5\n",
      "1561/1561 [==============================] - 48s 31ms/step - loss: 1.1335 - MAE: 0.8830 - MSE: 3.0084 - val_loss: 1.1641 - val_MAE: 0.8945 - val_MSE: 3.4152\n",
      "Epoch 98/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1309 - MAE: 0.8802 - MSE: 2.9328\n",
      "Epoch 00098: saving model to NNmodels/weights.98-1.17219.h5\n",
      "1561/1561 [==============================] - 48s 31ms/step - loss: 1.1309 - MAE: 0.8801 - MSE: 2.9322 - val_loss: 1.1722 - val_MAE: 0.8861 - val_MSE: 3.6119\n",
      "Epoch 99/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1308 - MAE: 0.8796 - MSE: 2.9556\n",
      "Epoch 00099: saving model to NNmodels/weights.99-1.16237.h5\n",
      "1561/1561 [==============================] - 48s 31ms/step - loss: 1.1308 - MAE: 0.8796 - MSE: 2.9550 - val_loss: 1.1624 - val_MAE: 0.8914 - val_MSE: 3.2990\n",
      "Epoch 100/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.1319 - MAE: 0.8813 - MSE: 2.9843\n",
      "Epoch 00100: saving model to NNmodels/weights.100-1.16202.h5\n",
      "1561/1561 [==============================] - 48s 31ms/step - loss: 1.1319 - MAE: 0.8813 - MSE: 2.9843 - val_loss: 1.1620 - val_MAE: 0.8936 - val_MSE: 3.2672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.1296 - MAE: 0.8788 - MSE: 2.9230\n",
      "Epoch 00101: saving model to NNmodels/weights.101-1.17078.h5\n",
      "1561/1561 [==============================] - 43s 28ms/step - loss: 1.1296 - MAE: 0.8789 - MSE: 2.9230 - val_loss: 1.1708 - val_MAE: 0.9002 - val_MSE: 6.4221\n",
      "Epoch 102/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1294 - MAE: 0.8793 - MSE: 2.9596\n",
      "Epoch 00102: saving model to NNmodels/weights.102-1.16712.h5\n",
      "1561/1561 [==============================] - 43s 28ms/step - loss: 1.1294 - MAE: 0.8792 - MSE: 2.9590 - val_loss: 1.1671 - val_MAE: 0.8962 - val_MSE: 3.8229\n",
      "Epoch 103/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.1297 - MAE: 0.8791 - MSE: 2.9640\n",
      "Epoch 00103: saving model to NNmodels/weights.103-1.18320.h5\n",
      "1561/1561 [==============================] - 43s 27ms/step - loss: 1.1297 - MAE: 0.8791 - MSE: 2.9633 - val_loss: 1.1832 - val_MAE: 0.9052 - val_MSE: 9.5054\n",
      "Epoch 104/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.1275 - MAE: 0.8779 - MSE: 2.9453\n",
      "Epoch 00104: saving model to NNmodels/weights.104-1.17241.h5\n",
      "1561/1561 [==============================] - 43s 27ms/step - loss: 1.1275 - MAE: 0.8779 - MSE: 2.9448 - val_loss: 1.1724 - val_MAE: 0.9049 - val_MSE: 6.1753\n",
      "Epoch 105/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.1278 - MAE: 0.8774 - MSE: 2.9255\n",
      "Epoch 00105: saving model to NNmodels/weights.105-1.17151.h5\n",
      "1561/1561 [==============================] - 43s 27ms/step - loss: 1.1278 - MAE: 0.8774 - MSE: 2.9255 - val_loss: 1.1715 - val_MAE: 0.8984 - val_MSE: 5.1578\n",
      "Epoch 106/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1270 - MAE: 0.8768 - MSE: 2.9009\n",
      "Epoch 00106: saving model to NNmodels/weights.106-1.17257.h5\n",
      "1561/1561 [==============================] - 42s 27ms/step - loss: 1.1270 - MAE: 0.8767 - MSE: 2.9004 - val_loss: 1.1726 - val_MAE: 0.9080 - val_MSE: 6.4679\n",
      "Epoch 107/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1262 - MAE: 0.8762 - MSE: 2.8930\n",
      "Epoch 00107: saving model to NNmodels/weights.107-1.17450.h5\n",
      "1561/1561 [==============================] - 43s 27ms/step - loss: 1.1262 - MAE: 0.8761 - MSE: 2.8925 - val_loss: 1.1745 - val_MAE: 0.8966 - val_MSE: 5.4227\n",
      "Epoch 108/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.1253 - MAE: 0.8746 - MSE: 2.8818\n",
      "Epoch 00108: saving model to NNmodels/weights.108-1.18271.h5\n",
      "1561/1561 [==============================] - 38s 24ms/step - loss: 1.1253 - MAE: 0.8746 - MSE: 2.8818 - val_loss: 1.1827 - val_MAE: 0.9090 - val_MSE: 9.7272\n",
      "Epoch 109/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1249 - MAE: 0.8739 - MSE: 2.8855\n",
      "Epoch 00109: saving model to NNmodels/weights.109-1.16943.h5\n",
      "1561/1561 [==============================] - 37s 24ms/step - loss: 1.1249 - MAE: 0.8739 - MSE: 2.8854 - val_loss: 1.1694 - val_MAE: 0.8956 - val_MSE: 4.0130\n",
      "Epoch 110/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1249 - MAE: 0.8735 - MSE: 2.8882\n",
      "Epoch 00110: saving model to NNmodels/weights.110-1.16458.h5\n",
      "1561/1561 [==============================] - 37s 24ms/step - loss: 1.1249 - MAE: 0.8735 - MSE: 2.8878 - val_loss: 1.1646 - val_MAE: 0.8991 - val_MSE: 3.8239\n",
      "Epoch 111/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.1240 - MAE: 0.8731 - MSE: 2.8759\n",
      "Epoch 00111: saving model to NNmodels/weights.111-1.17008.h5\n",
      "1561/1561 [==============================] - 37s 24ms/step - loss: 1.1241 - MAE: 0.8731 - MSE: 2.8757 - val_loss: 1.1701 - val_MAE: 0.8967 - val_MSE: 4.6671\n",
      "Epoch 112/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.1223 - MAE: 0.8714 - MSE: 2.8709\n",
      "Epoch 00112: saving model to NNmodels/weights.112-1.16659.h5\n",
      "1561/1561 [==============================] - 38s 24ms/step - loss: 1.1223 - MAE: 0.8714 - MSE: 2.8709 - val_loss: 1.1666 - val_MAE: 0.9010 - val_MSE: 4.6464\n",
      "Epoch 113/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.1224 - MAE: 0.8724 - MSE: 2.8594\n",
      "Epoch 00113: saving model to NNmodels/weights.113-1.17688.h5\n",
      "1561/1561 [==============================] - 38s 24ms/step - loss: 1.1224 - MAE: 0.8724 - MSE: 2.8594 - val_loss: 1.1769 - val_MAE: 0.8998 - val_MSE: 6.0060\n",
      "Epoch 114/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.1224 - MAE: 0.8719 - MSE: 2.8636\n",
      "Epoch 00114: saving model to NNmodels/weights.114-1.17327.h5\n",
      "1561/1561 [==============================] - 37s 24ms/step - loss: 1.1224 - MAE: 0.8719 - MSE: 2.8636 - val_loss: 1.1733 - val_MAE: 0.9013 - val_MSE: 6.7807\n",
      "Epoch 115/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1280 - MAE: 0.8793 - MSE: 2.9499\n",
      "Epoch 00115: saving model to NNmodels/weights.115-1.15872.h5\n",
      "1561/1561 [==============================] - 38s 24ms/step - loss: 1.1280 - MAE: 0.8792 - MSE: 2.9494 - val_loss: 1.1587 - val_MAE: 0.8926 - val_MSE: 3.1431\n",
      "Epoch 116/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.1210 - MAE: 0.8701 - MSE: 2.8577\n",
      "Epoch 00116: saving model to NNmodels/weights.116-1.25232.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.1211 - MAE: 0.8702 - MSE: 2.8574 - val_loss: 1.2523 - val_MAE: 0.9804 - val_MSE: 353.4539\n",
      "Epoch 117/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.1204 - MAE: 0.8703 - MSE: 2.8469\n",
      "Epoch 00117: saving model to NNmodels/weights.117-1.19122.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.1204 - MAE: 0.8703 - MSE: 2.8469 - val_loss: 1.1912 - val_MAE: 0.9126 - val_MSE: 19.6494\n",
      "Epoch 118/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.1195 - MAE: 0.8683 - MSE: 2.8120\n",
      "Epoch 00118: saving model to NNmodels/weights.118-1.18554.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.1195 - MAE: 0.8683 - MSE: 2.8118 - val_loss: 1.1855 - val_MAE: 0.9098 - val_MSE: 13.8837\n",
      "Epoch 119/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1195 - MAE: 0.8684 - MSE: 2.8182\n",
      "Epoch 00119: saving model to NNmodels/weights.119-1.17455.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.1195 - MAE: 0.8684 - MSE: 2.8179 - val_loss: 1.1745 - val_MAE: 0.8977 - val_MSE: 5.3570\n",
      "Epoch 120/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1195 - MAE: 0.8693 - MSE: 2.8382\n",
      "Epoch 00120: saving model to NNmodels/weights.120-1.20825.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.1195 - MAE: 0.8693 - MSE: 2.8377 - val_loss: 1.2083 - val_MAE: 0.9215 - val_MSE: 53.3192\n",
      "Epoch 121/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.1185 - MAE: 0.8679 - MSE: 2.8140\n",
      "Epoch 00121: saving model to NNmodels/weights.121-1.18067.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.1185 - MAE: 0.8679 - MSE: 2.8140 - val_loss: 1.1807 - val_MAE: 0.8995 - val_MSE: 9.7334\n",
      "Epoch 122/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.1216 - MAE: 0.8716 - MSE: 2.8641\n",
      "Epoch 00122: saving model to NNmodels/weights.122-1.17908.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.1216 - MAE: 0.8716 - MSE: 2.8641 - val_loss: 1.1791 - val_MAE: 0.8985 - val_MSE: 6.8145\n",
      "Epoch 123/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1187 - MAE: 0.8684 - MSE: 2.8668\n",
      "Epoch 00123: saving model to NNmodels/weights.123-1.18227.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.1187 - MAE: 0.8683 - MSE: 2.8661 - val_loss: 1.1823 - val_MAE: 0.9085 - val_MSE: 12.2807\n",
      "Epoch 124/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.1172 - MAE: 0.8659 - MSE: 2.8015\n",
      "Epoch 00124: saving model to NNmodels/weights.124-1.17502.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.1172 - MAE: 0.8659 - MSE: 2.8017 - val_loss: 1.1750 - val_MAE: 0.8953 - val_MSE: 5.3620\n",
      "Epoch 125/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.1154 - MAE: 0.8647 - MSE: 2.7934\n",
      "Epoch 00125: saving model to NNmodels/weights.125-1.17437.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.1154 - MAE: 0.8647 - MSE: 2.7934 - val_loss: 1.1744 - val_MAE: 0.8898 - val_MSE: 3.9339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.1148 - MAE: 0.8648 - MSE: 2.7867\n",
      "Epoch 00126: saving model to NNmodels/weights.126-1.20095.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.1148 - MAE: 0.8648 - MSE: 2.7863 - val_loss: 1.2009 - val_MAE: 0.9240 - val_MSE: 35.4582\n",
      "Epoch 127/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1169 - MAE: 0.8673 - MSE: 2.8351\n",
      "Epoch 00127: saving model to NNmodels/weights.127-1.22643.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.1169 - MAE: 0.8673 - MSE: 2.8346 - val_loss: 1.2264 - val_MAE: 0.9457 - val_MSE: 83.9982\n",
      "Epoch 128/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.1142 - MAE: 0.8645 - MSE: 2.7948\n",
      "Epoch 00128: saving model to NNmodels/weights.128-1.18456.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.1142 - MAE: 0.8645 - MSE: 2.7948 - val_loss: 1.1846 - val_MAE: 0.8983 - val_MSE: 7.5139\n",
      "Epoch 129/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1131 - MAE: 0.8626 - MSE: 2.7773\n",
      "Epoch 00129: saving model to NNmodels/weights.129-1.19213.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.1131 - MAE: 0.8625 - MSE: 2.7768 - val_loss: 1.1921 - val_MAE: 0.9026 - val_MSE: 10.0621\n",
      "Epoch 130/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1150 - MAE: 0.8644 - MSE: 2.7867\n",
      "Epoch 00130: saving model to NNmodels/weights.130-1.17368.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.1150 - MAE: 0.8643 - MSE: 2.7862 - val_loss: 1.1737 - val_MAE: 0.8925 - val_MSE: 4.3235\n",
      "Epoch 131/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1132 - MAE: 0.8627 - MSE: 2.7631\n",
      "Epoch 00131: saving model to NNmodels/weights.131-1.19932.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.1132 - MAE: 0.8627 - MSE: 2.7628 - val_loss: 1.1993 - val_MAE: 0.9291 - val_MSE: 28.9324\n",
      "Epoch 132/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.1112 - MAE: 0.8605 - MSE: 2.7631\n",
      "Epoch 00132: saving model to NNmodels/weights.132-1.21388.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.1112 - MAE: 0.8606 - MSE: 2.7634 - val_loss: 1.2139 - val_MAE: 0.9375 - val_MSE: 112.3297\n",
      "Epoch 133/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1121 - MAE: 0.8627 - MSE: 2.7878\n",
      "Epoch 00133: saving model to NNmodels/weights.133-1.17870.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.1121 - MAE: 0.8627 - MSE: 2.7875 - val_loss: 1.1787 - val_MAE: 0.8967 - val_MSE: 4.7833\n",
      "Epoch 134/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.1107 - MAE: 0.8603 - MSE: 2.7347\n",
      "Epoch 00134: saving model to NNmodels/weights.134-1.20659.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.1107 - MAE: 0.8603 - MSE: 2.7347 - val_loss: 1.2066 - val_MAE: 0.9202 - val_MSE: 41.0584\n",
      "Epoch 135/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.1094 - MAE: 0.8595 - MSE: 2.7308\n",
      "Epoch 00135: saving model to NNmodels/weights.135-1.17010.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.1094 - MAE: 0.8595 - MSE: 2.7301 - val_loss: 1.1701 - val_MAE: 0.8998 - val_MSE: 4.0325\n",
      "Epoch 136/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1101 - MAE: 0.8600 - MSE: 2.7842\n",
      "Epoch 00136: saving model to NNmodels/weights.136-1.16430.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.1101 - MAE: 0.8600 - MSE: 2.7836 - val_loss: 1.1643 - val_MAE: 0.8838 - val_MSE: 3.2028\n",
      "Epoch 137/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1082 - MAE: 0.8585 - MSE: 2.7212\n",
      "Epoch 00137: saving model to NNmodels/weights.137-1.18171.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.1082 - MAE: 0.8585 - MSE: 2.7207 - val_loss: 1.1817 - val_MAE: 0.9106 - val_MSE: 17.8458\n",
      "Epoch 138/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.1091 - MAE: 0.8594 - MSE: 2.7418\n",
      "Epoch 00138: saving model to NNmodels/weights.138-1.22354.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.1092 - MAE: 0.8595 - MSE: 2.7416 - val_loss: 1.2235 - val_MAE: 0.9347 - val_MSE: 110.4711\n",
      "Epoch 139/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1107 - MAE: 0.8600 - MSE: 2.7407\n",
      "Epoch 00139: saving model to NNmodels/weights.139-1.19756.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.1108 - MAE: 0.8600 - MSE: 2.7403 - val_loss: 1.1976 - val_MAE: 0.9107 - val_MSE: 21.2559\n",
      "Epoch 140/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1073 - MAE: 0.8575 - MSE: 2.7080\n",
      "Epoch 00140: saving model to NNmodels/weights.140-1.19243.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.1073 - MAE: 0.8575 - MSE: 2.7075 - val_loss: 1.1924 - val_MAE: 0.9165 - val_MSE: 19.4056\n",
      "Epoch 141/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.1069 - MAE: 0.8558 - MSE: 2.7302\n",
      "Epoch 00141: saving model to NNmodels/weights.141-1.18848.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.1069 - MAE: 0.8558 - MSE: 2.7302 - val_loss: 1.1885 - val_MAE: 0.9150 - val_MSE: 18.3073\n",
      "Epoch 142/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.1052 - MAE: 0.8538 - MSE: 2.6963\n",
      "Epoch 00142: saving model to NNmodels/weights.142-1.19161.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.1052 - MAE: 0.8538 - MSE: 2.6963 - val_loss: 1.1916 - val_MAE: 0.9061 - val_MSE: 12.9879\n",
      "Epoch 143/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1050 - MAE: 0.8548 - MSE: 2.7123\n",
      "Epoch 00143: saving model to NNmodels/weights.143-1.20694.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.1051 - MAE: 0.8548 - MSE: 2.7126 - val_loss: 1.2069 - val_MAE: 0.9078 - val_MSE: 18.8973\n",
      "Epoch 144/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1049 - MAE: 0.8544 - MSE: 2.6927\n",
      "Epoch 00144: saving model to NNmodels/weights.144-1.20879.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.1049 - MAE: 0.8544 - MSE: 2.6921 - val_loss: 1.2088 - val_MAE: 0.9295 - val_MSE: 51.8254\n",
      "Epoch 145/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.1048 - MAE: 0.8535 - MSE: 2.6684\n",
      "Epoch 00145: saving model to NNmodels/weights.145-1.22704.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.1048 - MAE: 0.8535 - MSE: 2.6684 - val_loss: 1.2270 - val_MAE: 0.9421 - val_MSE: 71.8918\n",
      "Epoch 146/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.1038 - MAE: 0.8546 - MSE: 2.7296\n",
      "Epoch 00146: saving model to NNmodels/weights.146-1.20397.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.1039 - MAE: 0.8546 - MSE: 2.7293 - val_loss: 1.2040 - val_MAE: 0.9091 - val_MSE: 20.2213\n",
      "Epoch 147/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1034 - MAE: 0.8530 - MSE: 2.6881\n",
      "Epoch 00147: saving model to NNmodels/weights.147-1.18576.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.1034 - MAE: 0.8530 - MSE: 2.6879 - val_loss: 1.1858 - val_MAE: 0.8950 - val_MSE: 6.8549\n",
      "Epoch 148/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.1018 - MAE: 0.8513 - MSE: 2.6792\n",
      "Epoch 00148: saving model to NNmodels/weights.148-1.18354.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.1018 - MAE: 0.8513 - MSE: 2.6792 - val_loss: 1.1835 - val_MAE: 0.8970 - val_MSE: 6.2202\n",
      "Epoch 149/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1037 - MAE: 0.8540 - MSE: 2.7049\n",
      "Epoch 00149: saving model to NNmodels/weights.149-1.19198.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.1037 - MAE: 0.8539 - MSE: 2.7045 - val_loss: 1.1920 - val_MAE: 0.9176 - val_MSE: 14.5879\n",
      "Epoch 150/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1037 - MAE: 0.8529 - MSE: 2.6930\n",
      "Epoch 00150: saving model to NNmodels/weights.150-1.23891.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.1037 - MAE: 0.8528 - MSE: 2.6925 - val_loss: 1.2389 - val_MAE: 0.9594 - val_MSE: 95.2782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.1018 - MAE: 0.8523 - MSE: 2.6746\n",
      "Epoch 00151: saving model to NNmodels/weights.151-1.21743.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.1018 - MAE: 0.8522 - MSE: 2.6742 - val_loss: 1.2174 - val_MAE: 0.9445 - val_MSE: 79.1631\n",
      "Epoch 152/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.1002 - MAE: 0.8499 - MSE: 2.6393\n",
      "Epoch 00152: saving model to NNmodels/weights.152-1.19652.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.1002 - MAE: 0.8499 - MSE: 2.6393 - val_loss: 1.1965 - val_MAE: 0.9186 - val_MSE: 28.7881\n",
      "Epoch 153/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.1000 - MAE: 0.8489 - MSE: 2.6433\n",
      "Epoch 00153: saving model to NNmodels/weights.153-1.19771.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.1000 - MAE: 0.8489 - MSE: 2.6433 - val_loss: 1.1977 - val_MAE: 0.9044 - val_MSE: 19.4088\n",
      "Epoch 154/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0983 - MAE: 0.8487 - MSE: 2.6411\n",
      "Epoch 00154: saving model to NNmodels/weights.154-1.19248.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0983 - MAE: 0.8487 - MSE: 2.6407 - val_loss: 1.1925 - val_MAE: 0.9089 - val_MSE: 11.8553\n",
      "Epoch 155/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0978 - MAE: 0.8487 - MSE: 2.6599\n",
      "Epoch 00155: saving model to NNmodels/weights.155-1.17397.h5\n",
      "1561/1561 [==============================] - 36s 23ms/step - loss: 1.0978 - MAE: 0.8487 - MSE: 2.6593 - val_loss: 1.1740 - val_MAE: 0.8964 - val_MSE: 4.2292\n",
      "Epoch 156/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.0987 - MAE: 0.8490 - MSE: 2.6566\n",
      "Epoch 00156: saving model to NNmodels/weights.156-1.19398.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.0987 - MAE: 0.8490 - MSE: 2.6566 - val_loss: 1.1940 - val_MAE: 0.9110 - val_MSE: 11.9651\n",
      "Epoch 157/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.0971 - MAE: 0.8476 - MSE: 2.6530\n",
      "Epoch 00157: saving model to NNmodels/weights.157-1.18158.h5\n",
      "1561/1561 [==============================] - 35s 23ms/step - loss: 1.0971 - MAE: 0.8476 - MSE: 2.6530 - val_loss: 1.1816 - val_MAE: 0.8924 - val_MSE: 5.2159\n",
      "Epoch 158/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0961 - MAE: 0.8452 - MSE: 2.6163\n",
      "Epoch 00158: saving model to NNmodels/weights.158-1.22654.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.0961 - MAE: 0.8452 - MSE: 2.6157 - val_loss: 1.2265 - val_MAE: 0.9406 - val_MSE: 78.5948\n",
      "Epoch 159/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.0981 - MAE: 0.8473 - MSE: 2.6310\n",
      "Epoch 00159: saving model to NNmodels/weights.159-1.19659.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.0981 - MAE: 0.8473 - MSE: 2.6310 - val_loss: 1.1966 - val_MAE: 0.9012 - val_MSE: 8.8142\n",
      "Epoch 160/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0949 - MAE: 0.8449 - MSE: 2.6136\n",
      "Epoch 00160: saving model to NNmodels/weights.160-1.20337.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.0949 - MAE: 0.8448 - MSE: 2.6131 - val_loss: 1.2034 - val_MAE: 0.9113 - val_MSE: 16.1362\n",
      "Epoch 161/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0975 - MAE: 0.8475 - MSE: 2.6796\n",
      "Epoch 00161: saving model to NNmodels/weights.161-1.22830.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.0974 - MAE: 0.8475 - MSE: 2.6791 - val_loss: 1.2283 - val_MAE: 0.9389 - val_MSE: 75.9630\n",
      "Epoch 162/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0950 - MAE: 0.8446 - MSE: 2.6181\n",
      "Epoch 00162: saving model to NNmodels/weights.162-1.20277.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0950 - MAE: 0.8446 - MSE: 2.6176 - val_loss: 1.2028 - val_MAE: 0.9120 - val_MSE: 7.8747\n",
      "Epoch 163/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.0935 - MAE: 0.8428 - MSE: 2.5832\n",
      "Epoch 00163: saving model to NNmodels/weights.163-1.19982.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0935 - MAE: 0.8428 - MSE: 2.5832 - val_loss: 1.1998 - val_MAE: 0.9141 - val_MSE: 19.8218\n",
      "Epoch 164/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0961 - MAE: 0.8454 - MSE: 2.6154\n",
      "Epoch 00164: saving model to NNmodels/weights.164-1.17827.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0962 - MAE: 0.8454 - MSE: 2.6155 - val_loss: 1.1783 - val_MAE: 0.8944 - val_MSE: 4.9360\n",
      "Epoch 165/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0960 - MAE: 0.8466 - MSE: 2.6396\n",
      "Epoch 00165: saving model to NNmodels/weights.165-1.35969.h5\n",
      "1561/1561 [==============================] - 36s 23ms/step - loss: 1.0960 - MAE: 0.8466 - MSE: 2.6387 - val_loss: 1.3597 - val_MAE: 1.0836 - val_MSE: 1085.6686\n",
      "Epoch 166/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0913 - MAE: 0.8407 - MSE: 2.5659\n",
      "Epoch 00166: saving model to NNmodels/weights.166-1.33155.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.0913 - MAE: 0.8407 - MSE: 2.5656 - val_loss: 1.3315 - val_MAE: 1.0426 - val_MSE: 834.0114\n",
      "Epoch 167/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0902 - MAE: 0.8390 - MSE: 2.5475\n",
      "Epoch 00167: saving model to NNmodels/weights.167-1.26147.h5\n",
      "1561/1561 [==============================] - 36s 23ms/step - loss: 1.0902 - MAE: 0.8389 - MSE: 2.5470 - val_loss: 1.2615 - val_MAE: 0.9733 - val_MSE: 283.7929\n",
      "Epoch 168/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0896 - MAE: 0.8394 - MSE: 2.5821\n",
      "Epoch 00168: saving model to NNmodels/weights.168-1.28804.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0896 - MAE: 0.8394 - MSE: 2.5817 - val_loss: 1.2880 - val_MAE: 1.0053 - val_MSE: 327.1788\n",
      "Epoch 169/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0902 - MAE: 0.8392 - MSE: 2.5392\n",
      "Epoch 00169: saving model to NNmodels/weights.169-1.24739.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0902 - MAE: 0.8391 - MSE: 2.5389 - val_loss: 1.2474 - val_MAE: 0.9630 - val_MSE: 104.4866\n",
      "Epoch 170/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0922 - MAE: 0.8427 - MSE: 2.5902\n",
      "Epoch 00170: saving model to NNmodels/weights.170-1.56742.h5\n",
      "1561/1561 [==============================] - 35s 23ms/step - loss: 1.0923 - MAE: 0.8427 - MSE: 2.5898 - val_loss: 1.5674 - val_MAE: 1.2884 - val_MSE: 5863.4302\n",
      "Epoch 171/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0893 - MAE: 0.8400 - MSE: 2.5941\n",
      "Epoch 00171: saving model to NNmodels/weights.171-2.35237.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0893 - MAE: 0.8400 - MSE: 2.5937 - val_loss: 2.3524 - val_MAE: 2.0733 - val_MSE: 59924.0117\n",
      "Epoch 172/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0888 - MAE: 0.8386 - MSE: 2.5480\n",
      "Epoch 00172: saving model to NNmodels/weights.172-1.33577.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0889 - MAE: 0.8385 - MSE: 2.5475 - val_loss: 1.3358 - val_MAE: 1.0508 - val_MSE: 433.6569\n",
      "Epoch 173/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0878 - MAE: 0.8377 - MSE: 2.5744\n",
      "Epoch 00173: saving model to NNmodels/weights.173-1.47195.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0879 - MAE: 0.8377 - MSE: 2.5741 - val_loss: 1.4719 - val_MAE: 1.1848 - val_MSE: 1660.5073\n",
      "Epoch 174/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.0867 - MAE: 0.8369 - MSE: 2.5557\n",
      "Epoch 00174: saving model to NNmodels/weights.174-1.41741.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0867 - MAE: 0.8369 - MSE: 2.5557 - val_loss: 1.4174 - val_MAE: 1.1365 - val_MSE: 1492.4747\n",
      "Epoch 175/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0857 - MAE: 0.8356 - MSE: 2.5662\n",
      "Epoch 00175: saving model to NNmodels/weights.175-1.64434.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0857 - MAE: 0.8355 - MSE: 2.5656 - val_loss: 1.6443 - val_MAE: 1.3579 - val_MSE: 6972.3066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 176/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0850 - MAE: 0.8351 - MSE: 2.5338\n",
      "Epoch 00176: saving model to NNmodels/weights.176-1.37940.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0851 - MAE: 0.8351 - MSE: 2.5336 - val_loss: 1.3794 - val_MAE: 1.0915 - val_MSE: 741.4952\n",
      "Epoch 177/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.0864 - MAE: 0.8353 - MSE: 2.5229\n",
      "Epoch 00177: saving model to NNmodels/weights.177-1.56652.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0864 - MAE: 0.8353 - MSE: 2.5229 - val_loss: 1.5665 - val_MAE: 1.2825 - val_MSE: 3672.8364\n",
      "Epoch 178/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0846 - MAE: 0.8335 - MSE: 2.4995\n",
      "Epoch 00178: saving model to NNmodels/weights.178-1.30967.h5\n",
      "1561/1561 [==============================] - 36s 23ms/step - loss: 1.0847 - MAE: 0.8336 - MSE: 2.4998 - val_loss: 1.3097 - val_MAE: 1.0277 - val_MSE: 301.2786\n",
      "Epoch 179/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.0854 - MAE: 0.8340 - MSE: 2.5148\n",
      "Epoch 00179: saving model to NNmodels/weights.179-1.47063.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0854 - MAE: 0.8340 - MSE: 2.5148 - val_loss: 1.4706 - val_MAE: 1.1787 - val_MSE: 2299.8582\n",
      "Epoch 180/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0835 - MAE: 0.8337 - MSE: 2.5241\n",
      "Epoch 00180: saving model to NNmodels/weights.180-1.28017.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0836 - MAE: 0.8338 - MSE: 2.5243 - val_loss: 1.2802 - val_MAE: 0.9972 - val_MSE: 167.5683\n",
      "Epoch 181/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.0807 - MAE: 0.8303 - MSE: 2.4880\n",
      "Epoch 00181: saving model to NNmodels/weights.181-1.97744.h5\n",
      "1561/1561 [==============================] - 36s 23ms/step - loss: 1.0807 - MAE: 0.8303 - MSE: 2.4880 - val_loss: 1.9774 - val_MAE: 1.6974 - val_MSE: 9846.2705\n",
      "Epoch 182/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0834 - MAE: 0.8331 - MSE: 2.5280\n",
      "Epoch 00182: saving model to NNmodels/weights.182-1.63231.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.0834 - MAE: 0.8331 - MSE: 2.5279 - val_loss: 1.6323 - val_MAE: 1.3440 - val_MSE: 4779.9771\n",
      "Epoch 183/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.0827 - MAE: 0.8339 - MSE: 2.5168\n",
      "Epoch 00183: saving model to NNmodels/weights.183-1.41949.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0827 - MAE: 0.8339 - MSE: 2.5168 - val_loss: 1.4195 - val_MAE: 1.1335 - val_MSE: 1101.2699\n",
      "Epoch 184/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0815 - MAE: 0.8314 - MSE: 2.5345\n",
      "Epoch 00184: saving model to NNmodels/weights.184-1.41443.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0816 - MAE: 0.8314 - MSE: 2.5341 - val_loss: 1.4144 - val_MAE: 1.1356 - val_MSE: 952.0415\n",
      "Epoch 185/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0805 - MAE: 0.8317 - MSE: 2.5129\n",
      "Epoch 00185: saving model to NNmodels/weights.185-1.28466.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0805 - MAE: 0.8317 - MSE: 2.5125 - val_loss: 1.2847 - val_MAE: 0.9985 - val_MSE: 306.6447\n",
      "Epoch 186/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0793 - MAE: 0.8284 - MSE: 2.4810\n",
      "Epoch 00186: saving model to NNmodels/weights.186-1.35058.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0794 - MAE: 0.8284 - MSE: 2.4806 - val_loss: 1.3506 - val_MAE: 1.0628 - val_MSE: 802.9327\n",
      "Epoch 187/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0775 - MAE: 0.8278 - MSE: 2.4890\n",
      "Epoch 00187: saving model to NNmodels/weights.187-1.63887.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0775 - MAE: 0.8278 - MSE: 2.4888 - val_loss: 1.6389 - val_MAE: 1.3501 - val_MSE: 3036.5349\n",
      "Epoch 188/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0787 - MAE: 0.8289 - MSE: 2.4775\n",
      "Epoch 00188: saving model to NNmodels/weights.188-2.50516.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0787 - MAE: 0.8289 - MSE: 2.4769 - val_loss: 2.5052 - val_MAE: 2.2185 - val_MSE: 56705.9844\n",
      "Epoch 189/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0784 - MAE: 0.8287 - MSE: 2.4883\n",
      "Epoch 00189: saving model to NNmodels/weights.189-8.25802.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0784 - MAE: 0.8287 - MSE: 2.4878 - val_loss: 8.2580 - val_MAE: 7.9779 - val_MSE: 2441064.5000\n",
      "Epoch 190/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0770 - MAE: 0.8272 - MSE: 2.5240\n",
      "Epoch 00190: saving model to NNmodels/weights.190-1.75536.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0770 - MAE: 0.8272 - MSE: 2.5236 - val_loss: 1.7554 - val_MAE: 1.4664 - val_MSE: 7681.8677\n",
      "Epoch 191/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0799 - MAE: 0.8302 - MSE: 2.5402\n",
      "Epoch 00191: saving model to NNmodels/weights.191-1.44097.h5\n",
      "1561/1561 [==============================] - 35s 23ms/step - loss: 1.0799 - MAE: 0.8302 - MSE: 2.5396 - val_loss: 1.4410 - val_MAE: 1.1697 - val_MSE: 1237.1439\n",
      "Epoch 192/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0766 - MAE: 0.8268 - MSE: 2.4550\n",
      "Epoch 00192: saving model to NNmodels/weights.192-1.38630.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0766 - MAE: 0.8267 - MSE: 2.4546 - val_loss: 1.3863 - val_MAE: 1.1130 - val_MSE: 589.0857\n",
      "Epoch 193/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.0786 - MAE: 0.8286 - MSE: 2.4990\n",
      "Epoch 00193: saving model to NNmodels/weights.193-1.27973.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.0786 - MAE: 0.8286 - MSE: 2.4990 - val_loss: 1.2797 - val_MAE: 0.9995 - val_MSE: 150.1830\n",
      "Epoch 194/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0749 - MAE: 0.8258 - MSE: 2.4664\n",
      "Epoch 00194: saving model to NNmodels/weights.194-2.01479.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0750 - MAE: 0.8257 - MSE: 2.4658 - val_loss: 2.0148 - val_MAE: 1.7280 - val_MSE: 13242.4160\n",
      "Epoch 195/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0752 - MAE: 0.8262 - MSE: 2.4916\n",
      "Epoch 00195: saving model to NNmodels/weights.195-1.82379.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0753 - MAE: 0.8262 - MSE: 2.4916 - val_loss: 1.8238 - val_MAE: 1.5376 - val_MSE: 7213.8813\n",
      "Epoch 196/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0746 - MAE: 0.8263 - MSE: 2.4833\n",
      "Epoch 00196: saving model to NNmodels/weights.196-1.60277.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0746 - MAE: 0.8262 - MSE: 2.4829 - val_loss: 1.6028 - val_MAE: 1.3252 - val_MSE: 3286.5508\n",
      "Epoch 197/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.0731 - MAE: 0.8235 - MSE: 2.4432\n",
      "Epoch 00197: saving model to NNmodels/weights.197-8.82929.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0731 - MAE: 0.8235 - MSE: 2.4432 - val_loss: 8.8293 - val_MAE: 8.5458 - val_MSE: 2021489.5000\n",
      "Epoch 198/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.0737 - MAE: 0.8249 - MSE: 2.4672\n",
      "Epoch 00198: saving model to NNmodels/weights.198-1.76166.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0737 - MAE: 0.8249 - MSE: 2.4672 - val_loss: 1.7617 - val_MAE: 1.4852 - val_MSE: 9657.3945\n",
      "Epoch 199/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.0738 - MAE: 0.8249 - MSE: 2.4611\n",
      "Epoch 00199: saving model to NNmodels/weights.199-1.90666.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0738 - MAE: 0.8249 - MSE: 2.4611 - val_loss: 1.9067 - val_MAE: 1.6164 - val_MSE: 15505.0273\n",
      "Epoch 200/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.0725 - MAE: 0.8230 - MSE: 2.4520\n",
      "Epoch 00200: saving model to NNmodels/weights.200-1.35767.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0725 - MAE: 0.8230 - MSE: 2.4520 - val_loss: 1.3577 - val_MAE: 1.0743 - val_MSE: 577.2258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 201/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0702 - MAE: 0.8209 - MSE: 2.4021\n",
      "Epoch 00201: saving model to NNmodels/weights.201-1.39954.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0703 - MAE: 0.8210 - MSE: 2.4018 - val_loss: 1.3995 - val_MAE: 1.1119 - val_MSE: 1599.3660\n",
      "Epoch 202/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0715 - MAE: 0.8232 - MSE: 2.4480\n",
      "Epoch 00202: saving model to NNmodels/weights.202-1.26494.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0715 - MAE: 0.8232 - MSE: 2.4478 - val_loss: 1.2649 - val_MAE: 0.9758 - val_MSE: 120.6600\n",
      "Epoch 203/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.0703 - MAE: 0.8223 - MSE: 2.4484\n",
      "Epoch 00203: saving model to NNmodels/weights.203-2.59042.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0703 - MAE: 0.8223 - MSE: 2.4484 - val_loss: 2.5904 - val_MAE: 2.3002 - val_MSE: 55828.0078\n",
      "Epoch 204/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.0680 - MAE: 0.8182 - MSE: 2.4080\n",
      "Epoch 00204: saving model to NNmodels/weights.204-3.11759.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0680 - MAE: 0.8182 - MSE: 2.4080 - val_loss: 3.1176 - val_MAE: 2.8321 - val_MSE: 117904.1016\n",
      "Epoch 205/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0684 - MAE: 0.8189 - MSE: 2.4193\n",
      "Epoch 00205: saving model to NNmodels/weights.205-2.46746.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0684 - MAE: 0.8190 - MSE: 2.4193 - val_loss: 2.4675 - val_MAE: 2.1604 - val_MSE: 57408.5039\n",
      "Epoch 206/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0680 - MAE: 0.8187 - MSE: 2.3921\n",
      "Epoch 00206: saving model to NNmodels/weights.206-4.45342.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0680 - MAE: 0.8187 - MSE: 2.3917 - val_loss: 4.4534 - val_MAE: 4.1638 - val_MSE: 443359.2188\n",
      "Epoch 207/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.0664 - MAE: 0.8182 - MSE: 2.4016\n",
      "Epoch 00207: saving model to NNmodels/weights.207-3.44934.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0664 - MAE: 0.8182 - MSE: 2.4016 - val_loss: 3.4493 - val_MAE: 3.1608 - val_MSE: 165250.1562\n",
      "Epoch 208/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0669 - MAE: 0.8175 - MSE: 2.4255\n",
      "Epoch 00208: saving model to NNmodels/weights.208-1.48246.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0669 - MAE: 0.8175 - MSE: 2.4249 - val_loss: 1.4825 - val_MAE: 1.2081 - val_MSE: 1618.6117\n",
      "Epoch 209/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0660 - MAE: 0.8157 - MSE: 2.3677\n",
      "Epoch 00209: saving model to NNmodels/weights.209-2.25930.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0660 - MAE: 0.8156 - MSE: 2.3672 - val_loss: 2.2593 - val_MAE: 1.9709 - val_MSE: 33194.7227\n",
      "Epoch 210/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0665 - MAE: 0.8156 - MSE: 2.3770\n",
      "Epoch 00210: saving model to NNmodels/weights.210-1.39990.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.0665 - MAE: 0.8156 - MSE: 2.3770 - val_loss: 1.3999 - val_MAE: 1.1130 - val_MSE: 963.3068\n",
      "Epoch 211/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.0638 - MAE: 0.8151 - MSE: 2.3810\n",
      "Epoch 00211: saving model to NNmodels/weights.211-1.80560.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.0638 - MAE: 0.8151 - MSE: 2.3810 - val_loss: 1.8056 - val_MAE: 1.5192 - val_MSE: 13222.6025\n",
      "Epoch 212/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0650 - MAE: 0.8156 - MSE: 2.3670\n",
      "Epoch 00212: saving model to NNmodels/weights.212-1.77085.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.0651 - MAE: 0.8156 - MSE: 2.3668 - val_loss: 1.7708 - val_MAE: 1.4760 - val_MSE: 11147.8555\n",
      "Epoch 213/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0628 - MAE: 0.8143 - MSE: 2.3594\n",
      "Epoch 00213: saving model to NNmodels/weights.213-1.48211.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.0627 - MAE: 0.8142 - MSE: 2.3591 - val_loss: 1.4821 - val_MAE: 1.2051 - val_MSE: 1604.9119\n",
      "Epoch 214/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0627 - MAE: 0.8138 - MSE: 2.3739\n",
      "Epoch 00214: saving model to NNmodels/weights.214-2.53274.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.0627 - MAE: 0.8138 - MSE: 2.3734 - val_loss: 2.5327 - val_MAE: 2.2404 - val_MSE: 37543.5469\n",
      "Epoch 215/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0620 - MAE: 0.8123 - MSE: 2.3493\n",
      "Epoch 00215: saving model to NNmodels/weights.215-2.18255.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.0620 - MAE: 0.8122 - MSE: 2.3486 - val_loss: 2.1826 - val_MAE: 1.8879 - val_MSE: 17624.5508\n",
      "Epoch 216/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.0618 - MAE: 0.8135 - MSE: 2.3586\n",
      "Epoch 00216: saving model to NNmodels/weights.216-1.46344.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.0618 - MAE: 0.8135 - MSE: 2.3586 - val_loss: 1.4634 - val_MAE: 1.1782 - val_MSE: 1470.6027\n",
      "Epoch 217/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.0599 - MAE: 0.8106 - MSE: 2.3383\n",
      "Epoch 00217: saving model to NNmodels/weights.217-2.93225.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0599 - MAE: 0.8106 - MSE: 2.3383 - val_loss: 2.9323 - val_MAE: 2.6457 - val_MSE: 121982.3828\n",
      "Epoch 218/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.0606 - MAE: 0.8109 - MSE: 2.3352\n",
      "Epoch 00218: saving model to NNmodels/weights.218-3.66732.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0606 - MAE: 0.8109 - MSE: 2.3352 - val_loss: 3.6673 - val_MAE: 3.3796 - val_MSE: 227087.1250\n",
      "Epoch 219/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.0610 - MAE: 0.8115 - MSE: 2.3799\n",
      "Epoch 00219: saving model to NNmodels/weights.219-2.15945.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0610 - MAE: 0.8115 - MSE: 2.3799 - val_loss: 2.1595 - val_MAE: 1.8639 - val_MSE: 25757.3711\n",
      "Epoch 220/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.0591 - MAE: 0.8109 - MSE: 2.3495\n",
      "Epoch 00220: saving model to NNmodels/weights.220-1.60639.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0591 - MAE: 0.8109 - MSE: 2.3495 - val_loss: 1.6064 - val_MAE: 1.3022 - val_MSE: 3854.4558\n",
      "Epoch 221/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0595 - MAE: 0.8091 - MSE: 2.3685\n",
      "Epoch 00221: saving model to NNmodels/weights.221-2.56872.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0595 - MAE: 0.8091 - MSE: 2.3684 - val_loss: 2.5687 - val_MAE: 2.2886 - val_MSE: 78200.8125\n",
      "Epoch 222/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0582 - MAE: 0.8094 - MSE: 2.3415\n",
      "Epoch 00222: saving model to NNmodels/weights.222-1.34954.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0582 - MAE: 0.8094 - MSE: 2.3410 - val_loss: 1.3495 - val_MAE: 1.0689 - val_MSE: 605.2424\n",
      "Epoch 223/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0582 - MAE: 0.8105 - MSE: 2.3500\n",
      "Epoch 00223: saving model to NNmodels/weights.223-1.43174.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.0582 - MAE: 0.8105 - MSE: 2.3500 - val_loss: 1.4317 - val_MAE: 1.1388 - val_MSE: 1036.7394\n",
      "Epoch 224/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0577 - MAE: 0.8101 - MSE: 2.3534\n",
      "Epoch 00224: saving model to NNmodels/weights.224-1.26399.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.0577 - MAE: 0.8101 - MSE: 2.3531 - val_loss: 1.2640 - val_MAE: 0.9679 - val_MSE: 132.4407\n",
      "Epoch 225/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0575 - MAE: 0.8086 - MSE: 2.3398\n",
      "Epoch 00225: saving model to NNmodels/weights.225-1.24630.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.0575 - MAE: 0.8086 - MSE: 2.3392 - val_loss: 1.2463 - val_MAE: 0.9505 - val_MSE: 103.4408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 226/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0570 - MAE: 0.8093 - MSE: 2.3938\n",
      "Epoch 00226: saving model to NNmodels/weights.226-1.43599.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.0571 - MAE: 0.8093 - MSE: 2.3936 - val_loss: 1.4360 - val_MAE: 1.1379 - val_MSE: 1356.6555\n",
      "Epoch 227/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0545 - MAE: 0.8054 - MSE: 2.3122\n",
      "Epoch 00227: saving model to NNmodels/weights.227-1.22875.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0545 - MAE: 0.8053 - MSE: 2.3119 - val_loss: 1.2288 - val_MAE: 0.9380 - val_MSE: 46.2701\n",
      "Epoch 228/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.0585 - MAE: 0.8085 - MSE: 2.3376\n",
      "Epoch 00228: saving model to NNmodels/weights.228-1.23086.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0585 - MAE: 0.8085 - MSE: 2.3376 - val_loss: 1.2309 - val_MAE: 0.9453 - val_MSE: 69.2285\n",
      "Epoch 229/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.0543 - MAE: 0.8065 - MSE: 2.3246\n",
      "Epoch 00229: saving model to NNmodels/weights.229-1.29540.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0543 - MAE: 0.8065 - MSE: 2.3246 - val_loss: 1.2954 - val_MAE: 0.9925 - val_MSE: 258.6724\n",
      "Epoch 230/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0523 - MAE: 0.8041 - MSE: 2.2983\n",
      "Epoch 00230: saving model to NNmodels/weights.230-1.29401.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0523 - MAE: 0.8041 - MSE: 2.2981 - val_loss: 1.2940 - val_MAE: 1.0043 - val_MSE: 273.3207\n",
      "Epoch 231/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0536 - MAE: 0.8046 - MSE: 2.3001\n",
      "Epoch 00231: saving model to NNmodels/weights.231-1.57826.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.0536 - MAE: 0.8046 - MSE: 2.2997 - val_loss: 1.5783 - val_MAE: 1.2853 - val_MSE: 3758.8660\n",
      "Epoch 232/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0536 - MAE: 0.8065 - MSE: 2.3159\n",
      "Epoch 00232: saving model to NNmodels/weights.232-1.26387.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0536 - MAE: 0.8065 - MSE: 2.3154 - val_loss: 1.2639 - val_MAE: 0.9697 - val_MSE: 120.9286\n",
      "Epoch 233/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0519 - MAE: 0.8034 - MSE: 2.3021\n",
      "Epoch 00233: saving model to NNmodels/weights.233-1.44594.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0520 - MAE: 0.8033 - MSE: 2.3017 - val_loss: 1.4459 - val_MAE: 1.1598 - val_MSE: 1459.3022\n",
      "Epoch 234/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.0519 - MAE: 0.8045 - MSE: 2.3039\n",
      "Epoch 00234: saving model to NNmodels/weights.234-1.61238.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0519 - MAE: 0.8045 - MSE: 2.3039 - val_loss: 1.6124 - val_MAE: 1.3174 - val_MSE: 4363.9429\n",
      "Epoch 235/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.0506 - MAE: 0.8031 - MSE: 2.3044\n",
      "Epoch 00235: saving model to NNmodels/weights.235-1.32516.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0506 - MAE: 0.8031 - MSE: 2.3044 - val_loss: 1.3252 - val_MAE: 1.0402 - val_MSE: 383.1691\n",
      "Epoch 236/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0508 - MAE: 0.8018 - MSE: 2.2761\n",
      "Epoch 00236: saving model to NNmodels/weights.236-1.92330.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.0508 - MAE: 0.8019 - MSE: 2.2764 - val_loss: 1.9233 - val_MAE: 1.6310 - val_MSE: 10468.9150\n",
      "Epoch 237/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0501 - MAE: 0.8019 - MSE: 2.3246\n",
      "Epoch 00237: saving model to NNmodels/weights.237-1.41777.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.0501 - MAE: 0.8018 - MSE: 2.3241 - val_loss: 1.4178 - val_MAE: 1.1264 - val_MSE: 916.5540\n",
      "Epoch 238/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.0482 - MAE: 0.8006 - MSE: 2.2728\n",
      "Epoch 00238: saving model to NNmodels/weights.238-1.25674.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0482 - MAE: 0.8006 - MSE: 2.2728 - val_loss: 1.2567 - val_MAE: 0.9637 - val_MSE: 97.4520\n",
      "Epoch 239/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0474 - MAE: 0.8001 - MSE: 2.2712\n",
      "Epoch 00239: saving model to NNmodels/weights.239-2.45115.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0474 - MAE: 0.8001 - MSE: 2.2705 - val_loss: 2.4512 - val_MAE: 2.1422 - val_MSE: 29366.1445\n",
      "Epoch 240/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0485 - MAE: 0.8020 - MSE: 2.3212\n",
      "Epoch 00240: saving model to NNmodels/weights.240-1.44993.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0486 - MAE: 0.8020 - MSE: 2.3207 - val_loss: 1.4499 - val_MAE: 1.1594 - val_MSE: 1852.8065\n",
      "Epoch 241/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0469 - MAE: 0.7986 - MSE: 2.3014\n",
      "Epoch 00241: saving model to NNmodels/weights.241-1.26047.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0469 - MAE: 0.7986 - MSE: 2.3009 - val_loss: 1.2605 - val_MAE: 0.9661 - val_MSE: 122.6568\n",
      "Epoch 242/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0469 - MAE: 0.8010 - MSE: 2.3099\n",
      "Epoch 00242: saving model to NNmodels/weights.242-1.50895.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0469 - MAE: 0.8010 - MSE: 2.3094 - val_loss: 1.5089 - val_MAE: 1.2166 - val_MSE: 1881.2413\n",
      "Epoch 243/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0489 - MAE: 0.8011 - MSE: 2.3099\n",
      "Epoch 00243: saving model to NNmodels/weights.243-1.87785.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.0489 - MAE: 0.8010 - MSE: 2.3092 - val_loss: 1.8779 - val_MAE: 1.5811 - val_MSE: 7686.1519\n",
      "Epoch 244/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0443 - MAE: 0.7960 - MSE: 2.2657\n",
      "Epoch 00244: saving model to NNmodels/weights.244-1.60330.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0443 - MAE: 0.7959 - MSE: 2.2652 - val_loss: 1.6033 - val_MAE: 1.3084 - val_MSE: 2843.3477\n",
      "Epoch 245/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.0454 - MAE: 0.7973 - MSE: 2.2695\n",
      "Epoch 00245: saving model to NNmodels/weights.245-2.54326.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0454 - MAE: 0.7973 - MSE: 2.2695 - val_loss: 2.5433 - val_MAE: 2.2319 - val_MSE: 54638.1992\n",
      "Epoch 246/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0457 - MAE: 0.7991 - MSE: 2.2913\n",
      "Epoch 00246: saving model to NNmodels/weights.246-1.63160.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0457 - MAE: 0.7991 - MSE: 2.2912 - val_loss: 1.6316 - val_MAE: 1.3356 - val_MSE: 4924.5288\n",
      "Epoch 247/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0426 - MAE: 0.7964 - MSE: 2.2521\n",
      "Epoch 00247: saving model to NNmodels/weights.247-1.36177.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.0426 - MAE: 0.7964 - MSE: 2.2517 - val_loss: 1.3618 - val_MAE: 1.0664 - val_MSE: 408.2245\n",
      "Epoch 248/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0441 - MAE: 0.7964 - MSE: 2.2687\n",
      "Epoch 00248: saving model to NNmodels/weights.248-1.53704.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0441 - MAE: 0.7965 - MSE: 2.2687 - val_loss: 1.5370 - val_MAE: 1.2400 - val_MSE: 1892.3136\n",
      "Epoch 249/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0419 - MAE: 0.7947 - MSE: 2.2288\n",
      "Epoch 00249: saving model to NNmodels/weights.249-1.35840.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0419 - MAE: 0.7947 - MSE: 2.2284 - val_loss: 1.3584 - val_MAE: 1.0741 - val_MSE: 531.3708\n",
      "Epoch 250/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.0427 - MAE: 0.7945 - MSE: 2.2328\n",
      "Epoch 00250: saving model to NNmodels/weights.250-1.31713.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0427 - MAE: 0.7945 - MSE: 2.2328 - val_loss: 1.3171 - val_MAE: 1.0261 - val_MSE: 383.7254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 251/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0426 - MAE: 0.7948 - MSE: 2.2427\n",
      "Epoch 00251: saving model to NNmodels/weights.251-1.37040.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.0426 - MAE: 0.7948 - MSE: 2.2422 - val_loss: 1.3704 - val_MAE: 1.0738 - val_MSE: 765.1182\n",
      "Epoch 252/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0402 - MAE: 0.7927 - MSE: 2.2367\n",
      "Epoch 00252: saving model to NNmodels/weights.252-2.01271.h5\n",
      "1561/1561 [==============================] - 36s 23ms/step - loss: 1.0403 - MAE: 0.7927 - MSE: 2.2364 - val_loss: 2.0127 - val_MAE: 1.7271 - val_MSE: 16668.6309\n",
      "Epoch 253/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0396 - MAE: 0.7927 - MSE: 2.2464\n",
      "Epoch 00253: saving model to NNmodels/weights.253-1.57769.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.0396 - MAE: 0.7927 - MSE: 2.2461 - val_loss: 1.5777 - val_MAE: 1.2769 - val_MSE: 2198.6035\n",
      "Epoch 254/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0393 - MAE: 0.7920 - MSE: 2.2278\n",
      "Epoch 00254: saving model to NNmodels/weights.254-1.52315.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0393 - MAE: 0.7919 - MSE: 2.2273 - val_loss: 1.5231 - val_MAE: 1.2250 - val_MSE: 2948.1533\n",
      "Epoch 255/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0408 - MAE: 0.7931 - MSE: 2.2323\n",
      "Epoch 00255: saving model to NNmodels/weights.255-2.29745.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.0408 - MAE: 0.7931 - MSE: 2.2320 - val_loss: 2.2975 - val_MAE: 1.9990 - val_MSE: 27364.0000\n",
      "Epoch 256/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.0380 - MAE: 0.7908 - MSE: 2.2151\n",
      "Epoch 00256: saving model to NNmodels/weights.256-1.23872.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0380 - MAE: 0.7908 - MSE: 2.2151 - val_loss: 1.2387 - val_MAE: 0.9437 - val_MSE: 59.5631\n",
      "Epoch 257/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0388 - MAE: 0.7917 - MSE: 2.2432\n",
      "Epoch 00257: saving model to NNmodels/weights.257-1.54233.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0388 - MAE: 0.7916 - MSE: 2.2426 - val_loss: 1.5423 - val_MAE: 1.2513 - val_MSE: 3019.5540\n",
      "Epoch 258/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0374 - MAE: 0.7898 - MSE: 2.2190\n",
      "Epoch 00258: saving model to NNmodels/weights.258-1.28043.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0374 - MAE: 0.7897 - MSE: 2.2184 - val_loss: 1.2804 - val_MAE: 0.9810 - val_MSE: 238.0917\n",
      "Epoch 259/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0365 - MAE: 0.7911 - MSE: 2.2348\n",
      "Epoch 00259: saving model to NNmodels/weights.259-1.34933.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0366 - MAE: 0.7911 - MSE: 2.2343 - val_loss: 1.3493 - val_MAE: 1.0587 - val_MSE: 594.5973\n",
      "Epoch 260/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0352 - MAE: 0.7884 - MSE: 2.2092\n",
      "Epoch 00260: saving model to NNmodels/weights.260-1.25862.h5\n",
      "1561/1561 [==============================] - 36s 23ms/step - loss: 1.0352 - MAE: 0.7884 - MSE: 2.2087 - val_loss: 1.2586 - val_MAE: 0.9586 - val_MSE: 101.9514\n",
      "Epoch 261/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0351 - MAE: 0.7898 - MSE: 2.2474\n",
      "Epoch 00261: saving model to NNmodels/weights.261-1.34859.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0351 - MAE: 0.7897 - MSE: 2.2468 - val_loss: 1.3486 - val_MAE: 1.0501 - val_MSE: 469.5219\n",
      "Epoch 262/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.0360 - MAE: 0.7887 - MSE: 2.2544\n",
      "Epoch 00262: saving model to NNmodels/weights.262-1.34730.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0360 - MAE: 0.7887 - MSE: 2.2544 - val_loss: 1.3473 - val_MAE: 1.0488 - val_MSE: 392.5464\n",
      "Epoch 263/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.0351 - MAE: 0.7894 - MSE: 2.2306\n",
      "Epoch 00263: saving model to NNmodels/weights.263-1.39156.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0351 - MAE: 0.7894 - MSE: 2.2306 - val_loss: 1.3916 - val_MAE: 1.0849 - val_MSE: 530.8820\n",
      "Epoch 264/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0333 - MAE: 0.7873 - MSE: 2.2103\n",
      "Epoch 00264: saving model to NNmodels/weights.264-1.37818.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0333 - MAE: 0.7873 - MSE: 2.2101 - val_loss: 1.3782 - val_MAE: 1.0823 - val_MSE: 508.4763\n",
      "Epoch 265/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0337 - MAE: 0.7871 - MSE: 2.1936\n",
      "Epoch 00265: saving model to NNmodels/weights.265-1.26330.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0337 - MAE: 0.7870 - MSE: 2.1933 - val_loss: 1.2633 - val_MAE: 0.9829 - val_MSE: 112.2169\n",
      "Epoch 266/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0328 - MAE: 0.7852 - MSE: 2.1814\n",
      "Epoch 00266: saving model to NNmodels/weights.266-1.30136.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0329 - MAE: 0.7852 - MSE: 2.1811 - val_loss: 1.3014 - val_MAE: 1.0044 - val_MSE: 218.4290\n",
      "Epoch 267/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0320 - MAE: 0.7870 - MSE: 2.1969\n",
      "Epoch 00267: saving model to NNmodels/weights.267-1.26390.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0320 - MAE: 0.7871 - MSE: 2.1968 - val_loss: 1.2639 - val_MAE: 0.9735 - val_MSE: 105.5765\n",
      "Epoch 268/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0312 - MAE: 0.7848 - MSE: 2.2059\n",
      "Epoch 00268: saving model to NNmodels/weights.268-1.20906.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0312 - MAE: 0.7848 - MSE: 2.2055 - val_loss: 1.2091 - val_MAE: 0.9124 - val_MSE: 7.7239\n",
      "Epoch 269/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.0340 - MAE: 0.7891 - MSE: 2.2568\n",
      "Epoch 00269: saving model to NNmodels/weights.269-1.20207.h5\n",
      "1561/1561 [==============================] - 35s 23ms/step - loss: 1.0340 - MAE: 0.7891 - MSE: 2.2568 - val_loss: 1.2021 - val_MAE: 0.9045 - val_MSE: 5.3755\n",
      "Epoch 270/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0304 - MAE: 0.7848 - MSE: 2.1933\n",
      "Epoch 00270: saving model to NNmodels/weights.270-1.19944.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0304 - MAE: 0.7848 - MSE: 2.1927 - val_loss: 1.1994 - val_MAE: 0.9015 - val_MSE: 5.6203\n",
      "Epoch 271/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0291 - MAE: 0.7832 - MSE: 2.1833\n",
      "Epoch 00271: saving model to NNmodels/weights.271-1.27419.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0291 - MAE: 0.7832 - MSE: 2.1826 - val_loss: 1.2742 - val_MAE: 0.9702 - val_MSE: 99.6660\n",
      "Epoch 272/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.0302 - MAE: 0.7839 - MSE: 2.1770\n",
      "Epoch 00272: saving model to NNmodels/weights.272-1.30288.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0302 - MAE: 0.7839 - MSE: 2.1770 - val_loss: 1.3029 - val_MAE: 1.0027 - val_MSE: 162.8242\n",
      "Epoch 273/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0292 - MAE: 0.7836 - MSE: 2.1963\n",
      "Epoch 00273: saving model to NNmodels/weights.273-1.24986.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0293 - MAE: 0.7837 - MSE: 2.1964 - val_loss: 1.2499 - val_MAE: 0.9590 - val_MSE: 97.1886\n",
      "Epoch 274/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.0288 - MAE: 0.7840 - MSE: 2.1804\n",
      "Epoch 00274: saving model to NNmodels/weights.274-1.24920.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0288 - MAE: 0.7840 - MSE: 2.1804 - val_loss: 1.2492 - val_MAE: 0.9665 - val_MSE: 71.7892\n",
      "Epoch 275/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.0274 - MAE: 0.7825 - MSE: 2.1660\n",
      "Epoch 00275: saving model to NNmodels/weights.275-1.25296.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0274 - MAE: 0.7825 - MSE: 2.1660 - val_loss: 1.2530 - val_MAE: 0.9591 - val_MSE: 83.1899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 276/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0267 - MAE: 0.7796 - MSE: 2.1557\n",
      "Epoch 00276: saving model to NNmodels/weights.276-1.32379.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0267 - MAE: 0.7796 - MSE: 2.1552 - val_loss: 1.3238 - val_MAE: 1.0311 - val_MSE: 289.0505\n",
      "Epoch 277/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.0280 - MAE: 0.7829 - MSE: 2.1785\n",
      "Epoch 00277: saving model to NNmodels/weights.277-10321159782400.00000.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0280 - MAE: 0.7829 - MSE: 2.1785 - val_loss: 10321159782400.0000 - val_MAE: 10321159782400.0000 - val_MSE: 6230905224062646395286306422784.0000\n",
      "Epoch 278/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.0258 - MAE: 0.7794 - MSE: 2.1565\n",
      "Epoch 00278: saving model to NNmodels/weights.278-1.85293.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0258 - MAE: 0.7794 - MSE: 2.1565 - val_loss: 1.8529 - val_MAE: 1.5588 - val_MSE: 6245.8052\n",
      "Epoch 279/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0256 - MAE: 0.7799 - MSE: 2.1523\n",
      "Epoch 00279: saving model to NNmodels/weights.279-1.32834.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0256 - MAE: 0.7799 - MSE: 2.1520 - val_loss: 1.3283 - val_MAE: 1.0350 - val_MSE: 370.0931\n",
      "Epoch 280/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.0252 - MAE: 0.7795 - MSE: 2.1569\n",
      "Epoch 00280: saving model to NNmodels/weights.280-1.58051.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0252 - MAE: 0.7795 - MSE: 2.1569 - val_loss: 1.5805 - val_MAE: 1.2625 - val_MSE: 7463.5039\n",
      "Epoch 281/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0251 - MAE: 0.7801 - MSE: 2.1682\n",
      "Epoch 00281: saving model to NNmodels/weights.281-1.20566.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0251 - MAE: 0.7801 - MSE: 2.1676 - val_loss: 1.2057 - val_MAE: 0.9129 - val_MSE: 8.1450\n",
      "Epoch 282/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.0243 - MAE: 0.7791 - MSE: 2.1609\n",
      "Epoch 00282: saving model to NNmodels/weights.282-1.20749.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0243 - MAE: 0.7791 - MSE: 2.1609 - val_loss: 1.2075 - val_MAE: 0.9035 - val_MSE: 7.5230\n",
      "Epoch 283/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.0232 - MAE: 0.7764 - MSE: 2.1462\n",
      "Epoch 00283: saving model to NNmodels/weights.283-1.60377.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0232 - MAE: 0.7764 - MSE: 2.1462 - val_loss: 1.6038 - val_MAE: 1.3161 - val_MSE: 8144.1367\n",
      "Epoch 284/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0222 - MAE: 0.7771 - MSE: 2.1391\n",
      "Epoch 00284: saving model to NNmodels/weights.284-1.59180.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0221 - MAE: 0.7770 - MSE: 2.1386 - val_loss: 1.5918 - val_MAE: 1.2885 - val_MSE: 4622.6558\n",
      "Epoch 285/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0232 - MAE: 0.7781 - MSE: 2.1546\n",
      "Epoch 00285: saving model to NNmodels/weights.285-1.31518.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0232 - MAE: 0.7780 - MSE: 2.1542 - val_loss: 1.3152 - val_MAE: 1.0160 - val_MSE: 463.6990\n",
      "Epoch 286/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0213 - MAE: 0.7751 - MSE: 2.1447\n",
      "Epoch 00286: saving model to NNmodels/weights.286-1.27166.h5\n",
      "1561/1561 [==============================] - 36s 23ms/step - loss: 1.0214 - MAE: 0.7751 - MSE: 2.1445 - val_loss: 1.2717 - val_MAE: 0.9860 - val_MSE: 118.1510\n",
      "Epoch 287/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0229 - MAE: 0.7782 - MSE: 2.1746\n",
      "Epoch 00287: saving model to NNmodels/weights.287-1.21450.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0229 - MAE: 0.7782 - MSE: 2.1740 - val_loss: 1.2145 - val_MAE: 0.9255 - val_MSE: 14.2834\n",
      "Epoch 288/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.0208 - MAE: 0.7755 - MSE: 2.1471\n",
      "Epoch 00288: saving model to NNmodels/weights.288-1.28557.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0208 - MAE: 0.7755 - MSE: 2.1471 - val_loss: 1.2856 - val_MAE: 0.9889 - val_MSE: 165.0537\n",
      "Epoch 289/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0202 - MAE: 0.7761 - MSE: 2.1579\n",
      "Epoch 00289: saving model to NNmodels/weights.289-1.22056.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.0203 - MAE: 0.7761 - MSE: 2.1574 - val_loss: 1.2206 - val_MAE: 0.9188 - val_MSE: 15.0673\n",
      "Epoch 290/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0203 - MAE: 0.7758 - MSE: 2.1353\n",
      "Epoch 00290: saving model to NNmodels/weights.290-1.68687.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.0203 - MAE: 0.7758 - MSE: 2.1347 - val_loss: 1.6869 - val_MAE: 1.4003 - val_MSE: 10546.3525\n",
      "Epoch 291/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0200 - MAE: 0.7750 - MSE: 2.1278\n",
      "Epoch 00291: saving model to NNmodels/weights.291-1.21777.h5\n",
      "1561/1561 [==============================] - 33s 21ms/step - loss: 1.0200 - MAE: 0.7751 - MSE: 2.1276 - val_loss: 1.2178 - val_MAE: 0.9290 - val_MSE: 13.0077\n",
      "Epoch 292/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.0199 - MAE: 0.7745 - MSE: 2.1489\n",
      "Epoch 00292: saving model to NNmodels/weights.292-1.23754.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0199 - MAE: 0.7745 - MSE: 2.1489 - val_loss: 1.2375 - val_MAE: 0.9315 - val_MSE: 26.5476\n",
      "Epoch 293/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.0179 - MAE: 0.7724 - MSE: 2.1059\n",
      "Epoch 00293: saving model to NNmodels/weights.293-1.21345.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0179 - MAE: 0.7724 - MSE: 2.1059 - val_loss: 1.2134 - val_MAE: 0.9204 - val_MSE: 12.6708\n",
      "Epoch 294/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.0183 - MAE: 0.7742 - MSE: 2.1380\n",
      "Epoch 00294: saving model to NNmodels/weights.294-1.55943.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0183 - MAE: 0.7742 - MSE: 2.1380 - val_loss: 1.5594 - val_MAE: 1.2684 - val_MSE: 2411.8843\n",
      "Epoch 295/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0194 - MAE: 0.7744 - MSE: 2.1492\n",
      "Epoch 00295: saving model to NNmodels/weights.295-1.52241.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0194 - MAE: 0.7744 - MSE: 2.1488 - val_loss: 1.5224 - val_MAE: 1.2256 - val_MSE: 1700.1127\n",
      "Epoch 296/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.0160 - MAE: 0.7694 - MSE: 2.0895\n",
      "Epoch 00296: saving model to NNmodels/weights.296-1.38921.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0160 - MAE: 0.7694 - MSE: 2.0895 - val_loss: 1.3892 - val_MAE: 1.0843 - val_MSE: 568.1228\n",
      "Epoch 297/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0162 - MAE: 0.7732 - MSE: 2.1407\n",
      "Epoch 00297: saving model to NNmodels/weights.297-1.31664.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.0162 - MAE: 0.7732 - MSE: 2.1404 - val_loss: 1.3166 - val_MAE: 1.0218 - val_MSE: 245.4334\n",
      "Epoch 298/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.0160 - MAE: 0.7698 - MSE: 2.1089\n",
      "Epoch 00298: saving model to NNmodels/weights.298-1.48396.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0160 - MAE: 0.7698 - MSE: 2.1089 - val_loss: 1.4840 - val_MAE: 1.1827 - val_MSE: 2368.2310\n",
      "Epoch 299/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0136 - MAE: 0.7681 - MSE: 2.0870\n",
      "Epoch 00299: saving model to NNmodels/weights.299-1.58291.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0136 - MAE: 0.7680 - MSE: 2.0864 - val_loss: 1.5829 - val_MAE: 1.2786 - val_MSE: 8127.7520\n",
      "Epoch 300/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0159 - MAE: 0.7715 - MSE: 2.1044\n",
      "Epoch 00300: saving model to NNmodels/weights.300-10.48989.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.0159 - MAE: 0.7714 - MSE: 2.1039 - val_loss: 10.4899 - val_MAE: 10.2080 - val_MSE: 4635496.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0147 - MAE: 0.7716 - MSE: 2.1355\n",
      "Epoch 00301: saving model to NNmodels/weights.301-1.71179.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0148 - MAE: 0.7716 - MSE: 2.1351 - val_loss: 1.7118 - val_MAE: 1.4081 - val_MSE: 9445.9414\n",
      "Epoch 302/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0139 - MAE: 0.7691 - MSE: 2.0999\n",
      "Epoch 00302: saving model to NNmodels/weights.302-1.34425.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0139 - MAE: 0.7691 - MSE: 2.0993 - val_loss: 1.3442 - val_MAE: 1.0499 - val_MSE: 298.6018\n",
      "Epoch 303/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0126 - MAE: 0.7688 - MSE: 2.1053\n",
      "Epoch 00303: saving model to NNmodels/weights.303-1.21960.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0127 - MAE: 0.7688 - MSE: 2.1048 - val_loss: 1.2196 - val_MAE: 0.9171 - val_MSE: 11.2793\n",
      "Epoch 304/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0130 - MAE: 0.7689 - MSE: 2.1100\n",
      "Epoch 00304: saving model to NNmodels/weights.304-1.25266.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0129 - MAE: 0.7689 - MSE: 2.1094 - val_loss: 1.2527 - val_MAE: 0.9537 - val_MSE: 51.7829\n",
      "Epoch 305/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.0092 - MAE: 0.7653 - MSE: 2.0882\n",
      "Epoch 00305: saving model to NNmodels/weights.305-1.22380.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0092 - MAE: 0.7653 - MSE: 2.0882 - val_loss: 1.2238 - val_MAE: 0.9307 - val_MSE: 25.0657\n",
      "Epoch 306/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0137 - MAE: 0.7694 - MSE: 2.1040\n",
      "Epoch 00306: saving model to NNmodels/weights.306-6.90059.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0137 - MAE: 0.7694 - MSE: 2.1035 - val_loss: 6.9006 - val_MAE: 6.5869 - val_MSE: 1541290.5000\n",
      "Epoch 307/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0101 - MAE: 0.7669 - MSE: 2.0909\n",
      "Epoch 00307: saving model to NNmodels/weights.307-1.41841.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0102 - MAE: 0.7669 - MSE: 2.0902 - val_loss: 1.4184 - val_MAE: 1.1177 - val_MSE: 1026.1924\n",
      "Epoch 308/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0115 - MAE: 0.7676 - MSE: 2.1004\n",
      "Epoch 00308: saving model to NNmodels/weights.308-1.32385.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0115 - MAE: 0.7675 - MSE: 2.0999 - val_loss: 1.3238 - val_MAE: 1.0300 - val_MSE: 604.4365\n",
      "Epoch 309/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0099 - MAE: 0.7668 - MSE: 2.0920\n",
      "Epoch 00309: saving model to NNmodels/weights.309-3.67516.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0099 - MAE: 0.7668 - MSE: 2.0915 - val_loss: 3.6752 - val_MAE: 3.3781 - val_MSE: 319287.4062\n",
      "Epoch 310/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0088 - MAE: 0.7648 - MSE: 2.0925\n",
      "Epoch 00310: saving model to NNmodels/weights.310-2.29724.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0089 - MAE: 0.7648 - MSE: 2.0921 - val_loss: 2.2972 - val_MAE: 2.0021 - val_MSE: 59787.8242\n",
      "Epoch 311/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0082 - MAE: 0.7649 - MSE: 2.0758\n",
      "Epoch 00311: saving model to NNmodels/weights.311-1.25695.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0082 - MAE: 0.7648 - MSE: 2.0752 - val_loss: 1.2569 - val_MAE: 0.9555 - val_MSE: 105.2808\n",
      "Epoch 312/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0087 - MAE: 0.7658 - MSE: 2.0643\n",
      "Epoch 00312: saving model to NNmodels/weights.312-1.28524.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0087 - MAE: 0.7658 - MSE: 2.0639 - val_loss: 1.2852 - val_MAE: 0.9903 - val_MSE: 326.7420\n",
      "Epoch 313/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0077 - MAE: 0.7625 - MSE: 2.0771\n",
      "Epoch 00313: saving model to NNmodels/weights.313-1.32208.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.0078 - MAE: 0.7626 - MSE: 2.0769 - val_loss: 1.3221 - val_MAE: 1.0287 - val_MSE: 214.1628\n",
      "Epoch 314/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0085 - MAE: 0.7627 - MSE: 2.0949\n",
      "Epoch 00314: saving model to NNmodels/weights.314-1.23888.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.0085 - MAE: 0.7627 - MSE: 2.0946 - val_loss: 1.2389 - val_MAE: 0.9370 - val_MSE: 29.0216\n",
      "Epoch 315/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0072 - MAE: 0.7628 - MSE: 2.0548\n",
      "Epoch 00315: saving model to NNmodels/weights.315-1.34237.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0072 - MAE: 0.7627 - MSE: 2.0544 - val_loss: 1.3424 - val_MAE: 1.0410 - val_MSE: 616.8723\n",
      "Epoch 316/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.0055 - MAE: 0.7615 - MSE: 2.0554\n",
      "Epoch 00316: saving model to NNmodels/weights.316-1.39816.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.0055 - MAE: 0.7615 - MSE: 2.0554 - val_loss: 1.3982 - val_MAE: 1.0923 - val_MSE: 606.9868\n",
      "Epoch 317/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0054 - MAE: 0.7603 - MSE: 2.0336\n",
      "Epoch 00317: saving model to NNmodels/weights.317-1.23306.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.0055 - MAE: 0.7603 - MSE: 2.0330 - val_loss: 1.2331 - val_MAE: 0.9332 - val_MSE: 23.1026\n",
      "Epoch 318/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0055 - MAE: 0.7618 - MSE: 2.0780\n",
      "Epoch 00318: saving model to NNmodels/weights.318-1.32844.h5\n",
      "1561/1561 [==============================] - 35s 23ms/step - loss: 1.0055 - MAE: 0.7617 - MSE: 2.0775 - val_loss: 1.3284 - val_MAE: 1.0410 - val_MSE: 274.8445\n",
      "Epoch 319/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0048 - MAE: 0.7623 - MSE: 2.0791\n",
      "Epoch 00319: saving model to NNmodels/weights.319-1.27409.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.0048 - MAE: 0.7623 - MSE: 2.0784 - val_loss: 1.2741 - val_MAE: 0.9832 - val_MSE: 140.0278\n",
      "Epoch 320/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0056 - MAE: 0.7626 - MSE: 2.0756\n",
      "Epoch 00320: saving model to NNmodels/weights.320-6160773982605275037696.00000.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0056 - MAE: 0.7626 - MSE: 2.0752 - val_loss: 6160773982605275037696.0000 - val_MAE: 6160773982605275037696.0000 - val_MSE: inf\n",
      "Epoch 321/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0043 - MAE: 0.7618 - MSE: 2.0621\n",
      "Epoch 00321: saving model to NNmodels/weights.321-1.21921.h5\n",
      "1561/1561 [==============================] - 35s 23ms/step - loss: 1.0043 - MAE: 0.7619 - MSE: 2.0621 - val_loss: 1.2192 - val_MAE: 0.9168 - val_MSE: 10.5845\n",
      "Epoch 322/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.0039 - MAE: 0.7620 - MSE: 2.0824\n",
      "Epoch 00322: saving model to NNmodels/weights.322-1.23334.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.0039 - MAE: 0.7620 - MSE: 2.0824 - val_loss: 1.2333 - val_MAE: 0.9323 - val_MSE: 29.9208\n",
      "Epoch 323/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0044 - MAE: 0.7619 - MSE: 2.0897\n",
      "Epoch 00323: saving model to NNmodels/weights.323-1.73725.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.0044 - MAE: 0.7618 - MSE: 2.0893 - val_loss: 1.7373 - val_MAE: 1.4405 - val_MSE: 7533.4136\n",
      "Epoch 324/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0024 - MAE: 0.7597 - MSE: 2.0507\n",
      "Epoch 00324: saving model to NNmodels/weights.324-1.24429.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.0024 - MAE: 0.7597 - MSE: 2.0500 - val_loss: 1.2443 - val_MAE: 0.9546 - val_MSE: 35.6699\n",
      "Epoch 325/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0020 - MAE: 0.7593 - MSE: 2.0841\n",
      "Epoch 00325: saving model to NNmodels/weights.325-1.22976.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.0021 - MAE: 0.7593 - MSE: 2.0840 - val_loss: 1.2298 - val_MAE: 0.9381 - val_MSE: 35.0871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 326/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0016 - MAE: 0.7595 - MSE: 2.0629\n",
      "Epoch 00326: saving model to NNmodels/weights.326-1.31761.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0016 - MAE: 0.7596 - MSE: 2.0625 - val_loss: 1.3176 - val_MAE: 1.0054 - val_MSE: 311.5232\n",
      "Epoch 327/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0008 - MAE: 0.7589 - MSE: 2.0509\n",
      "Epoch 00327: saving model to NNmodels/weights.327-1.73087.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.0008 - MAE: 0.7588 - MSE: 2.0503 - val_loss: 1.7309 - val_MAE: 1.4292 - val_MSE: 9412.0508\n",
      "Epoch 328/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 1.0008 - MAE: 0.7587 - MSE: 2.0428\n",
      "Epoch 00328: saving model to NNmodels/weights.328-1.70268.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 1.0008 - MAE: 0.7587 - MSE: 2.0428 - val_loss: 1.7027 - val_MAE: 1.4009 - val_MSE: 5406.8096\n",
      "Epoch 329/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 1.0018 - MAE: 0.7605 - MSE: 2.0738\n",
      "Epoch 00329: saving model to NNmodels/weights.329-5.45402.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.0018 - MAE: 0.7605 - MSE: 2.0732 - val_loss: 5.4540 - val_MAE: 5.1573 - val_MSE: 633626.3750\n",
      "Epoch 330/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 1.0025 - MAE: 0.7597 - MSE: 2.0663\n",
      "Epoch 00330: saving model to NNmodels/weights.330-1.37544.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 1.0025 - MAE: 0.7597 - MSE: 2.0661 - val_loss: 1.3754 - val_MAE: 1.0803 - val_MSE: 673.8943\n",
      "Epoch 331/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9990 - MAE: 0.7584 - MSE: 2.0580\n",
      "Epoch 00331: saving model to NNmodels/weights.331-2.53773.h5\n",
      "1561/1561 [==============================] - 35s 23ms/step - loss: 0.9990 - MAE: 0.7584 - MSE: 2.0580 - val_loss: 2.5377 - val_MAE: 2.2276 - val_MSE: 48995.9609\n",
      "Epoch 332/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9997 - MAE: 0.7566 - MSE: 2.0382\n",
      "Epoch 00332: saving model to NNmodels/weights.332-1.40613.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9997 - MAE: 0.7566 - MSE: 2.0382 - val_loss: 1.4061 - val_MAE: 1.0977 - val_MSE: 709.3981\n",
      "Epoch 333/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9995 - MAE: 0.7575 - MSE: 2.0604\n",
      "Epoch 00333: saving model to NNmodels/weights.333-1.34592.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9994 - MAE: 0.7574 - MSE: 2.0598 - val_loss: 1.3459 - val_MAE: 1.0473 - val_MSE: 340.7820\n",
      "Epoch 334/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9988 - MAE: 0.7556 - MSE: 2.0187\n",
      "Epoch 00334: saving model to NNmodels/weights.334-1.43330.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9988 - MAE: 0.7556 - MSE: 2.0182 - val_loss: 1.4333 - val_MAE: 1.1388 - val_MSE: 998.7044\n",
      "Epoch 335/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9984 - MAE: 0.7563 - MSE: 2.0381\n",
      "Epoch 00335: saving model to NNmodels/weights.335-2.90347.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9984 - MAE: 0.7563 - MSE: 2.0381 - val_loss: 2.9035 - val_MAE: 2.6120 - val_MSE: 73463.2578\n",
      "Epoch 336/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9989 - MAE: 0.7565 - MSE: 2.0459\n",
      "Epoch 00336: saving model to NNmodels/weights.336-2.39889.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9990 - MAE: 0.7564 - MSE: 2.0457 - val_loss: 2.3989 - val_MAE: 2.1043 - val_MSE: 65106.0352\n",
      "Epoch 337/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9970 - MAE: 0.7556 - MSE: 2.0490\n",
      "Epoch 00337: saving model to NNmodels/weights.337-3.36499.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9970 - MAE: 0.7555 - MSE: 2.0481 - val_loss: 3.3650 - val_MAE: 3.0733 - val_MSE: 217119.4062\n",
      "Epoch 338/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9963 - MAE: 0.7557 - MSE: 2.0677\n",
      "Epoch 00338: saving model to NNmodels/weights.338-27.07588.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9963 - MAE: 0.7557 - MSE: 2.0677 - val_loss: 27.0759 - val_MAE: 26.7791 - val_MSE: 37447784.0000\n",
      "Epoch 339/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9961 - MAE: 0.7535 - MSE: 2.0197\n",
      "Epoch 00339: saving model to NNmodels/weights.339-1.31383.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9961 - MAE: 0.7534 - MSE: 2.0189 - val_loss: 1.3138 - val_MAE: 1.0148 - val_MSE: 304.2969\n",
      "Epoch 340/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9945 - MAE: 0.7537 - MSE: 2.0499\n",
      "Epoch 00340: saving model to NNmodels/weights.340-1.29078.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9945 - MAE: 0.7537 - MSE: 2.0499 - val_loss: 1.2908 - val_MAE: 0.9990 - val_MSE: 191.7789\n",
      "Epoch 341/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9945 - MAE: 0.7537 - MSE: 2.0430\n",
      "Epoch 00341: saving model to NNmodels/weights.341-1.30647.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9945 - MAE: 0.7537 - MSE: 2.0430 - val_loss: 1.3065 - val_MAE: 1.0309 - val_MSE: 266.3790\n",
      "Epoch 342/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9961 - MAE: 0.7543 - MSE: 2.0539\n",
      "Epoch 00342: saving model to NNmodels/weights.342-1.22316.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9961 - MAE: 0.7544 - MSE: 2.0535 - val_loss: 1.2232 - val_MAE: 0.9293 - val_MSE: 20.0315\n",
      "Epoch 343/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9950 - MAE: 0.7550 - MSE: 2.0658\n",
      "Epoch 00343: saving model to NNmodels/weights.343-1.26936.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9950 - MAE: 0.7550 - MSE: 2.0658 - val_loss: 1.2694 - val_MAE: 0.9644 - val_MSE: 91.5302\n",
      "Epoch 344/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9945 - MAE: 0.7532 - MSE: 2.0381\n",
      "Epoch 00344: saving model to NNmodels/weights.344-1.73775.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9946 - MAE: 0.7532 - MSE: 2.0378 - val_loss: 1.7377 - val_MAE: 1.4446 - val_MSE: 5015.0391\n",
      "Epoch 345/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9922 - MAE: 0.7494 - MSE: 1.9902\n",
      "Epoch 00345: saving model to NNmodels/weights.345-1.28441.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9923 - MAE: 0.7494 - MSE: 1.9898 - val_loss: 1.2844 - val_MAE: 1.0000 - val_MSE: 203.6053\n",
      "Epoch 346/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9918 - MAE: 0.7492 - MSE: 1.9727\n",
      "Epoch 00346: saving model to NNmodels/weights.346-1.44553.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9918 - MAE: 0.7491 - MSE: 1.9722 - val_loss: 1.4455 - val_MAE: 1.1417 - val_MSE: 1428.8744\n",
      "Epoch 347/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9911 - MAE: 0.7494 - MSE: 1.9918\n",
      "Epoch 00347: saving model to NNmodels/weights.347-2.13325.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9912 - MAE: 0.7494 - MSE: 1.9913 - val_loss: 2.1332 - val_MAE: 1.8425 - val_MSE: 20016.6582\n",
      "Epoch 348/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9914 - MAE: 0.7515 - MSE: 2.0270\n",
      "Epoch 00348: saving model to NNmodels/weights.348-1.73714.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9914 - MAE: 0.7515 - MSE: 2.0270 - val_loss: 1.7371 - val_MAE: 1.4472 - val_MSE: 5756.1177\n",
      "Epoch 349/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9908 - MAE: 0.7480 - MSE: 1.9871\n",
      "Epoch 00349: saving model to NNmodels/weights.349-1.33791.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9908 - MAE: 0.7480 - MSE: 1.9867 - val_loss: 1.3379 - val_MAE: 1.0384 - val_MSE: 423.8672\n",
      "Epoch 350/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9913 - MAE: 0.7491 - MSE: 1.9922\n",
      "Epoch 00350: saving model to NNmodels/weights.350-1.51601.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9913 - MAE: 0.7491 - MSE: 1.9922 - val_loss: 1.5160 - val_MAE: 1.2076 - val_MSE: 3713.8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 351/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9912 - MAE: 0.7497 - MSE: 2.0065\n",
      "Epoch 00351: saving model to NNmodels/weights.351-1.84785.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9912 - MAE: 0.7496 - MSE: 2.0060 - val_loss: 1.8478 - val_MAE: 1.5302 - val_MSE: 12063.6562\n",
      "Epoch 352/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9909 - MAE: 0.7490 - MSE: 1.9894\n",
      "Epoch 00352: saving model to NNmodels/weights.352-1.29123.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9910 - MAE: 0.7489 - MSE: 1.9890 - val_loss: 1.2912 - val_MAE: 0.9942 - val_MSE: 152.2776\n",
      "Epoch 353/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9901 - MAE: 0.7490 - MSE: 2.0028\n",
      "Epoch 00353: saving model to NNmodels/weights.353-1.28576.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9901 - MAE: 0.7490 - MSE: 2.0028 - val_loss: 1.2858 - val_MAE: 0.9859 - val_MSE: 122.6438\n",
      "Epoch 354/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9905 - MAE: 0.7476 - MSE: 1.9915\n",
      "Epoch 00354: saving model to NNmodels/weights.354-1.24076.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9905 - MAE: 0.7477 - MSE: 1.9914 - val_loss: 1.2408 - val_MAE: 0.9329 - val_MSE: 38.6566\n",
      "Epoch 355/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9907 - MAE: 0.7500 - MSE: 2.0147\n",
      "Epoch 00355: saving model to NNmodels/weights.355-1.22255.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9907 - MAE: 0.7500 - MSE: 2.0143 - val_loss: 1.2225 - val_MAE: 0.9228 - val_MSE: 12.6692\n",
      "Epoch 356/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9898 - MAE: 0.7488 - MSE: 2.0208\n",
      "Epoch 00356: saving model to NNmodels/weights.356-1.60755.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9898 - MAE: 0.7487 - MSE: 2.0205 - val_loss: 1.6076 - val_MAE: 1.3013 - val_MSE: 4030.5430\n",
      "Epoch 357/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9871 - MAE: 0.7461 - MSE: 1.9764\n",
      "Epoch 00357: saving model to NNmodels/weights.357-1.80092.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9871 - MAE: 0.7461 - MSE: 1.9764 - val_loss: 1.8009 - val_MAE: 1.5072 - val_MSE: 8694.6807\n",
      "Epoch 358/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9884 - MAE: 0.7469 - MSE: 2.2184\n",
      "Epoch 00358: saving model to NNmodels/weights.358-1.22485.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9884 - MAE: 0.7469 - MSE: 2.2184 - val_loss: 1.2248 - val_MAE: 0.9344 - val_MSE: 18.6854\n",
      "Epoch 359/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9881 - MAE: 0.7473 - MSE: 2.0145\n",
      "Epoch 00359: saving model to NNmodels/weights.359-1.23706.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9881 - MAE: 0.7473 - MSE: 2.0145 - val_loss: 1.2371 - val_MAE: 0.9404 - val_MSE: 26.9621\n",
      "Epoch 360/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9854 - MAE: 0.7436 - MSE: 1.9702\n",
      "Epoch 00360: saving model to NNmodels/weights.360-1.50895.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9854 - MAE: 0.7436 - MSE: 1.9702 - val_loss: 1.5090 - val_MAE: 1.2128 - val_MSE: 3739.8186\n",
      "Epoch 361/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9881 - MAE: 0.7472 - MSE: 2.0263\n",
      "Epoch 00361: saving model to NNmodels/weights.361-1.33927.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9881 - MAE: 0.7472 - MSE: 2.0260 - val_loss: 1.3393 - val_MAE: 1.0453 - val_MSE: 541.3921\n",
      "Epoch 362/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9868 - MAE: 0.7459 - MSE: 1.9889\n",
      "Epoch 00362: saving model to NNmodels/weights.362-1.49452.h5\n",
      "1561/1561 [==============================] - 35s 23ms/step - loss: 0.9868 - MAE: 0.7458 - MSE: 1.9883 - val_loss: 1.4945 - val_MAE: 1.2028 - val_MSE: 1527.4333\n",
      "Epoch 363/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9857 - MAE: 0.7444 - MSE: 1.9803\n",
      "Epoch 00363: saving model to NNmodels/weights.363-1.37184.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9857 - MAE: 0.7444 - MSE: 1.9799 - val_loss: 1.3718 - val_MAE: 1.0686 - val_MSE: 508.1206\n",
      "Epoch 364/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9858 - MAE: 0.7449 - MSE: 1.9993\n",
      "Epoch 00364: saving model to NNmodels/weights.364-1.55806.h5\n",
      "1561/1561 [==============================] - 35s 23ms/step - loss: 0.9858 - MAE: 0.7449 - MSE: 1.9989 - val_loss: 1.5581 - val_MAE: 1.2525 - val_MSE: 2400.5454\n",
      "Epoch 365/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9845 - MAE: 0.7451 - MSE: 2.0115\n",
      "Epoch 00365: saving model to NNmodels/weights.365-1.88517.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9845 - MAE: 0.7451 - MSE: 2.0112 - val_loss: 1.8852 - val_MAE: 1.5893 - val_MSE: 11116.6582\n",
      "Epoch 366/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9839 - MAE: 0.7451 - MSE: 1.9852\n",
      "Epoch 00366: saving model to NNmodels/weights.366-1.26234.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9839 - MAE: 0.7450 - MSE: 1.9844 - val_loss: 1.2623 - val_MAE: 0.9549 - val_MSE: 119.6150\n",
      "Epoch 367/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9823 - MAE: 0.7412 - MSE: 1.9863\n",
      "Epoch 00367: saving model to NNmodels/weights.367-1.24100.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9823 - MAE: 0.7412 - MSE: 1.9863 - val_loss: 1.2410 - val_MAE: 0.9417 - val_MSE: 80.0404\n",
      "Epoch 368/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9828 - MAE: 0.7408 - MSE: 1.9651\n",
      "Epoch 00368: saving model to NNmodels/weights.368-1.69061.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9828 - MAE: 0.7408 - MSE: 1.9648 - val_loss: 1.6906 - val_MAE: 1.3770 - val_MSE: 6209.3911\n",
      "Epoch 369/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9818 - MAE: 0.7406 - MSE: 1.9493\n",
      "Epoch 00369: saving model to NNmodels/weights.369-1.29183.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9818 - MAE: 0.7405 - MSE: 1.9489 - val_loss: 1.2918 - val_MAE: 0.9874 - val_MSE: 168.0603\n",
      "Epoch 370/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9846 - MAE: 0.7434 - MSE: 2.0113\n",
      "Epoch 00370: saving model to NNmodels/weights.370-1.30719.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9846 - MAE: 0.7433 - MSE: 2.0108 - val_loss: 1.3072 - val_MAE: 1.0088 - val_MSE: 235.0358\n",
      "Epoch 371/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9828 - MAE: 0.7434 - MSE: 1.9833\n",
      "Epoch 00371: saving model to NNmodels/weights.371-1.25914.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9828 - MAE: 0.7433 - MSE: 1.9825 - val_loss: 1.2591 - val_MAE: 0.9549 - val_MSE: 70.4791\n",
      "Epoch 372/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9814 - MAE: 0.7398 - MSE: 1.9529\n",
      "Epoch 00372: saving model to NNmodels/weights.372-1.30125.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9814 - MAE: 0.7398 - MSE: 1.9528 - val_loss: 1.3012 - val_MAE: 1.0084 - val_MSE: 242.5746\n",
      "Epoch 373/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9825 - MAE: 0.7414 - MSE: 1.9793\n",
      "Epoch 00373: saving model to NNmodels/weights.373-1.26777.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9825 - MAE: 0.7414 - MSE: 1.9793 - val_loss: 1.2678 - val_MAE: 0.9848 - val_MSE: 150.3121\n",
      "Epoch 374/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9808 - MAE: 0.7405 - MSE: 1.9466\n",
      "Epoch 00374: saving model to NNmodels/weights.374-1.45632.h5\n",
      "1561/1561 [==============================] - 36s 23ms/step - loss: 0.9808 - MAE: 0.7404 - MSE: 1.9461 - val_loss: 1.4563 - val_MAE: 1.1657 - val_MSE: 2416.9905\n",
      "Epoch 375/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9842 - MAE: 0.7425 - MSE: 1.9687\n",
      "Epoch 00375: saving model to NNmodels/weights.375-1.22806.h5\n",
      "1561/1561 [==============================] - 36s 23ms/step - loss: 0.9843 - MAE: 0.7425 - MSE: 1.9683 - val_loss: 1.2281 - val_MAE: 0.9376 - val_MSE: 22.3724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 376/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9813 - MAE: 0.7392 - MSE: 1.9317\n",
      "Epoch 00376: saving model to NNmodels/weights.376-1.26683.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9813 - MAE: 0.7391 - MSE: 1.9312 - val_loss: 1.2668 - val_MAE: 0.9674 - val_MSE: 121.3644\n",
      "Epoch 377/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9800 - MAE: 0.7389 - MSE: 1.9464\n",
      "Epoch 00377: saving model to NNmodels/weights.377-1.25055.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9800 - MAE: 0.7388 - MSE: 1.9459 - val_loss: 1.2505 - val_MAE: 0.9531 - val_MSE: 34.9854\n",
      "Epoch 378/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9788 - MAE: 0.7380 - MSE: 1.9376\n",
      "Epoch 00378: saving model to NNmodels/weights.378-1.21789.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9788 - MAE: 0.7380 - MSE: 1.9376 - val_loss: 1.2179 - val_MAE: 0.9182 - val_MSE: 7.3576\n",
      "Epoch 379/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9790 - MAE: 0.7408 - MSE: 1.9616\n",
      "Epoch 00379: saving model to NNmodels/weights.379-1.28322.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9790 - MAE: 0.7408 - MSE: 1.9616 - val_loss: 1.2832 - val_MAE: 0.9725 - val_MSE: 134.2467\n",
      "Epoch 380/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9793 - MAE: 0.7402 - MSE: 1.9861\n",
      "Epoch 00380: saving model to NNmodels/weights.380-1.33379.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9793 - MAE: 0.7402 - MSE: 1.9855 - val_loss: 1.3338 - val_MAE: 1.0396 - val_MSE: 323.8850\n",
      "Epoch 381/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9800 - MAE: 0.7388 - MSE: 1.9636\n",
      "Epoch 00381: saving model to NNmodels/weights.381-1.50354.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9801 - MAE: 0.7389 - MSE: 1.9633 - val_loss: 1.5035 - val_MAE: 1.1955 - val_MSE: 2076.8123\n",
      "Epoch 382/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9792 - MAE: 0.7393 - MSE: 1.9419\n",
      "Epoch 00382: saving model to NNmodels/weights.382-1.25931.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9793 - MAE: 0.7393 - MSE: 1.9416 - val_loss: 1.2593 - val_MAE: 0.9502 - val_MSE: 82.2793\n",
      "Epoch 383/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9773 - MAE: 0.7366 - MSE: 1.9351\n",
      "Epoch 00383: saving model to NNmodels/weights.383-1.23263.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9773 - MAE: 0.7365 - MSE: 1.9346 - val_loss: 1.2326 - val_MAE: 0.9303 - val_MSE: 22.4647\n",
      "Epoch 384/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9771 - MAE: 0.7382 - MSE: 1.9422\n",
      "Epoch 00384: saving model to NNmodels/weights.384-1.23640.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9771 - MAE: 0.7382 - MSE: 1.9422 - val_loss: 1.2364 - val_MAE: 0.9400 - val_MSE: 27.9102\n",
      "Epoch 385/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9773 - MAE: 0.7380 - MSE: 1.9651\n",
      "Epoch 00385: saving model to NNmodels/weights.385-1.21169.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9773 - MAE: 0.7380 - MSE: 1.9647 - val_loss: 1.2117 - val_MAE: 0.9112 - val_MSE: 4.4064\n",
      "Epoch 386/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9774 - MAE: 0.7372 - MSE: 1.9384\n",
      "Epoch 00386: saving model to NNmodels/weights.386-1.36808.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9774 - MAE: 0.7372 - MSE: 1.9377 - val_loss: 1.3681 - val_MAE: 1.0654 - val_MSE: 1266.4935\n",
      "Epoch 387/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9766 - MAE: 0.7366 - MSE: 1.9496\n",
      "Epoch 00387: saving model to NNmodels/weights.387-1.26767.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9766 - MAE: 0.7366 - MSE: 1.9490 - val_loss: 1.2677 - val_MAE: 0.9665 - val_MSE: 114.0947\n",
      "Epoch 388/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9756 - MAE: 0.7351 - MSE: 1.9197\n",
      "Epoch 00388: saving model to NNmodels/weights.388-1.23745.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9756 - MAE: 0.7350 - MSE: 1.9191 - val_loss: 1.2375 - val_MAE: 0.9304 - val_MSE: 16.4154\n",
      "Epoch 389/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9747 - MAE: 0.7353 - MSE: 1.9303\n",
      "Epoch 00389: saving model to NNmodels/weights.389-1.21934.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9747 - MAE: 0.7354 - MSE: 1.9304 - val_loss: 1.2193 - val_MAE: 0.9148 - val_MSE: 4.7583\n",
      "Epoch 390/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9745 - MAE: 0.7337 - MSE: 1.9424\n",
      "Epoch 00390: saving model to NNmodels/weights.390-1.25566.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9745 - MAE: 0.7337 - MSE: 1.9424 - val_loss: 1.2557 - val_MAE: 0.9472 - val_MSE: 44.1546\n",
      "Epoch 391/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9750 - MAE: 0.7368 - MSE: 1.9501\n",
      "Epoch 00391: saving model to NNmodels/weights.391-1.30156.h5\n",
      "1561/1561 [==============================] - 35s 23ms/step - loss: 0.9750 - MAE: 0.7368 - MSE: 1.9501 - val_loss: 1.3016 - val_MAE: 0.9948 - val_MSE: 177.7134\n",
      "Epoch 392/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9731 - MAE: 0.7327 - MSE: 1.9175\n",
      "Epoch 00392: saving model to NNmodels/weights.392-1.25716.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9732 - MAE: 0.7327 - MSE: 1.9171 - val_loss: 1.2572 - val_MAE: 0.9485 - val_MSE: 62.1980\n",
      "Epoch 393/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9744 - MAE: 0.7340 - MSE: 1.9201\n",
      "Epoch 00393: saving model to NNmodels/weights.393-1.24510.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9745 - MAE: 0.7339 - MSE: 1.9200 - val_loss: 1.2451 - val_MAE: 0.9348 - val_MSE: 47.1928\n",
      "Epoch 394/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9748 - MAE: 0.7343 - MSE: 1.9403\n",
      "Epoch 00394: saving model to NNmodels/weights.394-1.28278.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9748 - MAE: 0.7343 - MSE: 1.9403 - val_loss: 1.2828 - val_MAE: 0.9798 - val_MSE: 104.2433\n",
      "Epoch 395/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9726 - MAE: 0.7331 - MSE: 1.9344\n",
      "Epoch 00395: saving model to NNmodels/weights.395-1.24820.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9726 - MAE: 0.7331 - MSE: 1.9340 - val_loss: 1.2482 - val_MAE: 0.9446 - val_MSE: 40.7401\n",
      "Epoch 396/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9726 - MAE: 0.7340 - MSE: 1.9562\n",
      "Epoch 00396: saving model to NNmodels/weights.396-1.30609.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9727 - MAE: 0.7340 - MSE: 1.9557 - val_loss: 1.3061 - val_MAE: 0.9887 - val_MSE: 192.5512\n",
      "Epoch 397/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9717 - MAE: 0.7337 - MSE: 1.9541\n",
      "Epoch 00397: saving model to NNmodels/weights.397-1.26313.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9717 - MAE: 0.7336 - MSE: 1.9536 - val_loss: 1.2631 - val_MAE: 0.9482 - val_MSE: 78.5098\n",
      "Epoch 398/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9791 - MAE: 0.7400 - MSE: 1.9689\n",
      "Epoch 00398: saving model to NNmodels/weights.398-1.23917.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9792 - MAE: 0.7400 - MSE: 1.9687 - val_loss: 1.2392 - val_MAE: 0.9490 - val_MSE: 25.5052\n",
      "Epoch 399/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9751 - MAE: 0.7367 - MSE: 1.9340\n",
      "Epoch 00399: saving model to NNmodels/weights.399-1.22832.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9751 - MAE: 0.7366 - MSE: 1.9335 - val_loss: 1.2283 - val_MAE: 0.9322 - val_MSE: 10.1894\n",
      "Epoch 400/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9724 - MAE: 0.7329 - MSE: 1.9673\n",
      "Epoch 00400: saving model to NNmodels/weights.400-1.23102.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9725 - MAE: 0.7329 - MSE: 1.9666 - val_loss: 1.2310 - val_MAE: 0.9303 - val_MSE: 16.4872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 401/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9711 - MAE: 0.7317 - MSE: 1.9166\n",
      "Epoch 00401: saving model to NNmodels/weights.401-1.22540.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9711 - MAE: 0.7317 - MSE: 1.9162 - val_loss: 1.2254 - val_MAE: 0.9190 - val_MSE: 9.2779\n",
      "Epoch 402/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9720 - MAE: 0.7349 - MSE: 1.9694\n",
      "Epoch 00402: saving model to NNmodels/weights.402-1.32457.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9720 - MAE: 0.7349 - MSE: 1.9694 - val_loss: 1.3246 - val_MAE: 1.0128 - val_MSE: 451.5027\n",
      "Epoch 403/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9697 - MAE: 0.7315 - MSE: 1.9276\n",
      "Epoch 00403: saving model to NNmodels/weights.403-1.25632.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9697 - MAE: 0.7314 - MSE: 1.9271 - val_loss: 1.2563 - val_MAE: 0.9507 - val_MSE: 60.4649\n",
      "Epoch 404/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9714 - MAE: 0.7329 - MSE: 1.9370\n",
      "Epoch 00404: saving model to NNmodels/weights.404-1.35853.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9714 - MAE: 0.7329 - MSE: 1.9370 - val_loss: 1.3585 - val_MAE: 1.0549 - val_MSE: 749.9279\n",
      "Epoch 405/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9703 - MAE: 0.7317 - MSE: 1.9559\n",
      "Epoch 00405: saving model to NNmodels/weights.405-1.23428.h5\n",
      "1561/1561 [==============================] - 35s 23ms/step - loss: 0.9703 - MAE: 0.7317 - MSE: 1.9559 - val_loss: 1.2343 - val_MAE: 0.9318 - val_MSE: 28.0449\n",
      "Epoch 406/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9696 - MAE: 0.7303 - MSE: 1.9033\n",
      "Epoch 00406: saving model to NNmodels/weights.406-1.25251.h5\n",
      "1561/1561 [==============================] - 35s 23ms/step - loss: 0.9696 - MAE: 0.7304 - MSE: 1.9030 - val_loss: 1.2525 - val_MAE: 0.9485 - val_MSE: 65.3552\n",
      "Epoch 407/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9687 - MAE: 0.7300 - MSE: 1.9097\n",
      "Epoch 00407: saving model to NNmodels/weights.407-1.28374.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9687 - MAE: 0.7300 - MSE: 1.9093 - val_loss: 1.2837 - val_MAE: 0.9775 - val_MSE: 139.1835\n",
      "Epoch 408/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9690 - MAE: 0.7301 - MSE: 1.9174\n",
      "Epoch 00408: saving model to NNmodels/weights.408-1.21672.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9690 - MAE: 0.7301 - MSE: 1.9174 - val_loss: 1.2167 - val_MAE: 0.9206 - val_MSE: 4.3194\n",
      "Epoch 409/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9680 - MAE: 0.7302 - MSE: 1.8939\n",
      "Epoch 00409: saving model to NNmodels/weights.409-1.21854.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9680 - MAE: 0.7302 - MSE: 1.8939 - val_loss: 1.2185 - val_MAE: 0.9295 - val_MSE: 6.0744\n",
      "Epoch 410/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9693 - MAE: 0.7309 - MSE: 1.9658\n",
      "Epoch 00410: saving model to NNmodels/weights.410-1.22350.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9694 - MAE: 0.7309 - MSE: 1.9656 - val_loss: 1.2235 - val_MAE: 0.9177 - val_MSE: 8.3564\n",
      "Epoch 411/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9692 - MAE: 0.7284 - MSE: 1.8817\n",
      "Epoch 00411: saving model to NNmodels/weights.411-1.25091.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9693 - MAE: 0.7285 - MSE: 1.8818 - val_loss: 1.2509 - val_MAE: 0.9424 - val_MSE: 32.8688\n",
      "Epoch 412/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9674 - MAE: 0.7284 - MSE: 1.9213\n",
      "Epoch 00412: saving model to NNmodels/weights.412-1.26348.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9674 - MAE: 0.7284 - MSE: 1.9205 - val_loss: 1.2635 - val_MAE: 0.9644 - val_MSE: 50.1505\n",
      "Epoch 413/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9668 - MAE: 0.7275 - MSE: 1.9167\n",
      "Epoch 00413: saving model to NNmodels/weights.413-1.22693.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9668 - MAE: 0.7276 - MSE: 1.9171 - val_loss: 1.2269 - val_MAE: 0.9116 - val_MSE: 6.0706\n",
      "Epoch 414/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9668 - MAE: 0.7270 - MSE: 1.8975\n",
      "Epoch 00414: saving model to NNmodels/weights.414-1.29649.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9669 - MAE: 0.7270 - MSE: 1.8969 - val_loss: 1.2965 - val_MAE: 0.9846 - val_MSE: 85.3309\n",
      "Epoch 415/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9674 - MAE: 0.7287 - MSE: 1.9055\n",
      "Epoch 00415: saving model to NNmodels/weights.415-1.42459.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9674 - MAE: 0.7287 - MSE: 1.9052 - val_loss: 1.4246 - val_MAE: 1.1277 - val_MSE: 767.0302\n",
      "Epoch 416/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9655 - MAE: 0.7277 - MSE: 1.8840\n",
      "Epoch 00416: saving model to NNmodels/weights.416-1.31946.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9655 - MAE: 0.7277 - MSE: 1.8840 - val_loss: 1.3195 - val_MAE: 1.0169 - val_MSE: 194.9413\n",
      "Epoch 417/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9657 - MAE: 0.7266 - MSE: 1.9001\n",
      "Epoch 00417: saving model to NNmodels/weights.417-1.53582.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9657 - MAE: 0.7266 - MSE: 1.9001 - val_loss: 1.5358 - val_MAE: 1.2337 - val_MSE: 2651.4531\n",
      "Epoch 418/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9645 - MAE: 0.7257 - MSE: 1.8902\n",
      "Epoch 00418: saving model to NNmodels/weights.418-1.36101.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9645 - MAE: 0.7257 - MSE: 1.8902 - val_loss: 1.3610 - val_MAE: 1.0504 - val_MSE: 438.6806\n",
      "Epoch 419/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9661 - MAE: 0.7273 - MSE: 1.8890\n",
      "Epoch 00419: saving model to NNmodels/weights.419-1.27404.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9662 - MAE: 0.7274 - MSE: 1.8894 - val_loss: 1.2740 - val_MAE: 0.9663 - val_MSE: 70.3042\n",
      "Epoch 420/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9651 - MAE: 0.7254 - MSE: 1.8726\n",
      "Epoch 00420: saving model to NNmodels/weights.420-1.46808.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9651 - MAE: 0.7254 - MSE: 1.8724 - val_loss: 1.4681 - val_MAE: 1.1571 - val_MSE: 1571.0216\n",
      "Epoch 421/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9645 - MAE: 0.7257 - MSE: 1.9070\n",
      "Epoch 00421: saving model to NNmodels/weights.421-1.44684.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9645 - MAE: 0.7256 - MSE: 1.9067 - val_loss: 1.4468 - val_MAE: 1.1398 - val_MSE: 1421.9222\n",
      "Epoch 422/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9658 - MAE: 0.7285 - MSE: 1.9216\n",
      "Epoch 00422: saving model to NNmodels/weights.422-1.23530.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9658 - MAE: 0.7285 - MSE: 1.9208 - val_loss: 1.2353 - val_MAE: 0.9339 - val_MSE: 18.7351\n",
      "Epoch 423/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9632 - MAE: 0.7264 - MSE: 1.9183\n",
      "Epoch 00423: saving model to NNmodels/weights.423-1.57078.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9633 - MAE: 0.7263 - MSE: 1.9179 - val_loss: 1.5708 - val_MAE: 1.2752 - val_MSE: 5843.0435\n",
      "Epoch 424/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9661 - MAE: 0.7294 - MSE: 1.9547\n",
      "Epoch 00424: saving model to NNmodels/weights.424-1.24059.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9661 - MAE: 0.7294 - MSE: 1.9547 - val_loss: 1.2406 - val_MAE: 0.9317 - val_MSE: 24.3333\n",
      "Epoch 425/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9634 - MAE: 0.7251 - MSE: 1.9231\n",
      "Epoch 00425: saving model to NNmodels/weights.425-1.29666.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9635 - MAE: 0.7252 - MSE: 1.9228 - val_loss: 1.2967 - val_MAE: 1.0058 - val_MSE: 417.5113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 426/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9640 - MAE: 0.7261 - MSE: 1.9048\n",
      "Epoch 00426: saving model to NNmodels/weights.426-1.24560.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9640 - MAE: 0.7261 - MSE: 1.9048 - val_loss: 1.2456 - val_MAE: 0.9612 - val_MSE: 41.2778\n",
      "Epoch 427/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9615 - MAE: 0.7245 - MSE: 1.8701\n",
      "Epoch 00427: saving model to NNmodels/weights.427-1.23734.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9616 - MAE: 0.7245 - MSE: 1.8698 - val_loss: 1.2373 - val_MAE: 0.9420 - val_MSE: 16.1961\n",
      "Epoch 428/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9619 - MAE: 0.7257 - MSE: 1.9202\n",
      "Epoch 00428: saving model to NNmodels/weights.428-1.21891.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9619 - MAE: 0.7257 - MSE: 1.9199 - val_loss: 1.2189 - val_MAE: 0.9336 - val_MSE: 8.1192\n",
      "Epoch 429/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9617 - MAE: 0.7236 - MSE: 1.8844\n",
      "Epoch 00429: saving model to NNmodels/weights.429-1.27456.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9617 - MAE: 0.7236 - MSE: 1.8842 - val_loss: 1.2746 - val_MAE: 0.9752 - val_MSE: 88.4687\n",
      "Epoch 430/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9641 - MAE: 0.7258 - MSE: 1.8904\n",
      "Epoch 00430: saving model to NNmodels/weights.430-1.24407.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9642 - MAE: 0.7258 - MSE: 1.8900 - val_loss: 1.2441 - val_MAE: 0.9406 - val_MSE: 25.2725\n",
      "Epoch 431/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9610 - MAE: 0.7236 - MSE: 1.8893\n",
      "Epoch 00431: saving model to NNmodels/weights.431-1.28988.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9611 - MAE: 0.7237 - MSE: 1.8893 - val_loss: 1.2899 - val_MAE: 0.9779 - val_MSE: 83.2224\n",
      "Epoch 432/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9600 - MAE: 0.7219 - MSE: 1.8832\n",
      "Epoch 00432: saving model to NNmodels/weights.432-1.26440.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9600 - MAE: 0.7220 - MSE: 1.8830 - val_loss: 1.2644 - val_MAE: 0.9545 - val_MSE: 45.1662\n",
      "Epoch 433/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9594 - MAE: 0.7225 - MSE: 1.8718\n",
      "Epoch 00433: saving model to NNmodels/weights.433-1.94051.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9594 - MAE: 0.7225 - MSE: 1.8718 - val_loss: 1.9405 - val_MAE: 1.6326 - val_MSE: 23401.1309\n",
      "Epoch 434/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9606 - MAE: 0.7229 - MSE: 1.8582\n",
      "Epoch 00434: saving model to NNmodels/weights.434-1.71695.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9607 - MAE: 0.7231 - MSE: 1.8585 - val_loss: 1.7170 - val_MAE: 1.3992 - val_MSE: 6833.5933\n",
      "Epoch 435/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9597 - MAE: 0.7221 - MSE: 1.8727\n",
      "Epoch 00435: saving model to NNmodels/weights.435-1.38674.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9597 - MAE: 0.7221 - MSE: 1.8727 - val_loss: 1.3867 - val_MAE: 1.1050 - val_MSE: 876.2438\n",
      "Epoch 436/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9629 - MAE: 0.7250 - MSE: 1.8779\n",
      "Epoch 00436: saving model to NNmodels/weights.436-2.02065.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9630 - MAE: 0.7250 - MSE: 1.8776 - val_loss: 2.0207 - val_MAE: 1.7026 - val_MSE: 29710.3359\n",
      "Epoch 437/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9598 - MAE: 0.7223 - MSE: 1.8804\n",
      "Epoch 00437: saving model to NNmodels/weights.437-1.30286.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9599 - MAE: 0.7224 - MSE: 1.8808 - val_loss: 1.3029 - val_MAE: 1.0032 - val_MSE: 313.0376\n",
      "Epoch 438/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9583 - MAE: 0.7209 - MSE: 1.8605\n",
      "Epoch 00438: saving model to NNmodels/weights.438-1.32961.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9584 - MAE: 0.7210 - MSE: 1.8608 - val_loss: 1.3296 - val_MAE: 1.0131 - val_MSE: 283.5866\n",
      "Epoch 439/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9585 - MAE: 0.7203 - MSE: 1.8643\n",
      "Epoch 00439: saving model to NNmodels/weights.439-1.24567.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9585 - MAE: 0.7203 - MSE: 1.8642 - val_loss: 1.2457 - val_MAE: 0.9387 - val_MSE: 46.7953\n",
      "Epoch 440/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9583 - MAE: 0.7207 - MSE: 1.8649\n",
      "Epoch 00440: saving model to NNmodels/weights.440-1.21755.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9583 - MAE: 0.7207 - MSE: 1.8649 - val_loss: 1.2175 - val_MAE: 0.9098 - val_MSE: 3.5829\n",
      "Epoch 441/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9594 - MAE: 0.7224 - MSE: 1.8786\n",
      "Epoch 00441: saving model to NNmodels/weights.441-1.46884.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9595 - MAE: 0.7225 - MSE: 1.8787 - val_loss: 1.4688 - val_MAE: 1.1608 - val_MSE: 1701.4762\n",
      "Epoch 442/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9591 - MAE: 0.7206 - MSE: 1.9093\n",
      "Epoch 00442: saving model to NNmodels/weights.442-1.23608.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9591 - MAE: 0.7206 - MSE: 1.9093 - val_loss: 1.2361 - val_MAE: 0.9338 - val_MSE: 13.0692\n",
      "Epoch 443/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9578 - MAE: 0.7203 - MSE: 1.8750\n",
      "Epoch 00443: saving model to NNmodels/weights.443-1.57476.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9578 - MAE: 0.7203 - MSE: 1.8750 - val_loss: 1.5748 - val_MAE: 1.2651 - val_MSE: 5323.7285\n",
      "Epoch 444/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9564 - MAE: 0.7208 - MSE: 1.8875\n",
      "Epoch 00444: saving model to NNmodels/weights.444-1.32398.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9564 - MAE: 0.7209 - MSE: 1.8876 - val_loss: 1.3240 - val_MAE: 1.0305 - val_MSE: 268.8817\n",
      "Epoch 445/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9574 - MAE: 0.7211 - MSE: 1.8748\n",
      "Epoch 00445: saving model to NNmodels/weights.445-1.41601.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9575 - MAE: 0.7211 - MSE: 1.8748 - val_loss: 1.4160 - val_MAE: 1.1248 - val_MSE: 1446.7335\n",
      "Epoch 446/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9559 - MAE: 0.7181 - MSE: 1.8667\n",
      "Epoch 00446: saving model to NNmodels/weights.446-1.29595.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9559 - MAE: 0.7181 - MSE: 1.8667 - val_loss: 1.2959 - val_MAE: 0.9947 - val_MSE: 130.3039\n",
      "Epoch 447/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9548 - MAE: 0.7160 - MSE: 1.8474\n",
      "Epoch 00447: saving model to NNmodels/weights.447-1.31354.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9548 - MAE: 0.7160 - MSE: 1.8466 - val_loss: 1.3135 - val_MAE: 1.0100 - val_MSE: 268.5995\n",
      "Epoch 448/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9582 - MAE: 0.7207 - MSE: 1.8792\n",
      "Epoch 00448: saving model to NNmodels/weights.448-1.28993.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9582 - MAE: 0.7207 - MSE: 1.8787 - val_loss: 1.2899 - val_MAE: 0.9929 - val_MSE: 136.0273\n",
      "Epoch 449/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9563 - MAE: 0.7190 - MSE: 1.8563\n",
      "Epoch 00449: saving model to NNmodels/weights.449-1.59081.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9563 - MAE: 0.7191 - MSE: 1.8560 - val_loss: 1.5908 - val_MAE: 1.2843 - val_MSE: 3912.2617\n",
      "Epoch 450/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9563 - MAE: 0.7192 - MSE: 1.8863\n",
      "Epoch 00450: saving model to NNmodels/weights.450-1.26617.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9564 - MAE: 0.7193 - MSE: 1.8860 - val_loss: 1.2662 - val_MAE: 0.9775 - val_MSE: 78.3809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 451/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9547 - MAE: 0.7175 - MSE: 1.8814\n",
      "Epoch 00451: saving model to NNmodels/weights.451-1.22585.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9547 - MAE: 0.7174 - MSE: 1.8810 - val_loss: 1.2258 - val_MAE: 0.9193 - val_MSE: 6.9981\n",
      "Epoch 452/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9555 - MAE: 0.7184 - MSE: 1.8838\n",
      "Epoch 00452: saving model to NNmodels/weights.452-1.22273.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9555 - MAE: 0.7184 - MSE: 1.8833 - val_loss: 1.2227 - val_MAE: 0.9200 - val_MSE: 6.8368\n",
      "Epoch 453/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9564 - MAE: 0.7188 - MSE: 1.8746\n",
      "Epoch 00453: saving model to NNmodels/weights.453-1.22549.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9564 - MAE: 0.7188 - MSE: 1.8741 - val_loss: 1.2255 - val_MAE: 0.9188 - val_MSE: 5.3612\n",
      "Epoch 454/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9536 - MAE: 0.7166 - MSE: 1.8417\n",
      "Epoch 00454: saving model to NNmodels/weights.454-1.27030.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9537 - MAE: 0.7165 - MSE: 1.8413 - val_loss: 1.2703 - val_MAE: 0.9633 - val_MSE: 76.4482\n",
      "Epoch 455/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9556 - MAE: 0.7172 - MSE: 1.8956\n",
      "Epoch 00455: saving model to NNmodels/weights.455-1.26921.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9556 - MAE: 0.7172 - MSE: 1.8952 - val_loss: 1.2692 - val_MAE: 0.9648 - val_MSE: 93.3962\n",
      "Epoch 456/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9541 - MAE: 0.7164 - MSE: 1.8339\n",
      "Epoch 00456: saving model to NNmodels/weights.456-1.25015.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9541 - MAE: 0.7164 - MSE: 1.8339 - val_loss: 1.2501 - val_MAE: 0.9411 - val_MSE: 27.3792\n",
      "Epoch 457/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9527 - MAE: 0.7153 - MSE: 1.8822\n",
      "Epoch 00457: saving model to NNmodels/weights.457-1.38051.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9527 - MAE: 0.7153 - MSE: 1.8819 - val_loss: 1.3805 - val_MAE: 1.0738 - val_MSE: 772.8306\n",
      "Epoch 458/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9539 - MAE: 0.7170 - MSE: 1.8532\n",
      "Epoch 00458: saving model to NNmodels/weights.458-1.33649.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9539 - MAE: 0.7171 - MSE: 1.8530 - val_loss: 1.3365 - val_MAE: 1.0190 - val_MSE: 415.9966\n",
      "Epoch 459/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9528 - MAE: 0.7138 - MSE: 1.8065\n",
      "Epoch 00459: saving model to NNmodels/weights.459-1.36742.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9528 - MAE: 0.7138 - MSE: 1.8059 - val_loss: 1.3674 - val_MAE: 1.0556 - val_MSE: 631.7351\n",
      "Epoch 460/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9536 - MAE: 0.7169 - MSE: 1.8539\n",
      "Epoch 00460: saving model to NNmodels/weights.460-1.35178.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9536 - MAE: 0.7169 - MSE: 1.8539 - val_loss: 1.3518 - val_MAE: 1.0422 - val_MSE: 310.2195\n",
      "Epoch 461/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9533 - MAE: 0.7177 - MSE: 1.8639\n",
      "Epoch 00461: saving model to NNmodels/weights.461-1.35249.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9533 - MAE: 0.7177 - MSE: 1.8639 - val_loss: 1.3525 - val_MAE: 1.0523 - val_MSE: 317.6983\n",
      "Epoch 462/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9523 - MAE: 0.7150 - MSE: 1.8518\n",
      "Epoch 00462: saving model to NNmodels/weights.462-1.27741.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9523 - MAE: 0.7150 - MSE: 1.8513 - val_loss: 1.2774 - val_MAE: 0.9779 - val_MSE: 63.0672\n",
      "Epoch 463/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9581 - MAE: 0.7212 - MSE: 1.8804\n",
      "Epoch 00463: saving model to NNmodels/weights.463-1.27256.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9581 - MAE: 0.7212 - MSE: 1.8804 - val_loss: 1.2726 - val_MAE: 0.9680 - val_MSE: 85.8478\n",
      "Epoch 464/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9523 - MAE: 0.7168 - MSE: 1.8736\n",
      "Epoch 00464: saving model to NNmodels/weights.464-1.23225.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9523 - MAE: 0.7168 - MSE: 1.8736 - val_loss: 1.2323 - val_MAE: 0.9027 - val_MSE: 6.0160\n",
      "Epoch 465/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9506 - MAE: 0.7140 - MSE: 1.8442\n",
      "Epoch 00465: saving model to NNmodels/weights.465-1.22042.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9506 - MAE: 0.7140 - MSE: 1.8440 - val_loss: 1.2204 - val_MAE: 0.9121 - val_MSE: 4.0107\n",
      "Epoch 466/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9524 - MAE: 0.7144 - MSE: 1.8375\n",
      "Epoch 00466: saving model to NNmodels/weights.466-1.23643.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9524 - MAE: 0.7143 - MSE: 1.8370 - val_loss: 1.2364 - val_MAE: 0.9188 - val_MSE: 9.1124\n",
      "Epoch 467/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9521 - MAE: 0.7147 - MSE: 1.8369\n",
      "Epoch 00467: saving model to NNmodels/weights.467-1.33344.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9522 - MAE: 0.7147 - MSE: 1.8367 - val_loss: 1.3334 - val_MAE: 1.0245 - val_MSE: 202.5057\n",
      "Epoch 468/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9515 - MAE: 0.7154 - MSE: 1.8943\n",
      "Epoch 00468: saving model to NNmodels/weights.468-1.37196.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9515 - MAE: 0.7154 - MSE: 1.8939 - val_loss: 1.3720 - val_MAE: 1.0656 - val_MSE: 574.2200\n",
      "Epoch 469/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9517 - MAE: 0.7148 - MSE: 1.8478\n",
      "Epoch 00469: saving model to NNmodels/weights.469-1.48117.h5\n",
      "1561/1561 [==============================] - 35s 23ms/step - loss: 0.9517 - MAE: 0.7148 - MSE: 1.8474 - val_loss: 1.4812 - val_MAE: 1.1769 - val_MSE: 1350.6648\n",
      "Epoch 470/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9497 - MAE: 0.7141 - MSE: 1.8426\n",
      "Epoch 00470: saving model to NNmodels/weights.470-1.40798.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9497 - MAE: 0.7141 - MSE: 1.8426 - val_loss: 1.4080 - val_MAE: 1.0891 - val_MSE: 915.8989\n",
      "Epoch 471/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9488 - MAE: 0.7133 - MSE: 1.8706\n",
      "Epoch 00471: saving model to NNmodels/weights.471-1.37215.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9488 - MAE: 0.7134 - MSE: 1.8713 - val_loss: 1.3722 - val_MAE: 1.0668 - val_MSE: 685.1063\n",
      "Epoch 472/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9501 - MAE: 0.7134 - MSE: 1.8729\n",
      "Epoch 00472: saving model to NNmodels/weights.472-1.46360.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9501 - MAE: 0.7134 - MSE: 1.8729 - val_loss: 1.4636 - val_MAE: 1.1465 - val_MSE: 1767.7792\n",
      "Epoch 473/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9472 - MAE: 0.7096 - MSE: 1.8104\n",
      "Epoch 00473: saving model to NNmodels/weights.473-1.26290.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9472 - MAE: 0.7096 - MSE: 1.8099 - val_loss: 1.2629 - val_MAE: 0.9351 - val_MSE: 40.9446\n",
      "Epoch 474/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9493 - MAE: 0.7133 - MSE: 1.8508\n",
      "Epoch 00474: saving model to NNmodels/weights.474-1.25497.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9494 - MAE: 0.7133 - MSE: 1.8506 - val_loss: 1.2550 - val_MAE: 0.9494 - val_MSE: 37.0640\n",
      "Epoch 475/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9486 - MAE: 0.7116 - MSE: 1.8150\n",
      "Epoch 00475: saving model to NNmodels/weights.475-1.31639.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9486 - MAE: 0.7116 - MSE: 1.8144 - val_loss: 1.3164 - val_MAE: 1.0090 - val_MSE: 138.8360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 476/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9471 - MAE: 0.7111 - MSE: 1.8376\n",
      "Epoch 00476: saving model to NNmodels/weights.476-1.38164.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9471 - MAE: 0.7111 - MSE: 1.8376 - val_loss: 1.3816 - val_MAE: 1.0663 - val_MSE: 713.6067\n",
      "Epoch 477/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9517 - MAE: 0.7154 - MSE: 1.8777\n",
      "Epoch 00477: saving model to NNmodels/weights.477-1.39957.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9517 - MAE: 0.7154 - MSE: 1.8777 - val_loss: 1.3996 - val_MAE: 1.0763 - val_MSE: 814.5823\n",
      "Epoch 478/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9470 - MAE: 0.7098 - MSE: 1.8155\n",
      "Epoch 00478: saving model to NNmodels/weights.478-1.84717.h5\n",
      "1561/1561 [==============================] - 36s 23ms/step - loss: 0.9470 - MAE: 0.7098 - MSE: 1.8155 - val_loss: 1.8472 - val_MAE: 1.5378 - val_MSE: 15398.1807\n",
      "Epoch 479/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9480 - MAE: 0.7121 - MSE: 1.8635\n",
      "Epoch 00479: saving model to NNmodels/weights.479-1.32392.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9480 - MAE: 0.7121 - MSE: 1.8635 - val_loss: 1.3239 - val_MAE: 1.0148 - val_MSE: 346.3189\n",
      "Epoch 480/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9493 - MAE: 0.7120 - MSE: 1.8560\n",
      "Epoch 00480: saving model to NNmodels/weights.480-4.81657.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9493 - MAE: 0.7119 - MSE: 1.8555 - val_loss: 4.8166 - val_MAE: 4.5003 - val_MSE: 633066.2500\n",
      "Epoch 481/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9493 - MAE: 0.7122 - MSE: 1.8609\n",
      "Epoch 00481: saving model to NNmodels/weights.481-1.36105.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9493 - MAE: 0.7122 - MSE: 1.8605 - val_loss: 1.3611 - val_MAE: 1.0529 - val_MSE: 360.8410\n",
      "Epoch 482/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9485 - MAE: 0.7117 - MSE: 1.8260\n",
      "Epoch 00482: saving model to NNmodels/weights.482-1.35890.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9485 - MAE: 0.7117 - MSE: 1.8260 - val_loss: 1.3589 - val_MAE: 1.0412 - val_MSE: 298.6142\n",
      "Epoch 483/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9469 - MAE: 0.7093 - MSE: 1.8446\n",
      "Epoch 00483: saving model to NNmodels/weights.483-1.29855.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9469 - MAE: 0.7093 - MSE: 1.8442 - val_loss: 1.2986 - val_MAE: 0.9836 - val_MSE: 176.8720\n",
      "Epoch 484/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9456 - MAE: 0.7091 - MSE: 1.8355\n",
      "Epoch 00484: saving model to NNmodels/weights.484-1.28674.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9456 - MAE: 0.7090 - MSE: 1.8350 - val_loss: 1.2867 - val_MAE: 0.9605 - val_MSE: 179.8706\n",
      "Epoch 485/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9460 - MAE: 0.7095 - MSE: 1.8295\n",
      "Epoch 00485: saving model to NNmodels/weights.485-1.25579.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9461 - MAE: 0.7096 - MSE: 1.8295 - val_loss: 1.2558 - val_MAE: 0.9214 - val_MSE: 24.9059\n",
      "Epoch 486/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9468 - MAE: 0.7086 - MSE: 1.8082\n",
      "Epoch 00486: saving model to NNmodels/weights.486-1.26996.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9468 - MAE: 0.7086 - MSE: 1.8077 - val_loss: 1.2700 - val_MAE: 0.9505 - val_MSE: 71.7599\n",
      "Epoch 487/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9461 - MAE: 0.7101 - MSE: 1.8155\n",
      "Epoch 00487: saving model to NNmodels/weights.487-1.23646.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9462 - MAE: 0.7100 - MSE: 1.8152 - val_loss: 1.2365 - val_MAE: 0.9301 - val_MSE: 10.2734\n",
      "Epoch 488/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9454 - MAE: 0.7083 - MSE: 1.8314\n",
      "Epoch 00488: saving model to NNmodels/weights.488-1.35237.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9454 - MAE: 0.7083 - MSE: 1.8314 - val_loss: 1.3524 - val_MAE: 1.0269 - val_MSE: 495.9693\n",
      "Epoch 489/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9446 - MAE: 0.7088 - MSE: 1.8280\n",
      "Epoch 00489: saving model to NNmodels/weights.489-1.31973.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9446 - MAE: 0.7088 - MSE: 1.8282 - val_loss: 1.3197 - val_MAE: 1.0033 - val_MSE: 240.0292\n",
      "Epoch 490/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9470 - MAE: 0.7100 - MSE: 1.8242\n",
      "Epoch 00490: saving model to NNmodels/weights.490-1.28211.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9470 - MAE: 0.7100 - MSE: 1.8242 - val_loss: 1.2821 - val_MAE: 0.9790 - val_MSE: 86.3562\n",
      "Epoch 491/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9439 - MAE: 0.7071 - MSE: 1.7982\n",
      "Epoch 00491: saving model to NNmodels/weights.491-1.23352.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9439 - MAE: 0.7071 - MSE: 1.7982 - val_loss: 1.2335 - val_MAE: 0.9229 - val_MSE: 9.2230\n",
      "Epoch 492/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9447 - MAE: 0.7094 - MSE: 1.8471\n",
      "Epoch 00492: saving model to NNmodels/weights.492-1.26181.h5\n",
      "1561/1561 [==============================] - 35s 23ms/step - loss: 0.9447 - MAE: 0.7094 - MSE: 1.8471 - val_loss: 1.2618 - val_MAE: 0.9463 - val_MSE: 50.2773\n",
      "Epoch 493/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9444 - MAE: 0.7076 - MSE: 1.8374\n",
      "Epoch 00493: saving model to NNmodels/weights.493-1.24352.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9444 - MAE: 0.7075 - MSE: 1.8369 - val_loss: 1.2435 - val_MAE: 0.9257 - val_MSE: 16.9529\n",
      "Epoch 494/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9449 - MAE: 0.7088 - MSE: 1.8288\n",
      "Epoch 00494: saving model to NNmodels/weights.494-1.26106.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9449 - MAE: 0.7088 - MSE: 1.8288 - val_loss: 1.2611 - val_MAE: 0.9467 - val_MSE: 37.1020\n",
      "Epoch 495/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9448 - MAE: 0.7091 - MSE: 1.8265\n",
      "Epoch 00495: saving model to NNmodels/weights.495-1.24623.h5\n",
      "1561/1561 [==============================] - 36s 23ms/step - loss: 0.9449 - MAE: 0.7091 - MSE: 1.8270 - val_loss: 1.2462 - val_MAE: 0.9023 - val_MSE: 6.9465\n",
      "Epoch 496/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9446 - MAE: 0.7072 - MSE: 1.7955\n",
      "Epoch 00496: saving model to NNmodels/weights.496-1.72909.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9446 - MAE: 0.7072 - MSE: 1.7951 - val_loss: 1.7291 - val_MAE: 1.4116 - val_MSE: 10158.3105\n",
      "Epoch 497/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9446 - MAE: 0.7085 - MSE: 1.8222\n",
      "Epoch 00497: saving model to NNmodels/weights.497-2.00186.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9446 - MAE: 0.7085 - MSE: 1.8219 - val_loss: 2.0019 - val_MAE: 1.6769 - val_MSE: 14757.1396\n",
      "Epoch 498/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9427 - MAE: 0.7069 - MSE: 1.8080\n",
      "Epoch 00498: saving model to NNmodels/weights.498-1.71902.h5\n",
      "1561/1561 [==============================] - 36s 23ms/step - loss: 0.9427 - MAE: 0.7069 - MSE: 1.8075 - val_loss: 1.7190 - val_MAE: 1.4069 - val_MSE: 6625.6309\n",
      "Epoch 499/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9442 - MAE: 0.7081 - MSE: 1.8334\n",
      "Epoch 00499: saving model to NNmodels/weights.499-1.56566.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9442 - MAE: 0.7081 - MSE: 1.8331 - val_loss: 1.5657 - val_MAE: 1.2433 - val_MSE: 3541.5430\n",
      "Epoch 500/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9440 - MAE: 0.7078 - MSE: 1.8348\n",
      "Epoch 00500: saving model to NNmodels/weights.500-1.58158.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9440 - MAE: 0.7078 - MSE: 1.8348 - val_loss: 1.5816 - val_MAE: 1.2499 - val_MSE: 6090.8999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 501/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9418 - MAE: 0.7054 - MSE: 1.8008\n",
      "Epoch 00501: saving model to NNmodels/weights.501-1.36211.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9419 - MAE: 0.7054 - MSE: 1.8004 - val_loss: 1.3621 - val_MAE: 1.0375 - val_MSE: 814.5325\n",
      "Epoch 502/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9407 - MAE: 0.7042 - MSE: 1.7745\n",
      "Epoch 00502: saving model to NNmodels/weights.502-1.35821.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9407 - MAE: 0.7042 - MSE: 1.7749 - val_loss: 1.3582 - val_MAE: 1.0324 - val_MSE: 323.8493\n",
      "Epoch 503/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9414 - MAE: 0.7050 - MSE: 1.7942\n",
      "Epoch 00503: saving model to NNmodels/weights.503-1.32353.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9415 - MAE: 0.7050 - MSE: 1.7937 - val_loss: 1.3235 - val_MAE: 1.0098 - val_MSE: 318.4407\n",
      "Epoch 504/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9424 - MAE: 0.7082 - MSE: 1.8346\n",
      "Epoch 00504: saving model to NNmodels/weights.504-1.36858.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9424 - MAE: 0.7082 - MSE: 1.8346 - val_loss: 1.3686 - val_MAE: 1.0355 - val_MSE: 452.9749\n",
      "Epoch 505/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9428 - MAE: 0.7079 - MSE: 1.8179\n",
      "Epoch 00505: saving model to NNmodels/weights.505-1.27757.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9428 - MAE: 0.7079 - MSE: 1.8179 - val_loss: 1.2776 - val_MAE: 0.9407 - val_MSE: 49.8117\n",
      "Epoch 506/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9408 - MAE: 0.7036 - MSE: 1.7834\n",
      "Epoch 00506: saving model to NNmodels/weights.506-1.46013.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9409 - MAE: 0.7036 - MSE: 1.7831 - val_loss: 1.4601 - val_MAE: 1.1533 - val_MSE: 1703.3746\n",
      "Epoch 507/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9414 - MAE: 0.7054 - MSE: 1.8147\n",
      "Epoch 00507: saving model to NNmodels/weights.507-1.24429.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9414 - MAE: 0.7054 - MSE: 1.8147 - val_loss: 1.2443 - val_MAE: 0.9064 - val_MSE: 8.4956\n",
      "Epoch 508/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9413 - MAE: 0.7039 - MSE: 1.7940\n",
      "Epoch 00508: saving model to NNmodels/weights.508-1.23824.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9413 - MAE: 0.7039 - MSE: 1.7940 - val_loss: 1.2382 - val_MAE: 0.9293 - val_MSE: 8.5824\n",
      "Epoch 509/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9408 - MAE: 0.7050 - MSE: 1.8035\n",
      "Epoch 00509: saving model to NNmodels/weights.509-1.24325.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9408 - MAE: 0.7050 - MSE: 1.8033 - val_loss: 1.2433 - val_MAE: 0.9166 - val_MSE: 8.6450\n",
      "Epoch 510/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9398 - MAE: 0.7053 - MSE: 1.8262\n",
      "Epoch 00510: saving model to NNmodels/weights.510-1.30560.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9398 - MAE: 0.7053 - MSE: 1.8262 - val_loss: 1.3056 - val_MAE: 0.9808 - val_MSE: 123.5813\n",
      "Epoch 511/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9391 - MAE: 0.7042 - MSE: 1.8032\n",
      "Epoch 00511: saving model to NNmodels/weights.511-1.25744.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9391 - MAE: 0.7042 - MSE: 1.8032 - val_loss: 1.2574 - val_MAE: 0.9460 - val_MSE: 26.5536\n",
      "Epoch 512/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9389 - MAE: 0.7033 - MSE: 1.8144\n",
      "Epoch 00512: saving model to NNmodels/weights.512-2.33418.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9389 - MAE: 0.7033 - MSE: 1.8144 - val_loss: 2.3342 - val_MAE: 2.0147 - val_MSE: 52632.1211\n",
      "Epoch 513/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9392 - MAE: 0.7027 - MSE: 1.8030\n",
      "Epoch 00513: saving model to NNmodels/weights.513-1.25686.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9392 - MAE: 0.7027 - MSE: 1.8026 - val_loss: 1.2569 - val_MAE: 0.9299 - val_MSE: 18.3865\n",
      "Epoch 514/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9405 - MAE: 0.7040 - MSE: 1.8023\n",
      "Epoch 00514: saving model to NNmodels/weights.514-1.26042.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9405 - MAE: 0.7040 - MSE: 1.8017 - val_loss: 1.2604 - val_MAE: 0.9312 - val_MSE: 32.4789\n",
      "Epoch 515/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9406 - MAE: 0.7043 - MSE: 1.7883\n",
      "Epoch 00515: saving model to NNmodels/weights.515-1.32327.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9407 - MAE: 0.7044 - MSE: 1.7886 - val_loss: 1.3233 - val_MAE: 1.0136 - val_MSE: 134.4245\n",
      "Epoch 516/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9404 - MAE: 0.7059 - MSE: 1.7900\n",
      "Epoch 00516: saving model to NNmodels/weights.516-1.35098.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9404 - MAE: 0.7059 - MSE: 1.7900 - val_loss: 1.3510 - val_MAE: 1.0357 - val_MSE: 327.9357\n",
      "Epoch 517/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9368 - MAE: 0.7019 - MSE: 1.7817\n",
      "Epoch 00517: saving model to NNmodels/weights.517-1.27006.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9368 - MAE: 0.7019 - MSE: 1.7813 - val_loss: 1.2701 - val_MAE: 0.9529 - val_MSE: 34.5536\n",
      "Epoch 518/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9387 - MAE: 0.7031 - MSE: 1.7856\n",
      "Epoch 00518: saving model to NNmodels/weights.518-1.23631.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9387 - MAE: 0.7031 - MSE: 1.7856 - val_loss: 1.2363 - val_MAE: 0.9147 - val_MSE: 5.1886\n",
      "Epoch 519/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9382 - MAE: 0.7005 - MSE: 1.7582\n",
      "Epoch 00519: saving model to NNmodels/weights.519-1.23770.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9382 - MAE: 0.7005 - MSE: 1.7582 - val_loss: 1.2377 - val_MAE: 0.9089 - val_MSE: 4.1753\n",
      "Epoch 520/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9382 - MAE: 0.7023 - MSE: 1.8145\n",
      "Epoch 00520: saving model to NNmodels/weights.520-1.25656.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9382 - MAE: 0.7023 - MSE: 1.8145 - val_loss: 1.2566 - val_MAE: 0.9398 - val_MSE: 27.8324\n",
      "Epoch 521/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9389 - MAE: 0.7036 - MSE: 1.8048\n",
      "Epoch 00521: saving model to NNmodels/weights.521-1.27528.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9389 - MAE: 0.7036 - MSE: 1.8048 - val_loss: 1.2753 - val_MAE: 0.9522 - val_MSE: 42.9311\n",
      "Epoch 522/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9391 - MAE: 0.7042 - MSE: 1.8041\n",
      "Epoch 00522: saving model to NNmodels/weights.522-1.25196.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9391 - MAE: 0.7042 - MSE: 1.8038 - val_loss: 1.2520 - val_MAE: 0.9278 - val_MSE: 19.6701\n",
      "Epoch 523/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9379 - MAE: 0.7020 - MSE: 1.8122\n",
      "Epoch 00523: saving model to NNmodels/weights.523-1.24623.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9379 - MAE: 0.7020 - MSE: 1.8122 - val_loss: 1.2462 - val_MAE: 0.9156 - val_MSE: 6.3667\n",
      "Epoch 524/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9380 - MAE: 0.7013 - MSE: 1.7807\n",
      "Epoch 00524: saving model to NNmodels/weights.524-1.26486.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9380 - MAE: 0.7012 - MSE: 1.7802 - val_loss: 1.2649 - val_MAE: 0.9576 - val_MSE: 27.1073\n",
      "Epoch 525/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9365 - MAE: 0.7013 - MSE: 1.8036\n",
      "Epoch 00525: saving model to NNmodels/weights.525-1.26875.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9365 - MAE: 0.7013 - MSE: 1.8036 - val_loss: 1.2688 - val_MAE: 0.9438 - val_MSE: 30.1277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 526/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9345 - MAE: 0.6998 - MSE: 1.7784\n",
      "Epoch 00526: saving model to NNmodels/weights.526-1.23377.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9346 - MAE: 0.6998 - MSE: 1.7781 - val_loss: 1.2338 - val_MAE: 0.9098 - val_MSE: 3.7726\n",
      "Epoch 527/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9343 - MAE: 0.6990 - MSE: 1.7863\n",
      "Epoch 00527: saving model to NNmodels/weights.527-1.24277.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9344 - MAE: 0.6990 - MSE: 1.7859 - val_loss: 1.2428 - val_MAE: 0.9321 - val_MSE: 8.6695\n",
      "Epoch 528/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9377 - MAE: 0.7026 - MSE: 1.8181\n",
      "Epoch 00528: saving model to NNmodels/weights.528-1.23295.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9377 - MAE: 0.7026 - MSE: 1.8177 - val_loss: 1.2329 - val_MAE: 0.9108 - val_MSE: 4.2770\n",
      "Epoch 529/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9363 - MAE: 0.7011 - MSE: 1.8328\n",
      "Epoch 00529: saving model to NNmodels/weights.529-1.28353.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9363 - MAE: 0.7011 - MSE: 1.8324 - val_loss: 1.2835 - val_MAE: 0.9724 - val_MSE: 59.3534\n",
      "Epoch 530/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9351 - MAE: 0.6987 - MSE: 1.7650\n",
      "Epoch 00530: saving model to NNmodels/weights.530-1.22869.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9351 - MAE: 0.6987 - MSE: 1.7650 - val_loss: 1.2287 - val_MAE: 0.9108 - val_MSE: 3.8124\n",
      "Epoch 531/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9364 - MAE: 0.6986 - MSE: 1.8049\n",
      "Epoch 00531: saving model to NNmodels/weights.531-1.23622.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9364 - MAE: 0.6986 - MSE: 1.8044 - val_loss: 1.2362 - val_MAE: 0.9191 - val_MSE: 3.9579\n",
      "Epoch 532/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9352 - MAE: 0.7003 - MSE: 1.7800\n",
      "Epoch 00532: saving model to NNmodels/weights.532-1.26036.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9352 - MAE: 0.7002 - MSE: 1.7795 - val_loss: 1.2604 - val_MAE: 0.9404 - val_MSE: 23.0244\n",
      "Epoch 533/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9373 - MAE: 0.7024 - MSE: 1.7935\n",
      "Epoch 00533: saving model to NNmodels/weights.533-1.23776.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9373 - MAE: 0.7023 - MSE: 1.7930 - val_loss: 1.2378 - val_MAE: 0.9245 - val_MSE: 6.0933\n",
      "Epoch 534/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9357 - MAE: 0.7026 - MSE: 1.8099\n",
      "Epoch 00534: saving model to NNmodels/weights.534-1.22940.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9357 - MAE: 0.7025 - MSE: 1.8094 - val_loss: 1.2294 - val_MAE: 0.9150 - val_MSE: 4.5669\n",
      "Epoch 535/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9347 - MAE: 0.6999 - MSE: 1.7826\n",
      "Epoch 00535: saving model to NNmodels/weights.535-1.23868.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9347 - MAE: 0.6999 - MSE: 1.7826 - val_loss: 1.2387 - val_MAE: 0.9254 - val_MSE: 5.4158\n",
      "Epoch 536/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9355 - MAE: 0.6990 - MSE: 1.8087\n",
      "Epoch 00536: saving model to NNmodels/weights.536-1.23578.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9355 - MAE: 0.6990 - MSE: 1.8087 - val_loss: 1.2358 - val_MAE: 0.9123 - val_MSE: 5.3889\n",
      "Epoch 537/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9343 - MAE: 0.6972 - MSE: 1.7802\n",
      "Epoch 00537: saving model to NNmodels/weights.537-1.23534.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9344 - MAE: 0.6972 - MSE: 1.7799 - val_loss: 1.2353 - val_MAE: 0.9053 - val_MSE: 4.4813\n",
      "Epoch 538/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9341 - MAE: 0.6989 - MSE: 1.7966\n",
      "Epoch 00538: saving model to NNmodels/weights.538-1.27085.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9342 - MAE: 0.6990 - MSE: 1.7964 - val_loss: 1.2708 - val_MAE: 0.9398 - val_MSE: 31.6322\n",
      "Epoch 539/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9348 - MAE: 0.6993 - MSE: 1.7694\n",
      "Epoch 00539: saving model to NNmodels/weights.539-1.38406.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9348 - MAE: 0.6993 - MSE: 1.7691 - val_loss: 1.3841 - val_MAE: 1.0681 - val_MSE: 497.9324\n",
      "Epoch 540/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9331 - MAE: 0.6995 - MSE: 1.8196\n",
      "Epoch 00540: saving model to NNmodels/weights.540-1.25580.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9331 - MAE: 0.6994 - MSE: 1.8192 - val_loss: 1.2558 - val_MAE: 0.9247 - val_MSE: 11.4890\n",
      "Epoch 541/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9334 - MAE: 0.6980 - MSE: 1.7812\n",
      "Epoch 00541: saving model to NNmodels/weights.541-1.44610.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9335 - MAE: 0.6981 - MSE: 1.7816 - val_loss: 1.4461 - val_MAE: 1.1328 - val_MSE: 655.5702\n",
      "Epoch 542/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9336 - MAE: 0.6989 - MSE: 1.7859\n",
      "Epoch 00542: saving model to NNmodels/weights.542-1.33531.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9336 - MAE: 0.6988 - MSE: 1.7855 - val_loss: 1.3353 - val_MAE: 1.0239 - val_MSE: 281.3615\n",
      "Epoch 543/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9336 - MAE: 0.6970 - MSE: 1.7485\n",
      "Epoch 00543: saving model to NNmodels/weights.543-1.39132.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9336 - MAE: 0.6970 - MSE: 1.7485 - val_loss: 1.3913 - val_MAE: 1.0656 - val_MSE: 450.3078\n",
      "Epoch 544/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9340 - MAE: 0.6982 - MSE: 1.7718\n",
      "Epoch 00544: saving model to NNmodels/weights.544-1.34256.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9340 - MAE: 0.6982 - MSE: 1.7714 - val_loss: 1.3426 - val_MAE: 1.0136 - val_MSE: 223.0037\n",
      "Epoch 545/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9324 - MAE: 0.6980 - MSE: 1.7737\n",
      "Epoch 00545: saving model to NNmodels/weights.545-1.26832.h5\n",
      "1561/1561 [==============================] - 34s 21ms/step - loss: 0.9324 - MAE: 0.6980 - MSE: 1.7737 - val_loss: 1.2683 - val_MAE: 0.9439 - val_MSE: 47.1207\n",
      "Epoch 546/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9331 - MAE: 0.6974 - MSE: 1.7740\n",
      "Epoch 00546: saving model to NNmodels/weights.546-1.27502.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9332 - MAE: 0.6974 - MSE: 1.7737 - val_loss: 1.2750 - val_MAE: 0.9555 - val_MSE: 40.0276\n",
      "Epoch 547/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9328 - MAE: 0.6979 - MSE: 1.7713\n",
      "Epoch 00547: saving model to NNmodels/weights.547-1.73355.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9328 - MAE: 0.6979 - MSE: 1.7711 - val_loss: 1.7336 - val_MAE: 1.4104 - val_MSE: 11012.8447\n",
      "Epoch 548/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9304 - MAE: 0.6952 - MSE: 1.7456\n",
      "Epoch 00548: saving model to NNmodels/weights.548-1.30801.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9304 - MAE: 0.6952 - MSE: 1.7458 - val_loss: 1.3080 - val_MAE: 0.9843 - val_MSE: 119.2486\n",
      "Epoch 549/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9326 - MAE: 0.6971 - MSE: 1.7703\n",
      "Epoch 00549: saving model to NNmodels/weights.549-1.28032.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9326 - MAE: 0.6971 - MSE: 1.7702 - val_loss: 1.2803 - val_MAE: 0.9427 - val_MSE: 42.3209\n",
      "Epoch 550/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9304 - MAE: 0.6954 - MSE: 1.7526\n",
      "Epoch 00550: saving model to NNmodels/weights.550-1.24967.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9304 - MAE: 0.6953 - MSE: 1.7521 - val_loss: 1.2497 - val_MAE: 0.9205 - val_MSE: 10.0139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 551/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9324 - MAE: 0.6972 - MSE: 1.7844\n",
      "Epoch 00551: saving model to NNmodels/weights.551-1.27432.h5\n",
      "1561/1561 [==============================] - 35s 22ms/step - loss: 0.9324 - MAE: 0.6972 - MSE: 1.7844 - val_loss: 1.2743 - val_MAE: 0.9408 - val_MSE: 34.4900\n",
      "Epoch 552/1100\n",
      "1561/1561 [==============================] - ETA: 0s - loss: 0.9339 - MAE: 0.6979 - MSE: 1.7649\n",
      "Epoch 00552: saving model to NNmodels/weights.552-1.27806.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9339 - MAE: 0.6979 - MSE: 1.7649 - val_loss: 1.2781 - val_MAE: 0.9241 - val_MSE: 37.2384\n",
      "Epoch 553/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9348 - MAE: 0.6988 - MSE: 1.7883\n",
      "Epoch 00553: saving model to NNmodels/weights.553-1.27757.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9348 - MAE: 0.6987 - MSE: 1.7876 - val_loss: 1.2776 - val_MAE: 0.9493 - val_MSE: 58.3799\n",
      "Epoch 554/1100\n",
      "1559/1561 [============================>.] - ETA: 0s - loss: 0.9323 - MAE: 0.6978 - MSE: 1.7837\n",
      "Epoch 00554: saving model to NNmodels/weights.554-1.41644.h5\n",
      "1561/1561 [==============================] - 34s 22ms/step - loss: 0.9324 - MAE: 0.6979 - MSE: 1.7845 - val_loss: 1.4164 - val_MAE: 1.0928 - val_MSE: 608.8706\n",
      "Epoch 555/1100\n",
      "1560/1561 [============================>.] - ETA: 0s - loss: 0.9302 - MAE: 0.6945 - MSE: 1.7620\n",
      "Epoch 00555: saving model to NNmodels/weights.555-1.38957.h5\n",
      "1561/1561 [==============================] - 43s 27ms/step - loss: 0.9302 - MAE: 0.6945 - MSE: 1.7617 - val_loss: 1.3896 - val_MAE: 1.0350 - val_MSE: 399.1010\n",
      "Epoch 556/1100\n",
      " 106/1561 [=>............................] - ETA: 40s - loss: 0.9426 - MAE: 0.7089 - MSE: 1.8247"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-428a13963115>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0msave_all_xy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NNmodels/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'weights.{epoch:02d}-{val_loss:.5f}.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_weights_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperiod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpoisson_loss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"MAE\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"MSE\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_part\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_part\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdemand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msave_all_xy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdemand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[main_input],outputs=[secondary_out])\n",
    "from keras import backend as K\n",
    "def poisson(y_true, y_pred): \n",
    "    return K.mean(K.maximum(.0, y_pred) - y_true * K.log(K.maximum(.0, y_pred) + K.epsilon()), axis=-1)\n",
    "#    return K.mean(y_pred - y_true * K.log(y_pred + K.epsilon()), axis=-1)\n",
    "def poisson_loss(y_true, y_pred):\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    return tf.reduce_mean(y_pred - y_true*tf.math.log(y_pred+1e-10) + \\\n",
    "                          tf.math.lgamma(y_true+1.0))\n",
    "m = tf.keras.losses.poisson\n",
    "\n",
    "save_all_xy = keras.callbacks.ModelCheckpoint(\"NNmodels/\"+'weights.{epoch:02d}-{val_loss:.5f}.h5', monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "model.compile(loss=[poisson_loss], metrics=[\"MAE\",\"MSE\"] ,optimizer=Adam(lr=0.001),loss_weights=[1])\n",
    "history = model.fit(train_part.loc[:,utils.input_features].values,train_part.demand, verbose=1, callbacks=[save_all_xy], validation_data=(validation.loc[:,utils.input_features].values, validation.demand), shuffle=True, batch_size=150, epochs=1100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Training loss', 'Validation loss'], loc='upper right')\n",
    "plt.savefig(\"loss.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "def r_square(y_true, y_pred):\n",
    "    from keras import backend as K\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return (1 - SS_res/(SS_tot + K.epsilon()))\n",
    "\n",
    "def poisson_loss(y_true, y_pred):\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    return tf.reduce_mean(y_pred - y_true*tf.math.log(y_pred+1e-10) + \\\n",
    "                          tf.math.lgamma(y_true+1.0))\n",
    "\n",
    "model = load_model(\"/Users/mykola/MLHEP/Wiremind/NNModels/weights.85-1.15921.h5\", custom_objects={'<lambda>': lambda x : tl.act.lrelu(x, 0.2),\"r_square\":r_square,\"exp\":K.exp,\"poisson_loss\":poisson_loss})\n",
    "prediction_validation = np.array(model.predict(validation.loc[:, utils.input_features].values),dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 39, 43, 46, 51, 53, 61])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = np.floor(prediction_validation).astype(np.int)\n",
    "np.unique(k)\n",
    "#validation.demand.unique\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = prediction_validation\n",
    "first.flatten().shape\n",
    "second = prediction_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58530, 1)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validation.shape\n",
    "prediction_validation.shape\n",
    "#validation.loc[:,\"nn_demand\"] = np.rint(prediction_validation.flatten())\n",
    "#validation[25:50]\n",
    "#prediction_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45139.0\n"
     ]
    }
   ],
   "source": [
    "#1.25*np.rint(prediction_validation)[:50]\n",
    "print(abs(np.rint(k.flatten()) - np.array(validation.demand)).sum())\n",
    "#np.rint(prediction_validation)[:50]\n",
    "#np.mean(validation.current_price*abs(np.rint(first.flatten()) - np.array(validation.demand)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.771211344609602"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(abs(np.rint(k.flatten()) - np.array(validation.demand)))\n",
    "#np.mean((np.rint(k.flatten()) - np.array(validation.demand))**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([36, 85, 51, ..., 54, 58, 21])"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "x = np.random.randint(1, 100, 5000)\n",
    "x\n",
    "#plt.hist(x, bins=20)\n",
    "#plt.ylabel('No of times')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47836.0"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features[all_features.od_destination_time_weekday.eq(1)].demand.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[47836.0, 51640.0, 56415.0, 75985.0, 44189.0, 59877.0, 59768.0]"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dem_weekday = [all_features[all_features.od_destination_time_weekday.eq(x)].demand.sum() for x in all_features.od_destination_time_weekday.unique()]\n",
    "dem_weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[128910.0,\n",
       " 71994.0,\n",
       " 29729.0,\n",
       " 22823.0,\n",
       " 18193.0,\n",
       " 14955.0,\n",
       " 12845.0,\n",
       " 11473.0,\n",
       " 9278.0,\n",
       " 7570.0,\n",
       " 6572.0,\n",
       " 5701.0,\n",
       " 4991.0,\n",
       " 4829.0,\n",
       " 4788.0,\n",
       " 4409.0,\n",
       " 3938.0,\n",
       " 3582.0,\n",
       " 3376.0,\n",
       " 3074.0,\n",
       " 2984.0,\n",
       " 2867.0,\n",
       " 2666.0,\n",
       " 2417.0,\n",
       " 2438.0,\n",
       " 1943.0,\n",
       " 1951.0,\n",
       " 1843.0,\n",
       " 1828.0,\n",
       " 1743.0]"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dem_daysbefore = [all_features[all_features.days_before_departure.eq(x)].demand.sum() for x in all_features.days_before_departure.unique()]\n",
    "dem_daysbefore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "365"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dem_date = [all_features[all_features.date_numerical.eq(x)].demand.sum() for x in all_features.date_numerical.unique()]\n",
    "len(dem_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47836.0, 51640.0, 56415.0, 75985.0, 44189.0, 59877.0, 59768.0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(dem_weekday)\n",
    "plt.plot(range(0,len(dem_weekday)),dem_weekday)\n",
    "plt.xlabel('Date')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(0,len(dem_date)),dem_date)\n",
    "plt.xlabel('Date')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dem_daysbefore_val = [validation[validation.days_before_departure.eq(x)].demand.sum() for x in validation.days_before_departure.unique()]\n",
    "dem_daysbefore_nn = [validation[validation.days_before_departure.eq(x)].nn_demand.sum() for x in validation.days_before_departure.unique()]\n",
    "all_ = [validation[validation.days_before_departure.eq(x)].nn_demand.sum() for x in validation.days_before_departure.unique()]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(0,len(dem_daysbefore_nn)),dem_daysbefore_val)\n",
    "plt.xlabel('Date')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211355     5.0\n",
       "22542     12.0\n",
       "175520    20.0\n",
       "164469     9.0\n",
       "53493      3.0\n",
       "          ... \n",
       "225451     1.0\n",
       "67483     13.0\n",
       "10644     24.0\n",
       "255157     7.0\n",
       "227682    12.0\n",
       "Name: days_before_departure, Length: 58530, dtype: float64"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.loc[:,\"days_before_departure\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current_price</th>\n",
       "      <th>days_before_departure</th>\n",
       "      <th>od_destination_time_month</th>\n",
       "      <th>od_destination_time_week</th>\n",
       "      <th>od_destination_time_day</th>\n",
       "      <th>od_destination_time_weekday</th>\n",
       "      <th>od_time_travel</th>\n",
       "      <th>od_destination_time_hourmin</th>\n",
       "      <th>od_origin_time_hourmin</th>\n",
       "      <th>direction_bool</th>\n",
       "      <th>demand</th>\n",
       "      <th>of_holiday</th>\n",
       "      <th>unof_holiday</th>\n",
       "      <th>date_numerical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69580</th>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>814.0</td>\n",
       "      <td>697.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49753</th>\n",
       "      <td>44.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>694.0</td>\n",
       "      <td>577.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2702</th>\n",
       "      <td>100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>456.0</td>\n",
       "      <td>317.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98526</th>\n",
       "      <td>100.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>994.0</td>\n",
       "      <td>877.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109822</th>\n",
       "      <td>44.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>983.0</td>\n",
       "      <td>865.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128419</th>\n",
       "      <td>44.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>1171.0</td>\n",
       "      <td>1057.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270933</th>\n",
       "      <td>100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>1350.0</td>\n",
       "      <td>1237.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292252</th>\n",
       "      <td>44.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>994.0</td>\n",
       "      <td>877.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247226</th>\n",
       "      <td>44.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1043.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205700</th>\n",
       "      <td>44.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>803.0</td>\n",
       "      <td>690.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58530 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        current_price  days_before_departure  od_destination_time_month  \\\n",
       "69580           100.0                   10.0                       10.0   \n",
       "49753            44.0                   13.0                       10.0   \n",
       "2702            100.0                    2.0                        5.0   \n",
       "98526           100.0                    6.0                       10.0   \n",
       "109822           44.0                   22.0                        9.0   \n",
       "...               ...                    ...                        ...   \n",
       "128419           44.0                   19.0                        5.0   \n",
       "270933          100.0                    3.0                        2.0   \n",
       "292252           44.0                   22.0                       12.0   \n",
       "247226           44.0                   26.0                        7.0   \n",
       "205700           44.0                   20.0                        1.0   \n",
       "\n",
       "        od_destination_time_week  od_destination_time_day  \\\n",
       "69580                       42.0                     15.0   \n",
       "49753                       41.0                      9.0   \n",
       "2702                        20.0                     15.0   \n",
       "98526                       44.0                     30.0   \n",
       "109822                      39.0                     27.0   \n",
       "...                          ...                      ...   \n",
       "128419                      21.0                     23.0   \n",
       "270933                       9.0                     26.0   \n",
       "292252                       1.0                     31.0   \n",
       "247226                      31.0                     31.0   \n",
       "205700                       4.0                     25.0   \n",
       "\n",
       "        od_destination_time_weekday  od_time_travel  \\\n",
       "69580                           0.0           117.0   \n",
       "49753                           1.0           117.0   \n",
       "2702                            1.0           139.0   \n",
       "98526                           1.0           117.0   \n",
       "109822                          3.0           118.0   \n",
       "...                             ...             ...   \n",
       "128419                          2.0           114.0   \n",
       "270933                          0.0           113.0   \n",
       "292252                          0.0           117.0   \n",
       "247226                          1.0           125.0   \n",
       "205700                          3.0           113.0   \n",
       "\n",
       "        od_destination_time_hourmin  od_origin_time_hourmin  direction_bool  \\\n",
       "69580                         814.0                   697.0               1   \n",
       "49753                         694.0                   577.0               1   \n",
       "2702                          456.0                   317.0               1   \n",
       "98526                         994.0                   877.0               1   \n",
       "109822                        983.0                   865.0               0   \n",
       "...                             ...                     ...             ...   \n",
       "128419                       1171.0                  1057.0               1   \n",
       "270933                       1350.0                  1237.0               1   \n",
       "292252                        994.0                   877.0               1   \n",
       "247226                       1043.0                   918.0               0   \n",
       "205700                        803.0                   690.0               0   \n",
       "\n",
       "        demand  of_holiday  unof_holiday  date_numerical  \n",
       "69580      0.0           0             0             288  \n",
       "49753      0.0           0             0             282  \n",
       "2702       1.0           0             0             135  \n",
       "98526      0.0           0             0             303  \n",
       "109822     2.0           0             0             270  \n",
       "...        ...         ...           ...             ...  \n",
       "128419     0.0           0             0             143  \n",
       "270933     0.0           0             0              57  \n",
       "292252     0.0           0             0             365  \n",
       "247226     0.0           0             0             212  \n",
       "205700     0.0           0             0              25  \n",
       "\n",
       "[58530 rows x 14 columns]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = MinMaxScaler()\n",
    "sc.fit(all_features.loc[:, utils.scalable_columns])\n",
    "val = validation.copy()\n",
    "val[utils.scalable_columns]= sc.inverse_transform(validation.loc[:, utils.scalable_columns])\n",
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
       "       13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,\n",
       "       28., 29., 32., 33., 44., 51., 52.])"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(validation.current_price*abs(np.rint(prediction_validation.flatten()) - np.array(validation.demand)))\n",
    "np.unique(diff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = (abs((second.flatten()) - np.array(validation.demand)))\n",
    "np.unique(diff)\n",
    "val[\"diff_second\"] = diff\n",
    "val[\"predict\"] = (second)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.49619961e+00],\n",
       "       [-4.26759152e-03],\n",
       "       [-3.73237440e-03],\n",
       "       ...,\n",
       "       [-4.41087782e-03],\n",
       "       [ 1.31557211e-02],\n",
       "       [ 2.01794505e-03]])"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current_price</th>\n",
       "      <th>days_before_departure</th>\n",
       "      <th>od_destination_time_month</th>\n",
       "      <th>od_destination_time_week</th>\n",
       "      <th>od_destination_time_day</th>\n",
       "      <th>od_destination_time_weekday</th>\n",
       "      <th>od_time_travel</th>\n",
       "      <th>od_destination_time_hourmin</th>\n",
       "      <th>od_origin_time_hourmin</th>\n",
       "      <th>direction_bool</th>\n",
       "      <th>demand</th>\n",
       "      <th>of_holiday</th>\n",
       "      <th>unof_holiday</th>\n",
       "      <th>date_numerical</th>\n",
       "      <th>diff</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110520</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>983.0</td>\n",
       "      <td>865.0</td>\n",
       "      <td>0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>294</td>\n",
       "      <td>33.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        current_price  days_before_departure  od_destination_time_month  \\\n",
       "110520          100.0                    0.0                       10.0   \n",
       "\n",
       "        od_destination_time_week  od_destination_time_day  \\\n",
       "110520                      42.0                     21.0   \n",
       "\n",
       "        od_destination_time_weekday  od_time_travel  \\\n",
       "110520                          6.0           118.0   \n",
       "\n",
       "        od_destination_time_hourmin  od_origin_time_hourmin  direction_bool  \\\n",
       "110520                        983.0                   865.0               0   \n",
       "\n",
       "        demand  of_holiday  unof_holiday  date_numerical  diff  predict  \n",
       "110520    58.0           0             0             294  33.0     25.0  "
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val[val[\"diff\"].eq(33)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8., -0.,  3.,  1.,  2., 11.,  6., 12., 14.,  5.,  4., 18., 34.,\n",
       "       16., 10., 15., 21., 22., 20.,  7., 13., 30., 23.,  9., 17., 32.,\n",
       "       19., 26., 47., 25., 36., 27., 33., 24., 28., 31., -1., 35., 29.,\n",
       "       39., 37., 41., 48., 52., 38., 42., 46., 45.])"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val[\"predict\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current_price</th>\n",
       "      <th>days_before_departure</th>\n",
       "      <th>od_destination_time_month</th>\n",
       "      <th>od_destination_time_week</th>\n",
       "      <th>od_destination_time_day</th>\n",
       "      <th>od_destination_time_weekday</th>\n",
       "      <th>od_time_travel</th>\n",
       "      <th>od_destination_time_hourmin</th>\n",
       "      <th>od_origin_time_hourmin</th>\n",
       "      <th>direction_bool</th>\n",
       "      <th>demand</th>\n",
       "      <th>of_holiday</th>\n",
       "      <th>unof_holiday</th>\n",
       "      <th>date_numerical</th>\n",
       "      <th>diff</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100860</th>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>1054.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>119</td>\n",
       "      <td>11.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66030</th>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>814.0</td>\n",
       "      <td>697.0</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "      <td>11.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131640</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>1171.0</td>\n",
       "      <td>1057.0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>251</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123780</th>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>1043.0</td>\n",
       "      <td>925.0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>336</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148710</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>1166.0</td>\n",
       "      <td>1038.0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>217</td>\n",
       "      <td>9.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69120</th>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>814.0</td>\n",
       "      <td>697.0</td>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>273</td>\n",
       "      <td>7.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114600</th>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>1110.0</td>\n",
       "      <td>997.0</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>9.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123600</th>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>1043.0</td>\n",
       "      <td>925.0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315</td>\n",
       "      <td>6.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117690</th>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>1114.0</td>\n",
       "      <td>997.0</td>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245</td>\n",
       "      <td>12.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        current_price  days_before_departure  od_destination_time_month  \\\n",
       "100860           85.0                    0.0                        4.0   \n",
       "66030            85.0                    0.0                        6.0   \n",
       "131640          100.0                    0.0                        9.0   \n",
       "123780           85.0                    0.0                       12.0   \n",
       "148710          100.0                    0.0                        8.0   \n",
       "69120            85.0                    0.0                        9.0   \n",
       "114600           85.0                    0.0                        3.0   \n",
       "123600           85.0                    0.0                       11.0   \n",
       "117690           85.0                    0.0                        9.0   \n",
       "\n",
       "        od_destination_time_week  od_destination_time_day  \\\n",
       "100860                      17.0                     29.0   \n",
       "66030                       24.0                     17.0   \n",
       "131640                      36.0                      8.0   \n",
       "123780                      48.0                      2.0   \n",
       "148710                      31.0                      5.0   \n",
       "69120                       39.0                     30.0   \n",
       "114600                      11.0                     18.0   \n",
       "123600                      45.0                     11.0   \n",
       "117690                      35.0                      2.0   \n",
       "\n",
       "        od_destination_time_weekday  od_time_travel  \\\n",
       "100860                          6.0           117.0   \n",
       "66030                           6.0           117.0   \n",
       "131640                          5.0           114.0   \n",
       "123780                          6.0           118.0   \n",
       "148710                          6.0           128.0   \n",
       "69120                           6.0           117.0   \n",
       "114600                          6.0           113.0   \n",
       "123600                          6.0           118.0   \n",
       "117690                          6.0           117.0   \n",
       "\n",
       "        od_destination_time_hourmin  od_origin_time_hourmin  direction_bool  \\\n",
       "100860                       1054.0                   937.0               1   \n",
       "66030                         814.0                   697.0               1   \n",
       "131640                       1171.0                  1057.0               1   \n",
       "123780                       1043.0                   925.0               0   \n",
       "148710                       1166.0                  1038.0               0   \n",
       "69120                         814.0                   697.0               1   \n",
       "114600                       1110.0                   997.0               1   \n",
       "123600                       1043.0                   925.0               0   \n",
       "117690                       1114.0                   997.0               1   \n",
       "\n",
       "        demand  of_holiday  unof_holiday  date_numerical  diff  predict  \n",
       "100860    18.0           0             0             119  11.0     29.0  \n",
       "66030     18.0           0             0             168  11.0     29.0  \n",
       "131640    26.0           0             0             251   3.0     29.0  \n",
       "123780    30.0           0             0             336   1.0     29.0  \n",
       "148710    20.0           0             0             217   9.0     29.0  \n",
       "69120     36.0           0             0             273   7.0     29.0  \n",
       "114600    38.0           0             0              77   9.0     29.0  \n",
       "123600    23.0           0             0             315   6.0     29.0  \n",
       "117690    41.0           0             0             245  12.0     29.0  "
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val[val[\"predict\"].eq(29)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current_price</th>\n",
       "      <th>days_before_departure</th>\n",
       "      <th>od_destination_time_month</th>\n",
       "      <th>od_destination_time_week</th>\n",
       "      <th>od_destination_time_day</th>\n",
       "      <th>od_destination_time_weekday</th>\n",
       "      <th>od_time_travel</th>\n",
       "      <th>od_destination_time_hourmin</th>\n",
       "      <th>od_origin_time_hourmin</th>\n",
       "      <th>direction_bool</th>\n",
       "      <th>demand</th>\n",
       "      <th>of_holiday</th>\n",
       "      <th>unof_holiday</th>\n",
       "      <th>date_numerical</th>\n",
       "      <th>diff</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114222</th>\n",
       "      <td>85.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>1110.0</td>\n",
       "      <td>997.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179616</th>\n",
       "      <td>100.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>570.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229021</th>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1068.0</td>\n",
       "      <td>970.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151051</th>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>1223.0</td>\n",
       "      <td>1110.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283441</th>\n",
       "      <td>85.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>754.0</td>\n",
       "      <td>637.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124262</th>\n",
       "      <td>100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>1172.0</td>\n",
       "      <td>1057.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99377</th>\n",
       "      <td>44.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>994.0</td>\n",
       "      <td>877.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>336</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265920</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>595.0</td>\n",
       "      <td>457.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>188</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179121</th>\n",
       "      <td>44.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>623.0</td>\n",
       "      <td>505.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>321</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213611</th>\n",
       "      <td>100.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>803.0</td>\n",
       "      <td>685.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>291</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233222</th>\n",
       "      <td>100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>1071.0</td>\n",
       "      <td>967.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>262</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48152</th>\n",
       "      <td>85.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>694.0</td>\n",
       "      <td>577.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>229</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257859</th>\n",
       "      <td>44.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>985.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>362</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124532</th>\n",
       "      <td>85.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>1170.0</td>\n",
       "      <td>1057.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265929</th>\n",
       "      <td>44.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>595.0</td>\n",
       "      <td>457.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>188</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181800</th>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>574.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46844</th>\n",
       "      <td>44.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>715.0</td>\n",
       "      <td>577.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>178</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207700</th>\n",
       "      <td>44.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>803.0</td>\n",
       "      <td>685.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285050</th>\n",
       "      <td>44.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>775.0</td>\n",
       "      <td>637.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>188</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36600</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>445.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63505</th>\n",
       "      <td>85.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>810.0</td>\n",
       "      <td>697.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77595</th>\n",
       "      <td>44.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>955.0</td>\n",
       "      <td>817.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>192</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59063</th>\n",
       "      <td>85.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>625.0</td>\n",
       "      <td>505.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78272</th>\n",
       "      <td>44.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>955.0</td>\n",
       "      <td>817.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>217</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148382</th>\n",
       "      <td>85.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>1166.0</td>\n",
       "      <td>1038.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102005</th>\n",
       "      <td>85.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>1054.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>244</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141578</th>\n",
       "      <td>44.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>1236.0</td>\n",
       "      <td>1117.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141936</th>\n",
       "      <td>44.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>1256.0</td>\n",
       "      <td>1117.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>178</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89146</th>\n",
       "      <td>85.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>863.0</td>\n",
       "      <td>745.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>287</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218253</th>\n",
       "      <td>85.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>923.0</td>\n",
       "      <td>810.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129871</th>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>1191.0</td>\n",
       "      <td>1057.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>192</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184982</th>\n",
       "      <td>100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>574.0</td>\n",
       "      <td>457.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73889</th>\n",
       "      <td>44.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>930.0</td>\n",
       "      <td>817.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77017</th>\n",
       "      <td>85.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>955.0</td>\n",
       "      <td>817.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174000</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>1346.0</td>\n",
       "      <td>1227.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268594</th>\n",
       "      <td>100.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>1291.0</td>\n",
       "      <td>1177.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>342</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154658</th>\n",
       "      <td>44.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1223.0</td>\n",
       "      <td>1098.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107374</th>\n",
       "      <td>44.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>983.0</td>\n",
       "      <td>865.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77546</th>\n",
       "      <td>44.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>955.0</td>\n",
       "      <td>817.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238380</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>526.0</td>\n",
       "      <td>423.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32460</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>631.0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>337</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55535</th>\n",
       "      <td>85.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>623.0</td>\n",
       "      <td>505.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23865</th>\n",
       "      <td>44.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>630.0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138726</th>\n",
       "      <td>100.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>1230.0</td>\n",
       "      <td>1117.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149805</th>\n",
       "      <td>44.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1165.0</td>\n",
       "      <td>1045.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>342</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85838</th>\n",
       "      <td>44.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>866.0</td>\n",
       "      <td>745.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51003</th>\n",
       "      <td>100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>694.0</td>\n",
       "      <td>577.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>326</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203344</th>\n",
       "      <td>44.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>683.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>355</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236733</th>\n",
       "      <td>100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>526.0</td>\n",
       "      <td>428.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46296</th>\n",
       "      <td>44.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>694.0</td>\n",
       "      <td>577.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        current_price  days_before_departure  od_destination_time_month  \\\n",
       "114222           85.0                   12.0                        3.0   \n",
       "179616          100.0                    6.0                        1.0   \n",
       "229021          100.0                    1.0                        1.0   \n",
       "151051          100.0                    1.0                        2.0   \n",
       "283441           85.0                    1.0                        5.0   \n",
       "124262          100.0                    2.0                        1.0   \n",
       "99377            44.0                   17.0                       12.0   \n",
       "265920          100.0                    0.0                        7.0   \n",
       "179121           44.0                   21.0                       11.0   \n",
       "213611          100.0                   11.0                       10.0   \n",
       "233222          100.0                    2.0                        9.0   \n",
       "48152            85.0                    2.0                        8.0   \n",
       "257859           44.0                    9.0                       12.0   \n",
       "124532           85.0                    2.0                        1.0   \n",
       "265929           44.0                    9.0                        7.0   \n",
       "181800           85.0                    0.0                        4.0   \n",
       "46844            44.0                   14.0                        6.0   \n",
       "207700           44.0                   10.0                        4.0   \n",
       "285050           44.0                   20.0                        7.0   \n",
       "36600           100.0                    0.0                        5.0   \n",
       "63505            85.0                   25.0                        3.0   \n",
       "77595            44.0                   15.0                        7.0   \n",
       "59063            85.0                   23.0                       10.0   \n",
       "78272            44.0                    2.0                        8.0   \n",
       "148382           85.0                    2.0                        6.0   \n",
       "102005           85.0                    5.0                        9.0   \n",
       "141578           44.0                    8.0                        6.0   \n",
       "141936           44.0                    6.0                        6.0   \n",
       "89146            85.0                   16.0                       10.0   \n",
       "218253           85.0                    3.0                        3.0   \n",
       "129871          100.0                    1.0                        7.0   \n",
       "184982          100.0                    2.0                       10.0   \n",
       "73889            44.0                   29.0                        3.0   \n",
       "77017            85.0                    7.0                        6.0   \n",
       "174000          100.0                    0.0                        8.0   \n",
       "268594          100.0                    4.0                       12.0   \n",
       "154658           44.0                    8.0                        6.0   \n",
       "107374           44.0                    4.0                        5.0   \n",
       "77546            44.0                   26.0                        7.0   \n",
       "238380          100.0                    0.0                        5.0   \n",
       "32460           100.0                    0.0                       12.0   \n",
       "55535            85.0                    5.0                        5.0   \n",
       "23865            44.0                   15.0                        2.0   \n",
       "138726          100.0                    6.0                        2.0   \n",
       "149805           44.0                   15.0                       12.0   \n",
       "85838            44.0                    8.0                        6.0   \n",
       "51003           100.0                    3.0                       11.0   \n",
       "203344           44.0                    4.0                       12.0   \n",
       "236733          100.0                    3.0                        3.0   \n",
       "46296            44.0                    6.0                        6.0   \n",
       "\n",
       "        od_destination_time_week  od_destination_time_day  \\\n",
       "114222                       9.0                      2.0   \n",
       "179616                       3.0                     15.0   \n",
       "229021                       3.0                     16.0   \n",
       "151051                       6.0                      7.0   \n",
       "283441                      18.0                      5.0   \n",
       "124262                       1.0                      5.0   \n",
       "99377                       48.0                      2.0   \n",
       "265920                      27.0                      7.0   \n",
       "179121                      46.0                     17.0   \n",
       "213611                      42.0                     18.0   \n",
       "233222                      38.0                     19.0   \n",
       "48152                       33.0                     17.0   \n",
       "257859                      52.0                     28.0   \n",
       "124532                       2.0                     14.0   \n",
       "265929                      27.0                      7.0   \n",
       "181800                      17.0                     27.0   \n",
       "46844                       26.0                     27.0   \n",
       "207700                      14.0                      2.0   \n",
       "285050                      27.0                      7.0   \n",
       "36600                       20.0                     15.0   \n",
       "63505                       12.0                     24.0   \n",
       "77595                       28.0                     11.0   \n",
       "59063                       41.0                     12.0   \n",
       "78272                       31.0                      5.0   \n",
       "148382                      26.0                     30.0   \n",
       "102005                      35.0                      1.0   \n",
       "141578                      24.0                     12.0   \n",
       "141936                      26.0                     27.0   \n",
       "89146                       41.0                     14.0   \n",
       "218253                      12.0                     23.0   \n",
       "129871                      28.0                     11.0   \n",
       "184982                      40.0                      4.0   \n",
       "73889                       10.0                      9.0   \n",
       "77017                       25.0                     22.0   \n",
       "174000                      35.0                     28.0   \n",
       "268594                      49.0                      8.0   \n",
       "154658                      26.0                     29.0   \n",
       "107374                      21.0                     21.0   \n",
       "77546                       28.0                      9.0   \n",
       "238380                      22.0                     30.0   \n",
       "32460                       49.0                      3.0   \n",
       "55535                       21.0                     25.0   \n",
       "23865                        7.0                     15.0   \n",
       "138726                       8.0                     20.0   \n",
       "149805                      49.0                      8.0   \n",
       "85838                       23.0                      5.0   \n",
       "51003                       47.0                     22.0   \n",
       "203344                      51.0                     21.0   \n",
       "236733                      10.0                      8.0   \n",
       "46296                       23.0                      5.0   \n",
       "\n",
       "        od_destination_time_weekday  od_time_travel  \\\n",
       "114222                          4.0           113.0   \n",
       "179616                          0.0           120.0   \n",
       "229021                          1.0            98.0   \n",
       "151051                          2.0           113.0   \n",
       "283441                          5.0           117.0   \n",
       "124262                          4.0           115.0   \n",
       "99377                           6.0           117.0   \n",
       "265920                          5.0           138.0   \n",
       "179121                          5.0           118.0   \n",
       "213611                          3.0           118.0   \n",
       "233222                          2.0           104.0   \n",
       "48152                           4.0           117.0   \n",
       "257859                          4.0           121.0   \n",
       "124532                          6.0           113.0   \n",
       "265929                          5.0           138.0   \n",
       "181800                          4.0           124.0   \n",
       "46844                           2.0           138.0   \n",
       "207700                          0.0           118.0   \n",
       "285050                          5.0           138.0   \n",
       "36600                           1.0           118.0   \n",
       "63505                           5.0           113.0   \n",
       "77595                           2.0           138.0   \n",
       "59063                           4.0           120.0   \n",
       "78272                           6.0           138.0   \n",
       "148382                          5.0           128.0   \n",
       "102005                          5.0           117.0   \n",
       "141578                          1.0           119.0   \n",
       "141936                          2.0           139.0   \n",
       "89146                           6.0           118.0   \n",
       "218253                          4.0           113.0   \n",
       "129871                          2.0           134.0   \n",
       "184982                          3.0           117.0   \n",
       "73889                           4.0           113.0   \n",
       "77017                           4.0           138.0   \n",
       "174000                          1.0           119.0   \n",
       "268594                          5.0           114.0   \n",
       "154658                          4.0           125.0   \n",
       "107374                          0.0           118.0   \n",
       "77546                           0.0           138.0   \n",
       "238380                          2.0           103.0   \n",
       "32460                           0.0           114.0   \n",
       "55535                           4.0           118.0   \n",
       "23865                           3.0           113.0   \n",
       "138726                          1.0           113.0   \n",
       "149805                          5.0           120.0   \n",
       "85838                           1.0           121.0   \n",
       "51003                           3.0           117.0   \n",
       "203344                          4.0           118.0   \n",
       "236733                          3.0            98.0   \n",
       "46296                           1.0           117.0   \n",
       "\n",
       "        od_destination_time_hourmin  od_origin_time_hourmin  direction_bool  \\\n",
       "114222                       1110.0                   997.0               1   \n",
       "179616                        570.0                   450.0               1   \n",
       "229021                       1068.0                   970.0               1   \n",
       "151051                       1223.0                  1110.0               0   \n",
       "283441                        754.0                   637.0               1   \n",
       "124262                       1172.0                  1057.0               1   \n",
       "99377                         994.0                   877.0               1   \n",
       "265920                        595.0                   457.0               1   \n",
       "179121                        623.0                   505.0               0   \n",
       "213611                        803.0                   685.0               0   \n",
       "233222                       1071.0                   967.0               1   \n",
       "48152                         694.0                   577.0               1   \n",
       "257859                       1106.0                   985.0               0   \n",
       "124532                       1170.0                  1057.0               1   \n",
       "265929                        595.0                   457.0               1   \n",
       "181800                        574.0                   450.0               1   \n",
       "46844                         715.0                   577.0               1   \n",
       "207700                        803.0                   685.0               0   \n",
       "285050                        775.0                   637.0               1   \n",
       "36600                         563.0                   445.0               0   \n",
       "63505                         810.0                   697.0               1   \n",
       "77595                         955.0                   817.0               1   \n",
       "59063                         625.0                   505.0               0   \n",
       "78272                         955.0                   817.0               1   \n",
       "148382                       1166.0                  1038.0               0   \n",
       "102005                       1054.0                   937.0               1   \n",
       "141578                       1236.0                  1117.0               1   \n",
       "141936                       1256.0                  1117.0               1   \n",
       "89146                         863.0                   745.0               0   \n",
       "218253                        923.0                   810.0               0   \n",
       "129871                       1191.0                  1057.0               1   \n",
       "184982                        574.0                   457.0               1   \n",
       "73889                         930.0                   817.0               1   \n",
       "77017                         955.0                   817.0               1   \n",
       "174000                       1346.0                  1227.0               0   \n",
       "268594                       1291.0                  1177.0               1   \n",
       "154658                       1223.0                  1098.0               0   \n",
       "107374                        983.0                   865.0               0   \n",
       "77546                         955.0                   817.0               1   \n",
       "238380                        526.0                   423.0               0   \n",
       "32460                         631.0                   517.0               1   \n",
       "55535                         623.0                   505.0               0   \n",
       "23865                         630.0                   517.0               1   \n",
       "138726                       1230.0                  1117.0               1   \n",
       "149805                       1165.0                  1045.0               0   \n",
       "85838                         866.0                   745.0               0   \n",
       "51003                         694.0                   577.0               1   \n",
       "203344                        683.0                   565.0               0   \n",
       "236733                        526.0                   428.0               0   \n",
       "46296                         694.0                   577.0               1   \n",
       "\n",
       "        demand  of_holiday  unof_holiday  date_numerical  diff  predict  \n",
       "114222     4.0           0             0              61   4.0      0.0  \n",
       "179616     4.0           0             0              15   3.0      1.0  \n",
       "229021     4.0           0             0              16   4.0      8.0  \n",
       "151051     4.0           0             0              38   1.0      3.0  \n",
       "283441     4.0           0             0             125  10.0     14.0  \n",
       "124262     4.0           0             0               5   1.0      3.0  \n",
       "99377      4.0           0             0             336   4.0     -0.0  \n",
       "265920     4.0           0             0             188   1.0      5.0  \n",
       "179121     4.0           0             0             321   4.0     -0.0  \n",
       "213611     4.0           0             0             291   4.0      0.0  \n",
       "233222     4.0           0             0             262   2.0      6.0  \n",
       "48152      4.0           0             0             229   0.0      4.0  \n",
       "257859     4.0           0             0             362   4.0     -0.0  \n",
       "124532     4.0           0             0              14   2.0      2.0  \n",
       "265929     4.0           0             0             188   3.0      1.0  \n",
       "181800     4.0           0             0             117   1.0      3.0  \n",
       "46844      4.0           0             0             178   4.0     -0.0  \n",
       "207700     4.0           0             0              92   4.0     -0.0  \n",
       "285050     4.0           0             0             188   4.0     -0.0  \n",
       "36600      4.0           0             0             135   1.0      3.0  \n",
       "63505      4.0           0             0              83   4.0     -0.0  \n",
       "77595      4.0           0             0             192   4.0     -0.0  \n",
       "59063      4.0           0             0             285   4.0     -0.0  \n",
       "78272      4.0           0             0             217   1.0      5.0  \n",
       "148382     4.0           0             0             181   1.0      5.0  \n",
       "102005     4.0           0             0             244   2.0      2.0  \n",
       "141578     4.0           0             0             163   3.0      1.0  \n",
       "141936     4.0           0             0             178   3.0      1.0  \n",
       "89146      4.0           0             0             287   4.0     -0.0  \n",
       "218253     4.0           0             0              82   0.0      4.0  \n",
       "129871     4.0           0             0             192   1.0      5.0  \n",
       "184982     4.0           0             0             277   0.0      4.0  \n",
       "73889      4.0           0             0              68   4.0     -0.0  \n",
       "77017      4.0           0             0             173   4.0      0.0  \n",
       "174000     4.0           0             0             240   9.0     13.0  \n",
       "268594     4.0           0             0             342   3.0      1.0  \n",
       "154658     4.0           0             0             180   3.0      1.0  \n",
       "107374     4.0           0             0             141   2.0      2.0  \n",
       "77546      4.0           0             0             190   4.0     -0.0  \n",
       "238380     4.0           0             0             150   1.0      3.0  \n",
       "32460      4.0           0             0             337   1.0      5.0  \n",
       "55535      4.0           0             0             145   4.0      0.0  \n",
       "23865      4.0           0             0              46   4.0     -0.0  \n",
       "138726     4.0           0             0              51   4.0      0.0  \n",
       "149805     4.0           0             0             342   4.0     -0.0  \n",
       "85838      4.0           0             0             156   3.0      1.0  \n",
       "51003      4.0           0             0             326   2.0      2.0  \n",
       "203344     4.0           0             0             355   2.0      2.0  \n",
       "236733     4.0           0             0              67   3.0      7.0  \n",
       "46296      4.0           0             0             156   2.0      2.0  "
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val[val[\"demand\"].eq(4)][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12.,  0.,  1.,  4.,  2., 13.,  5., 10.,  3.,  7., 17.,  8.,  6.,\n",
       "       30., 21., 23., 20., 11., 35., 25., 29.,  9., 14., 24., 26., 16.,\n",
       "       15., 22., 18., 27., 19., 28., 56., 47., 37., 44., 57., 46., 34.,\n",
       "       51., 31., 32., 43., 68., 33., 40., 41., 39., 36., 38., 53., 52.,\n",
       "       42., 45., 50., 58., 66.])"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val[\"demand\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.,   0.,   3.,   2.,   4.,   5.,   6.,   7.,   8.,  16.,  10.,\n",
       "        12.,   9.,  15.,  11.,  13.,  14.,  17.,  23.,  18.,  19.,  21.,\n",
       "        24.,  25.,  20.,  22.,  26.,  28.,  34.,  27.,  36.,  39.,  30.,\n",
       "        32.,  35.,  29.,  42.,  44.,  33.,  41.,  45.,  31.,  48.,  38.,\n",
       "        43.,  40.,  37.,  47.,  51.,  49.,  46.,  50.,  56.,  53.,  66.,\n",
       "        58.,  52.,  64.,  80.,  54.,  61.,  97.,  62.,  95.,  68.,  72.,\n",
       "        63.,  78.,  55.,  57.,  65., 128., 139.,  77.])"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features[\"demand\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'nn_demand'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-386-0601123edba7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdem_daysbefore_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdays_before_departure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdemand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdays_before_departure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdem_daysbefore_nn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdays_before_departure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn_demand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdays_before_departure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdem_daysbefore_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#import matplotlib.pyplot as plt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#plt.plot(range(0,len(dem_daysbefore_nn)),dem_daysbefore_val)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-386-0601123edba7>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdem_daysbefore_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdays_before_departure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdemand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdays_before_departure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdem_daysbefore_nn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdays_before_departure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn_demand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdays_before_departure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdem_daysbefore_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#import matplotlib.pyplot as plt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#plt.plot(range(0,len(dem_daysbefore_nn)),dem_daysbefore_val)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5272\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5273\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5274\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'nn_demand'"
     ]
    }
   ],
   "source": [
    "dem_daysbefore_val = [validation[validation.days_before_departure.eq(x)].demand.sum() for x in validation.days_before_departure.unique()]\n",
    "dem_daysbefore_nn = [validation[validation.days_before_departure.eq(x)].nn_demand.sum() for x in validation.days_before_departure.unique()]\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "#plt.plot(range(0,len(dem_daysbefore_nn)),dem_daysbefore_val)\n",
    "#plt.xlabel('Date')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = (abs(np.rint(second.flatten()) - np.array(validation.demand)))\n",
    "mse = ((np.rint(second.flatten()) - np.array(validation.demand)**2))\n",
    "diff_price =  (abs(np.rint(second.flatten()) - np.array(val.demand))*np.array(val.current_price))\n",
    "\n",
    "np.unique(diff)\n",
    "val[\"diff_second\"] = diff\n",
    "val[\"predict\"] = np.rint(second.flatten())\n",
    "val[\"mse\"] = mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([100.,  44.,  85., 115.,  49.])"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val[\"current_price\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58.993012130531355"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(diff_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.227894736842106, 3.1525247267048413, 1.7575140091696384, 1.470435684647303, 1.29737753587333, 1.1477035490605427, 1.0939663699307616, 1.0506134969325154, 0.9011387163561076, 0.7305912596401029, 0.6337751595483554, 0.5433526011560693, 0.5283687943262412, 0.48464687819856705, 0.5339958158995816, 0.43914555389965226, 0.4568421052631579, 0.3312945973496432, 0.35036119711042313, 0.3119918699186992, 0.29671457905544146, 0.3046185781006746, 0.26876876876876876, 0.2339862361037586, 0.2537467700258398, 0.17659462308908802, 0.2114342040413997, 0.1938509640437728, 0.1973816717019134, 0.1874032008260196]\n",
      "[13.133157894736842, 7.5679333680374805, 3.034131431482425, 2.2608921161825726, 1.8134586838198912, 1.5167014613778707, 1.327398615232443, 1.2111451942740286, 0.9544513457556936, 0.7691516709511568, 0.6597938144329897, 0.5680504466631634, 0.5390070921985816, 0.4872057318321392, 0.5418410041841004, 0.4401390958768008, 0.4568421052631579, 0.3312945973496432, 0.35036119711042313, 0.3119918699186992, 0.29671457905544146, 0.3046185781006746, 0.26876876876876876, 0.2339862361037586, 0.2537467700258398, 0.17659462308908802, 0.2114342040413997, 0.1938509640437728, 0.1973816717019134, 0.1874032008260196]\n",
      "[11.997894736842106, 6.750650702758979, 2.484971981660723, 1.7717842323651452, 1.334487877288471, 0.9869519832985386, 0.6973293768545994, 0.4775051124744376, 0.33281573498964806, 0.25244215938303344, 0.1958762886597938, 0.13189700472937468, 0.07750759878419453, 0.04350051177072672, 0.017259414225941423, 0.003974167908594138, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "#dem_daysbefore_val = [ np.mean(val[val.days_before_departure.eq(x)].diff_second)/np.mean(val[val.days_before_departure.eq(x)].demand) for x in sorted(val.days_before_departure.unique())]\n",
    "dem_daysbefore_val = [ np.mean(val[val.days_before_departure.eq(x)].diff_second) for x in sorted(val.days_before_departure.unique())]\n",
    "#dem_daysbefore_val = [ -np.mean(val[val.days_before_departure.eq(x)].predict)+np.mean(val[val.days_before_departure.eq(x)].demand) for x in sorted(val.days_before_departure.unique())]\n",
    "dem_daysbefore_va = [ np.mean(val[val.days_before_departure.eq(x)].demand) for x in sorted(val.days_before_departure.unique())]\n",
    "dem_daysbefore_v = [ np.mean(val[val.days_before_departure.eq(x)].predict) for x in sorted(val.days_before_departure.unique())]\n",
    "\n",
    "print (dem_daysbefore_val)\n",
    "print (dem_daysbefore_va)\n",
    "print (dem_daysbefore_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(0,len(dem_daysbefore_val)),dem_daysbefore_val)\n",
    "plt.xlabel('Date')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 6.0,\n",
       " 7.0,\n",
       " 8.0,\n",
       " 9.0,\n",
       " 10.0,\n",
       " 11.0,\n",
       " 12.0,\n",
       " 13.0,\n",
       " 14.0,\n",
       " 15.000000000000002,\n",
       " 16.0,\n",
       " 17.0,\n",
       " 18.0,\n",
       " 19.0,\n",
       " 20.0,\n",
       " 21.0,\n",
       " 22.0,\n",
       " 23.0,\n",
       " 24.0,\n",
       " 25.0,\n",
       " 26.0,\n",
       " 27.0,\n",
       " 28.0,\n",
       " 29.0]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(val.days_before_departure.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
